{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9695c4a0ac39aa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Static models evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f94114ca18284a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Environment preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e889072cbfa09",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880443f09a46911",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa21aaa-9b67-417f-ab21-b1cd0eef9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7dc328d0e378d42",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9adca62a-7ca0-4adf-b21a-c36264a1383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed, parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9986163c2d6c17ad",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad73284178e4fea",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e804d2c0221b6093",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc4ace0e0c4cf5d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from vstk.models import Word2Vec, GloVe, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6938c2f2fc1e7d82",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from vstk.data import WordSimilarity, WordAnalogy, STS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370e6ac2493cb51",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f70b2a4af738331",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "W2V_MODEL_PATH = '../resources/models/pre_trained/word_2_vec/'\n",
    "GV_MODEL_PATH = '../resources/models/pre_trained/glove/'\n",
    "FT_MODEL_PATH = '../resources/models/pre_trained/fast_text/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0346f9a02803dba",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "WS_DATA_PATH = '../resources/data/raw/wordsim353'\n",
    "WA_DATA_PATH = '../resources/data/raw/question-words'\n",
    "STS_DATA_PATH = '../resources/data/raw/stsbenchmark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b45a02012cf81df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('../experiments/'):\n",
    "    os.mkdir('../experiments/')\n",
    "if not os.path.exists('../experiments/static'):\n",
    "    os.mkdir('../experiments/static')\n",
    "RESULTS_FILE_PATH = f'../experiments/static/results_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404123a599bd86d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1f713e76425d119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 13:21:15 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 192MB/s]                                                                                     \n",
      "2024-05-04 13:21:15 INFO: Downloaded file to /home/vincenzo/stanza_resources/resources.json\n",
      "2024-05-04 13:21:15 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-05-04 13:21:15 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "========================\n",
      "\n",
      "2024-05-04 13:21:15 INFO: Using device: cuda\n",
      "2024-05-04 13:21:15 INFO: Loading: tokenize\n",
      "2024-05-04 13:21:16 INFO: Loading: mwt\n",
      "2024-05-04 13:21:16 INFO: Done loading processors!\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "w2v = Word2Vec.load(W2V_MODEL_PATH)\n",
    "gv = GloVe.load(GV_MODEL_PATH)\n",
    "ft = FastText.load(FT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa8785db78e631e8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Word2Vec': w2v, \n",
    "    'GloVe': gv,\n",
    "    'fastText': ft\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1847053447d67dca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ws = WordSimilarity(WS_DATA_PATH)\n",
    "wa = WordAnalogy(WA_DATA_PATH)\n",
    "sts = {split: STS(STS_DATA_PATH, split=split) for split in ['train', 'validation', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16c126ff7790ccc9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "top_k = [1, 10, 100]\n",
    "similarity_configs =  [\n",
    "    {'metric': metric, 'dynamax_method': None, 'pooling': pooling, 'wmd_stopwords': False}\n",
    "    for metric, pooling in product(['cos', 'l2', 'jaccard'], ['avg', 'max', 'sif'])\n",
    "] + [\n",
    "    {'metric': 'dynamax', 'dynamax_method': method, 'pooling': None, 'wmd_stopwords': False}\n",
    "    for method in ['jaccard', 'otsuka', 'dice']\n",
    "] + [\n",
    "    {'metric': 'wmd', 'wmd_stopwords': sw, 'dynamax_method': None, 'pooling': None }\n",
    "    for sw in [True, False]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae5b5a82c206b123",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5907d95adbd46145",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172a9c22c8381b0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Word similarity\n",
    "\n",
    "Evaluate on word similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917aaee58f0b45e2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Extract samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed00ce4379e8243",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "token_a, token_b, score_true = [*zip(*[\n",
    "    (sample['token_1'], sample['token_2'], sample['similarity_score']) \n",
    "    for sample in ws\n",
    "])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cad20432bc232f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e357df9a3692fe89",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 24.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for model_id, model in tqdm(models.items()):\n",
    "    with parallel_backend('threading', n_jobs=-1):\n",
    "        score_pred = model.token_similarity(token_a, token_b)\n",
    "    spearman_corr = spearmanr(score_true, score_pred)\n",
    "    pearson_corr = pearsonr(score_true, score_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'model': model_id, \n",
    "        'task': 'Word similarity',\n",
    "        'metric': 'Spearman corr.',\n",
    "        'value': spearman_corr.correlation,\n",
    "        'pvalue': spearman_corr.pvalue,\n",
    "        'measure': 'cos'\n",
    "    })\n",
    "    results.append({\n",
    "        'model': model_id, \n",
    "        'task': 'Word similarity',\n",
    "        'metric': 'Pearson corr.',\n",
    "        'value': pearson_corr.correlation,\n",
    "        'pvalue': pearson_corr.pvalue,\n",
    "        'measure': 'cos'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd307252c12f3d91",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Accuracy@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ce09d92cf58efda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.91it/s]\n"
     ]
    }
   ],
   "source": [
    "max_k =  max(top_k)\n",
    "\n",
    "for model_id, model in tqdm(models.items()):\n",
    "    with parallel_backend('threading', n_jobs=-1):\n",
    "        most_similar = model.get_similar_tokens(token_a, k=max_k)\n",
    "    \n",
    "        for k in top_k:\n",
    "            accuracy_score = sum(\n",
    "                Parallel()(\n",
    "                    delayed(lambda x, y: any(t.strip().lower() == y.strip().lower() for t, _ in x[:k]))(similar_tokens, target) \n",
    "                    for similar_tokens, target in zip(most_similar, token_b)\n",
    "                ) \n",
    "            )  / len(token_a)\n",
    "            \n",
    "            results.append({\n",
    "                'model': model_id, \n",
    "                'task': 'Word similarity',\n",
    "                'metric': f'Acc@{k}',\n",
    "                'value': accuracy_score,\n",
    "                'measure': 'cos'\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bbc0a5d80f87fd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Word analogy\n",
    "\n",
    "Evaluate on question-words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5479a3c8f6dd7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Extract samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbf04dc818a38826",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tokens_src, token_tgt, = [*zip(*[\n",
    "    ((sample['token_1_pair_1'], sample['token_2_pair_1'], sample['token_1_pair_2']), sample['token_2_pair_2']) \n",
    "    for sample in wa if len(sample) == 5\n",
    "])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adbca344065f10",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Accuracy@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afae461927813b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:28<00:00,  9.46s/it]\n"
     ]
    }
   ],
   "source": [
    "max_k =  max(top_k)\n",
    "\n",
    "for model_id, model in tqdm(models.items()):\n",
    "    with parallel_backend('threading', n_jobs=-1):\n",
    "        most_similar = model.solve_analogy(tokens_src, k=max_k)\n",
    "        \n",
    "        for k in top_k:\n",
    "            accuracy_score = sum(\n",
    "                Parallel()(\n",
    "                    delayed(lambda x, y: any(t.strip().lower() == y.strip().lower() for t, _ in x[:k]))(similar_tokens, target) \n",
    "                    for similar_tokens, target in zip(most_similar, token_tgt)\n",
    "                ) \n",
    "            )  / len(tokens_src)\n",
    "            \n",
    "            results.append({\n",
    "                'model': model_id, \n",
    "                'task': 'Word analogies',\n",
    "                'metric': f'Acc@{k}',\n",
    "                'value': accuracy_score,\n",
    "                'measure': 'cos'\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547a13734c86b1e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Semantic Textual Similarity\n",
    "\n",
    "Evaluate on the STS benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c480f1af305d666d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Extract samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe14224989b07759",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sif_data = [sample[key] for sample in sts['train'] for key in ['sequence_a', 'sequence_b']]\n",
    "sequences = {\n",
    "    split: [*zip(*[(sample['sequence_a'], sample['sequence_b'], sample['similarity_score']) for sample in sts[split]])]\n",
    "    for split in ['validation', 'test']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98240153cee916",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1533a082e2a7e7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [08:17<00:00, 165.87s/it]\n"
     ]
    }
   ],
   "source": [
    "for model_id, model in tqdm(models.items()):\n",
    "    model.fit_sif_embedding(sif_data)\n",
    "    for split, (sequence_a, sequence_b, score_true) in sequences.items():\n",
    "        for config in similarity_configs:\n",
    "            with parallel_backend('threading', n_jobs=-1):\n",
    "                score_pred = model.sequence_similarity(sequence_a, sequence_b, **config)\n",
    "            spearman_corr = spearmanr(score_true, score_pred)\n",
    "            pearson_corr = pearsonr(score_true, score_pred)\n",
    "    \n",
    "            results.append({\n",
    "                'model': model_id, \n",
    "                'task': 'Sematic textual similarity',\n",
    "                'metric': 'Spearman corr.',\n",
    "                'value': spearman_corr.correlation,\n",
    "                'pvalue': spearman_corr.pvalue,\n",
    "                'measure': config['metric'],\n",
    "                'dynamax_method': config['dynamax_method'],\n",
    "                'pooling': config['pooling'],\n",
    "                'split': split\n",
    "            })\n",
    "            results.append({\n",
    "                'model': model_id, \n",
    "                'task': 'Sematic textual similarity',\n",
    "                'metric': 'Pearson corr.',\n",
    "                'value': pearson_corr.correlation,\n",
    "                'pvalue': pearson_corr.pvalue,\n",
    "                'measure': config['metric'],\n",
    "                'dynamax_method':  config['dynamax_method'],\n",
    "                'pooling': config['pooling'],\n",
    "                'split': split\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a85e4cf66027e7b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7f1d9e4ada94b2c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>measure</th>\n",
       "      <th>dynamax_method</th>\n",
       "      <th>pooling</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>Word similarity</td>\n",
       "      <td>Spearman corr.</td>\n",
       "      <td>0.700017</td>\n",
       "      <td>2.868667e-53</td>\n",
       "      <td>cos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>Word similarity</td>\n",
       "      <td>Pearson corr.</td>\n",
       "      <td>0.652535</td>\n",
       "      <td>3.373411e-44</td>\n",
       "      <td>cos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GloVe</td>\n",
       "      <td>Word similarity</td>\n",
       "      <td>Spearman corr.</td>\n",
       "      <td>0.737944</td>\n",
       "      <td>6.523243e-62</td>\n",
       "      <td>cos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GloVe</td>\n",
       "      <td>Word similarity</td>\n",
       "      <td>Pearson corr.</td>\n",
       "      <td>0.733025</td>\n",
       "      <td>1.043601e-60</td>\n",
       "      <td>cos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fastText</td>\n",
       "      <td>Word similarity</td>\n",
       "      <td>Spearman corr.</td>\n",
       "      <td>0.780395</td>\n",
       "      <td>1.444605e-73</td>\n",
       "      <td>cos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>fastText</td>\n",
       "      <td>Sematic textual similarity</td>\n",
       "      <td>Pearson corr.</td>\n",
       "      <td>0.156155</td>\n",
       "      <td>5.564347e-09</td>\n",
       "      <td>dynamax</td>\n",
       "      <td>dice</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>fastText</td>\n",
       "      <td>Sematic textual similarity</td>\n",
       "      <td>Spearman corr.</td>\n",
       "      <td>0.549791</td>\n",
       "      <td>9.331995e-110</td>\n",
       "      <td>wmd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>fastText</td>\n",
       "      <td>Sematic textual similarity</td>\n",
       "      <td>Pearson corr.</td>\n",
       "      <td>0.564229</td>\n",
       "      <td>9.673081e-117</td>\n",
       "      <td>wmd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>fastText</td>\n",
       "      <td>Sematic textual similarity</td>\n",
       "      <td>Spearman corr.</td>\n",
       "      <td>0.433388</td>\n",
       "      <td>3.076163e-64</td>\n",
       "      <td>wmd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>fastText</td>\n",
       "      <td>Sematic textual similarity</td>\n",
       "      <td>Pearson corr.</td>\n",
       "      <td>0.438354</td>\n",
       "      <td>7.673948e-66</td>\n",
       "      <td>wmd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model                        task          metric     value  \\\n",
       "0    Word2Vec             Word similarity  Spearman corr.  0.700017   \n",
       "1    Word2Vec             Word similarity   Pearson corr.  0.652535   \n",
       "2       GloVe             Word similarity  Spearman corr.  0.737944   \n",
       "3       GloVe             Word similarity   Pearson corr.  0.733025   \n",
       "4    fastText             Word similarity  Spearman corr.  0.780395   \n",
       "..        ...                         ...             ...       ...   \n",
       "187  fastText  Sematic textual similarity   Pearson corr.  0.156155   \n",
       "188  fastText  Sematic textual similarity  Spearman corr.  0.549791   \n",
       "189  fastText  Sematic textual similarity   Pearson corr.  0.564229   \n",
       "190  fastText  Sematic textual similarity  Spearman corr.  0.433388   \n",
       "191  fastText  Sematic textual similarity   Pearson corr.  0.438354   \n",
       "\n",
       "            pvalue  measure dynamax_method pooling split  \n",
       "0     2.868667e-53      cos            NaN     NaN   NaN  \n",
       "1     3.373411e-44      cos            NaN     NaN   NaN  \n",
       "2     6.523243e-62      cos            NaN     NaN   NaN  \n",
       "3     1.043601e-60      cos            NaN     NaN   NaN  \n",
       "4     1.444605e-73      cos            NaN     NaN   NaN  \n",
       "..             ...      ...            ...     ...   ...  \n",
       "187   5.564347e-09  dynamax           dice    None  test  \n",
       "188  9.331995e-110      wmd           None    None  test  \n",
       "189  9.673081e-117      wmd           None    None  test  \n",
       "190   3.076163e-64      wmd           None    None  test  \n",
       "191   7.673948e-66      wmd           None    None  test  \n",
       "\n",
       "[192 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame.from_dict(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "401e8647f2ae351c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results.to_csv(RESULTS_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067180a8-962a-4b78-a376-de41350ef9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
