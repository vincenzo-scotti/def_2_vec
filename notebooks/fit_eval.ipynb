{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Contextual models evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Environment preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed, parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from vstk.models import Word2Vec, GloVe, FastText, Def2Vec, Def2VecLegacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from vstk.data import CoNLL2003, SST, STS, NewsGroups, WELFake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "W2V_MODEL_PATH = '../resources/models/pre_trained/word_2_vec/'\n",
    "GV_MODEL_PATH = '../resources/models/pre_trained/glove/'\n",
    "FT_MODEL_PATH = '../resources/models/pre_trained/fast_text/'\n",
    "D2V_LEGACY_MODEL_PATH = '../resources/models/pre_trained/def_2_vec_legacy/'\n",
    "# Sub-words\n",
    "# D2V_MODEL_PATH = '../resources/models/pre_trained/def_2_vec_084926b712881ac5c62a5c520898bc8a20d2df205cd3fafbfe8fb66060294291/'\n",
    "# Sub-words - Stop-words removed\n",
    "# D2V_MODEL_PATH = '../resources/models/pre_trained/def_2_vec_2528fc7769d477bed290bfa827d5b499b0849a7e1851cbfdc37e296e21373071/'  # Main model\n",
    "# D2V_MODEL_PATH = '../resources/models/pre_trained/def_2_vec_2528fc7769d477bed290bfa827d5b499b0849a7e1851cbfdc37e296e21373071_extended/'\n",
    "# D2V_MODEL_PATH = '../resources/models/pre_trained/def_2_vec_2528fc7769d477bed290bfa827d5b499b0849a7e1851cbfdc37e296e21373071_reduced/'\n",
    "# No sub-words\n",
    "# D2V_MODEL_PATH = '../resources/models/pre_trained/def_2_vec_6a9f23276b7f235c3ef6aa8facb0efee6f716bd7ce8387e01c8df27831f35b27/'\n",
    "# No sub-words - Stop-words removed\n",
    "# D2V_MODEL_PATH = '../resources/models/pre_trained/def_2_vec_85d911ac6e585a5f6d1abbdb40609fb024d8d67d24c5f14a9b8da1eca6d8f863/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "CONLL2003_DATA_PATH = '../resources/data/raw/conll2003'\n",
    "SST_DATA_PATH = '../resources/data/raw/stanfordSentimentTreebank'\n",
    "STS_DATA_PATH = '../resources/data/raw/stsbenchmark'\n",
    "WELFAKE_DATA_PATH = '../resources/data/raw/WELFake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "CLS_METRICS = [\n",
    "    'accuracy', \n",
    "    'precision (macro)', \n",
    "    'recall (macro)', \n",
    "    'fscore (macro)', \n",
    "    'auc (macro)', \n",
    "    'precision (weighted)', \n",
    "    'recall (weighted)', \n",
    "    'fscore (weighted)', \n",
    "    'auc (weighted)',\n",
    "    'accuracy (sample weight)', \n",
    "    'precision (sample weight)', \n",
    "    'recall (sample weight)', \n",
    "    'fscore (sample weight)', \n",
    "    'auc (sample weight)', \n",
    "]\n",
    "REG_METRICS = [\n",
    "    'pearson corr.',\n",
    "    'pearson corr. p',\n",
    "    'spearman corr.',\n",
    "    'spearman corr. p'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('../experiments/'):\n",
    "    os.mkdir('../experiments/')\n",
    "if not os.path.exists('../experiments/contextual'):\n",
    "    os.mkdir('../experiments/contextual')\n",
    "RESULTS_FILE_PATH = f'../experiments/contextual/results.csv'  # 'results_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "embeddings_model_dtype = GloVe\n",
    "embeddings_model_path = GV_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glove'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = os.path.basename(os.path.split(embeddings_model_path)[0])\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "embeddings_model = embeddings_model_dtype.load(embeddings_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "conll = {split: CoNLL2003(CONLL2003_DATA_PATH, split=split) for split in ['train', 'validation', 'test']}\n",
    "sst = {split: SST(SST_DATA_PATH, split=split, binary=True) for split in ['train', 'validation', 'test']}\n",
    "sts = {split: STS(STS_DATA_PATH, split=split) for split in ['train', 'validation', 'test']}\n",
    "ng = {split: NewsGroups(split=split) for split in ['train', 'validation', 'test']}\n",
    "welfake = {split: WELFake(WELFAKE_DATA_PATH, split=split) for split in ['train', 'validation', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### CoNLL 2003\n",
    "\n",
    "Evaluate on token classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "corpus = 'CoNLL-2003'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "conll['train']._data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class TokenClassification(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size: int = 512, kernel_size: int = 5):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_size)\n",
    "        self.conv1d = nn.Conv1d(input_size, hidden_size, kernel_size, padding='same', bias=False)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.cls_head = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # \n",
    "        x = self.dropout(x)\n",
    "        #\n",
    "        h = self.conv1d(x.transpose(-1, -2))  # self.norm(x).transpose(-1, -2)\n",
    "        # Non-linear activation\n",
    "        h = F.gelu(h)\n",
    "        # Dropout\n",
    "        h = self.dropout(h)\n",
    "        # Apply last linear projection\n",
    "        y = self.cls_head(h.transpose(-1, -2))\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "le = conll['train'].get_label_transformer()\n",
    "for label, le_ in le.items():\n",
    "    print(label, le_.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = {label: lw_.to(device) for label, lw_ in conll['train'].get_label_weights().items()}\n",
    "for label, lw_ in lw.items():\n",
    "    print(label, lw_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task = 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = TokenClassification(300, len(le[task].classes_))  # 300, 300, *, 3\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.001  # 0.0005\n",
    "batch_size = 512  # 128\n",
    "n_epochs = 64  # 10\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def collate(mini_batch):\n",
    "    # Get the length of the longest sentence\n",
    "    max_sequence_len = max(len(sample) for sample in mini_batch)\n",
    "    # Create an input tensor with all zero values\n",
    "    input_embeds = np.zeros((len(mini_batch), max_sequence_len, 300))\n",
    "    #\n",
    "    valid_mask = np.zeros((len(mini_batch), max_sequence_len))\n",
    "    # Create a target output matrix with all -100 (PyTorch ignores this value by default)\n",
    "    output_lbl = np.full((len(mini_batch), max_sequence_len), -100)\n",
    "    # Fill the tensor and the matrix\n",
    "    for i, sample in enumerate(mini_batch):\n",
    "        for j, token in enumerate(sample):\n",
    "            # Manage missing tokens in vocabulary\n",
    "            input_embeds[i, j] = embeddings_model[token['token'].lower()]\n",
    "            output_lbl[i, j] = le[task].transform([token[task]])[0]\n",
    "        valid_mask[i, :len(sample)] = 1.0\n",
    "    # Convert to PyTorch tensor\n",
    "    input_embeds = torch.tensor(input_embeds, dtype=torch.float, device=device)\n",
    "    valid_mask = torch.tensor(valid_mask, dtype=torch.float, device=device)\n",
    "    output_lbl = torch.tensor(output_lbl, device=device)\n",
    "\n",
    "    return input_embeds, output_lbl\n",
    "    # return input_embeds, valid_mask, output_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_loader = {\n",
    "    split: torch.utils.data.DataLoader(\n",
    "        data, batch_size=batch_size, collate_fn=collate, shuffle=split == 'train'\n",
    "    )\n",
    "    for split, data in conll.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join('../experiments/contextual/', f'{model_id}_{corpus}_{task}_{datetime.now()}.ckpt')\n",
    "\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Accumulator of loss\n",
    "history = []\n",
    "validation_history = []\n",
    "best_validation_loss = torch.tensor(float('inf'), device=device)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, steps_per_epoch=len(data_loader['train']), epochs=n_epochs, anneal_strategy='linear', pct_start=0.05)\n",
    "\n",
    "estop_counter = 0\n",
    "\n",
    "# Iterate over epochs\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Starting epoch {i + 1}/{n_epochs}\")\n",
    "    # Iterate over training batches\n",
    "    # for embeds, lbl in tqdm(data_loader['train']):\n",
    "    for embeds, lbl in tqdm(data_loader['train']):\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds)\n",
    "        # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "        logits = logits.reshape(-1, len(le[task].classes_))\n",
    "        # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "        lbl = lbl.reshape(-1)\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(logits, lbl)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # Save loss\n",
    "        history.append(loss.detach())\n",
    "    # Disable gradients\n",
    "    with torch.no_grad():\n",
    "        print(f\"Starting validation epoch {i + 1}/{n_epochs}\")\n",
    "        # Set in evaluation mode\n",
    "        model.eval()\n",
    "        # Init validation loss accumulator\n",
    "        loss = []\n",
    "        # Iterate over validation batches\n",
    "        for embeds, lbl in tqdm(data_loader['validation']):\n",
    "            # Move input and output to target device\n",
    "            embeds = embeds.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "            # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "            logits = model(embeds)\n",
    "            # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "            logits = logits.reshape(-1, len(le[task].classes_))\n",
    "            # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "            lbl = lbl.reshape(-1)\n",
    "            # Compute loss\n",
    "            loss.append(F.cross_entropy(logits, lbl))\n",
    "        # Aggregate validation loss\n",
    "        validation_history.append(torch.tensor(loss, device=device).mean())\n",
    "        # Check if validation loss has improved\n",
    "        if validation_history[-1] <= best_validation_loss:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_validation_loss = validation_history[-1]\n",
    "            estop_counter = 0\n",
    "        else:\n",
    "            estop_counter += 1\n",
    "        # Restore training mode\n",
    "        model.train()\n",
    "    if estop_counter >= 5:\n",
    "        break\n",
    "        \n",
    "# Restore best weights\n",
    "if os.path.exists(path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "history = [loss.cpu().item() for loss in history]\n",
    "validation_history = [loss.cpu().item() for loss in validation_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(history)), history, label='Training loss')\n",
    "plt.plot(range(len(data_loader['train']) - 1, len(history), len(data_loader['train'])), validation_history, label='Validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim([0.0, len(history)])\n",
    "plt.ylim([0.0, 4.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set model in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "split = 'validation'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "split = 'test'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task = 'chunk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = TokenClassification(300, len(le[task].classes_))  # 300, 300, *, 3\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.001  # 0.0005\n",
    "batch_size = 512  # 128\n",
    "n_epochs = 64  # 10\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def collate(mini_batch):\n",
    "    # Get the length of the longest sentence\n",
    "    max_sequence_len = max(len(sample) for sample in mini_batch)\n",
    "    # Create an input tensor with all zero values\n",
    "    input_embeds = np.zeros((len(mini_batch), max_sequence_len, 300))\n",
    "    #\n",
    "    valid_mask = np.zeros((len(mini_batch), max_sequence_len))\n",
    "    # Create a target output matrix with all -100 (PyTorch ignores this value by default)\n",
    "    output_lbl = np.full((len(mini_batch), max_sequence_len), -100)\n",
    "    # Fill the tensor and the matrix\n",
    "    for i, sample in enumerate(mini_batch):\n",
    "        for j, token in enumerate(sample):\n",
    "            # Manage missing tokens in vocabulary\n",
    "            input_embeds[i, j] = embeddings_model[token['token'].lower()]\n",
    "            try:\n",
    "                output_lbl[i, j] = le[task].transform([token[task]])[0]\n",
    "            except ValueError:\n",
    "                pass\n",
    "        valid_mask[i, :len(sample)] = 1.0\n",
    "    # Convert to PyTorch tensor\n",
    "    input_embeds = torch.tensor(input_embeds, dtype=torch.float, device=device)\n",
    "    valid_mask = torch.tensor(valid_mask, dtype=torch.float, device=device)\n",
    "    output_lbl = torch.tensor(output_lbl, device=device)\n",
    "\n",
    "    return input_embeds, output_lbl\n",
    "    # return input_embeds, valid_mask, output_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_loader = {\n",
    "    split: torch.utils.data.DataLoader(\n",
    "        data, batch_size=batch_size, collate_fn=collate, shuffle=split == 'train'\n",
    "    )\n",
    "    for split, data in conll.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join('../experiments/contextual/', f'{model_id}_{corpus}_{task}_{datetime.now()}.ckpt')\n",
    "\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Accumulator of loss\n",
    "history = []\n",
    "validation_history = []\n",
    "best_validation_loss = torch.tensor(float('inf'), device=device)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, steps_per_epoch=len(data_loader['train']), epochs=n_epochs, anneal_strategy='linear', pct_start=0.05)\n",
    "\n",
    "estop_counter = 0\n",
    "\n",
    "# Iterate over epochs\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Starting epoch {i + 1}/{n_epochs}\")\n",
    "    # Iterate over training batches\n",
    "    for embeds, lbl in tqdm(data_loader['train']):\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds)\n",
    "        # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "        logits = logits.reshape(-1, len(le[task].classes_))\n",
    "        # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "        lbl = lbl.reshape(-1)\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(logits, lbl)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # Save loss\n",
    "        history.append(loss.detach())\n",
    "    # Disable gradients\n",
    "    with torch.no_grad():\n",
    "        print(f\"Starting validation epoch {i + 1}/{n_epochs}\")\n",
    "        # Set in evaluation mode\n",
    "        model.eval()\n",
    "        # Init validation loss accumulator\n",
    "        loss = []\n",
    "        # Iterate over validation batches\n",
    "        for embeds, lbl in tqdm(data_loader['validation']):\n",
    "            # Move input and output to target device\n",
    "            embeds = embeds.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "            # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "            logits = model(embeds)\n",
    "            # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "            logits = logits.reshape(-1, len(le[task].classes_))\n",
    "            # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "            lbl = lbl.reshape(-1)\n",
    "            # Compute loss\n",
    "            loss.append(F.cross_entropy(logits, lbl))\n",
    "        # Aggregate validation loss\n",
    "        validation_history.append(torch.tensor(loss, device=device).mean())\n",
    "        # Check if validation loss has improved\n",
    "        if validation_history[-1] <= best_validation_loss:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_validation_loss = validation_history[-1]\n",
    "            estop_counter = 0\n",
    "        else:\n",
    "            estop_counter += 1\n",
    "        # Restore training mode\n",
    "        model.train()\n",
    "    if estop_counter >= 5:\n",
    "        break\n",
    "        \n",
    "# Restore best weights\n",
    "if os.path.exists(path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "history = [loss.cpu().item() for loss in history]\n",
    "validation_history = [loss.cpu().item() for loss in validation_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(history)), history, label='Training loss')\n",
    "plt.plot(range(len(data_loader['train']) - 1, len(history), len(data_loader['train'])), validation_history, label='Validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim([0.0, len(history)])\n",
    "plt.ylim([0.0, 4.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set model in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "split = 'validation'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "split = 'test'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task = 'ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = TokenClassification(300, len(le[task].classes_))  # 300, 300, *, 3\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.001  # 0.0005\n",
    "batch_size = 512  # 128\n",
    "n_epochs = 64  # 10\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def collate(mini_batch):\n",
    "    # Get the length of the longest sentence\n",
    "    max_sequence_len = max(len(sample) for sample in mini_batch)\n",
    "    # Create an input tensor with all zero values\n",
    "    input_embeds = np.zeros((len(mini_batch), max_sequence_len, 300))\n",
    "    #\n",
    "    valid_mask = np.zeros((len(mini_batch), max_sequence_len))\n",
    "    # Create a target output matrix with all -100 (PyTorch ignores this value by default)\n",
    "    output_lbl = np.full((len(mini_batch), max_sequence_len), -100)\n",
    "    # Fill the tensor and the matrix\n",
    "    for i, sample in enumerate(mini_batch):\n",
    "        for j, token in enumerate(sample):\n",
    "            # Manage missing tokens in vocabulary\n",
    "            input_embeds[i, j] = embeddings_model[token['token'].lower()]\n",
    "            output_lbl[i, j] = le[task].transform([token[task]])[0]\n",
    "        valid_mask[i, :len(sample)] = 1.0\n",
    "    # Convert to PyTorch tensor\n",
    "    input_embeds = torch.tensor(input_embeds, dtype=torch.float, device=device)\n",
    "    valid_mask = torch.tensor(valid_mask, dtype=torch.float, device=device)\n",
    "    output_lbl = torch.tensor(output_lbl, device=device)\n",
    "\n",
    "    return input_embeds, output_lbl\n",
    "    # return input_embeds, valid_mask, output_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_loader = {\n",
    "    split: torch.utils.data.DataLoader(\n",
    "        data, batch_size=batch_size, collate_fn=collate, shuffle=split == 'train'\n",
    "    )\n",
    "    for split, data in conll.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join('../experiments/contextual/', f'{model_id}_{corpus}_{task}_{datetime.now()}.ckpt')\n",
    "\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Accumulator of loss\n",
    "history = []\n",
    "validation_history = []\n",
    "best_validation_loss = torch.tensor(float('inf'), device=device)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, steps_per_epoch=len(data_loader['train']), epochs=n_epochs, anneal_strategy='linear', pct_start=0.05)\n",
    "\n",
    "estop_counter = 0\n",
    "\n",
    "# Iterate over epochs\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Starting epoch {i + 1}/{n_epochs}\")\n",
    "    # Iterate over training batches\n",
    "    for embeds, lbl in tqdm(data_loader['train']):\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds)\n",
    "        # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "        logits = logits.reshape(-1, len(le[task].classes_))\n",
    "        # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "        lbl = lbl.reshape(-1)\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(logits, lbl)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # Save loss\n",
    "        history.append(loss.detach())\n",
    "    # Disable gradients\n",
    "    with torch.no_grad():\n",
    "        print(f\"Starting validation epoch {i + 1}/{n_epochs}\")\n",
    "        # Set in evaluation mode\n",
    "        model.eval()\n",
    "        # Init validation loss accumulator\n",
    "        loss = []\n",
    "        # Iterate over validation batches\n",
    "        for embeds, lbl in tqdm(data_loader['validation']):\n",
    "            # Move input and output to target device\n",
    "            embeds = embeds.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "            # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "            logits = model(embeds)\n",
    "            # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "            logits = logits.reshape(-1, len(le[task].classes_))\n",
    "            # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "            lbl = lbl.reshape(-1)\n",
    "            # Compute loss\n",
    "            loss.append(F.cross_entropy(logits, lbl))\n",
    "        # Aggregate validation loss\n",
    "        validation_history.append(torch.tensor(loss, device=device).mean())\n",
    "        # Check if validation loss has improved\n",
    "        if validation_history[-1] <= best_validation_loss:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_validation_loss = validation_history[-1]\n",
    "            estop_counter = 0\n",
    "        else:\n",
    "            estop_counter += 1\n",
    "        # Restore training mode\n",
    "        model.train()\n",
    "    if estop_counter >= 5:\n",
    "        break\n",
    "        \n",
    "# Restore best weights\n",
    "if os.path.exists(path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "history = [loss.cpu().item() for loss in history]\n",
    "validation_history = [loss.cpu().item() for loss in validation_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(history)), history, label='Training loss')\n",
    "plt.plot(range(len(data_loader['train']) - 1, len(history), len(data_loader['train'])), validation_history, label='Validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim([0.0, len(history)])\n",
    "plt.ylim([0.0, 4.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set model in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "split = 'validation'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "split = 'test'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "corpus = 'SST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': \"The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\",\n",
       "  'sentiment': 'positive'},\n",
       " {'sequence': \"The gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\\\/director Peter Jackson 's expanded vision of J.R.R. Tolkien 's Middle-earth .\",\n",
       "  'sentiment': 'positive'},\n",
       " {'sequence': 'Singer\\\\/composer Bryan Adams contributes a slew of songs -- a few potential hits , a few more simply intrusive to the story -- but the whole package certainly captures the intended , er , spirit of the piece .',\n",
       "  'sentiment': 'positive'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst['train']._data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "embeddings_model.fit_sif_embedding([sample['sequence'] for sample in sst['train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass SequenceClassification(nn.Module):\\n    def __init__(self, input_size, output_size, hidden_size: int = 512, kernel_size: int = 5):\\n        super().__init__()\\n        self.norm = nn.LayerNorm(input_size)\\n        self.conv1d = nn.Conv1d(input_size, hidden_size, kernel_size, padding='same')\\n        self.dropout = nn.Dropout(0.1)\\n        self.cls_head = nn.Linear(hidden_size, output_size)\\n        \\n    def forward(self, x, w):\\n        # \\n        x = self.dropout(x)\\n        #\\n        h = self.conv1d(self.norm(x).transpose(-1, -2))\\n        # Non-linear activation\\n        h = F.gelu(h)\\n        # Dropout\\n        h = self.dropout(h)\\n        # Weighted sum\\n        h = torch.einsum('btd,bt->bd', h.transpose(-1, -2), w)\\n        # Apply last linear projection\\n        y = self.cls_head(h)\\n\\n        return y\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple, List, Set\n",
    "\n",
    "class Conv1D(nn.Module):\n",
    "    \"\"\"\n",
    "    1D-convolutional layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2).\n",
    "    Basically works like a linear layer but the weights are transposed.\n",
    "    Args:\n",
    "        nf (:obj:`int`): The number of output features.\n",
    "        nx (:obj:`int`): The number of input features.\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nf, nx):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        w = torch.empty(nx, nf)\n",
    "        nn.init.normal_(w, std=0.02)\n",
    "        self.weight = nn.Parameter(w)\n",
    "        self.bias = nn.Parameter(torch.zeros(nf))\n",
    "\n",
    "    def forward(self, x):\n",
    "        size_out = x.size()[:-1] + (self.nf,)\n",
    "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
    "        x = x.view(*size_out)\n",
    "        return x\n",
    "\n",
    "\n",
    "def find_pruneable_heads_and_indices(heads: List[int],\n",
    "                                     n_heads: int,\n",
    "                                     head_size: int,\n",
    "                                     already_pruned_heads: Set[int]) -> Tuple[Set[int], torch.LongTensor]:\n",
    "    \"\"\"\n",
    "    Finds the heads and their indices taking :obj:`already_pruned_heads` into account.\n",
    "    Args:\n",
    "        heads (:obj:`List[int]`): List of the indices of heads to prune.\n",
    "        n_heads (:obj:`int`): The number of heads in the model.\n",
    "        head_size (:obj:`int`): The size of each head.\n",
    "        already_pruned_heads (:obj:`Set[int]`): A set of already pruned heads.\n",
    "    Returns:\n",
    "        :obj:`Tuple[Set[int], torch.LongTensor]`: A tuple with the remaining heads and their corresponding indices.\n",
    "\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "    mask = torch.ones(n_heads, head_size)\n",
    "    heads = set(heads) - already_pruned_heads  # Convert to set and remove already pruned heads\n",
    "    for head in heads:\n",
    "        # Compute how many pruned heads are before the head and move the index accordingly\n",
    "        head = head - sum(1 if h < head else 0 for h in already_pruned_heads)\n",
    "        mask[head] = 0\n",
    "    mask = mask.view(-1).contiguous().eq(1)\n",
    "    index: torch.LongTensor = torch.arange(len(mask))[mask].long()\n",
    "    return heads, index\n",
    "\n",
    "\n",
    "def prune_conv1d_layer(layer: Conv1D, index: torch.LongTensor, dim: int = 1) -> Conv1D:\n",
    "    \"\"\"\n",
    "    Prune a Conv1D layer to keep only entries in index. A Conv1D work as a Linear layer (see e.g. BERT) but the weights\n",
    "    are transposed.\n",
    "    Used to remove heads.\n",
    "    Args:\n",
    "        layer (:class:`~transformers.modeling_utils.Conv1D`): The layer to prune.\n",
    "        index (:obj:`torch.LongTensor`): The indices to keep in the layer.\n",
    "        dim (:obj:`int`, `optional`, defaults to 1): The dimension on which to keep the indices.\n",
    "    Returns:\n",
    "        :class:`~transformers.modeling_utils.Conv1D`: The pruned layer as a new layer with :obj:`requires_grad=True`.\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "    index = index.to(layer.weight.device)\n",
    "    W = layer.weight.index_select(dim, index).clone().detach()\n",
    "    if dim == 0:\n",
    "        b = layer.bias.clone().detach()\n",
    "    else:\n",
    "        b = layer.bias[index].clone().detach()\n",
    "    new_size = list(layer.weight.size())\n",
    "    new_size[dim] = len(index)\n",
    "    new_layer = Conv1D(new_size[1], new_size[0]).to(layer.weight.device)\n",
    "    new_layer.weight.requires_grad = False\n",
    "    new_layer.weight.copy_(W.contiguous())\n",
    "    new_layer.weight.requires_grad = True\n",
    "    new_layer.bias.requires_grad = False\n",
    "    new_layer.bias.copy_(b.contiguous())\n",
    "    new_layer.bias.requires_grad = True\n",
    "    return new_layer\n",
    "\n",
    "\n",
    "class AttentionAvgPooling(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_hidden: int = 512,\n",
    "                 n_heads: int = 8,\n",
    "                 max_positions: int = 1024,\n",
    "                 p_dropout: float = 0.1,\n",
    "                 scale_attn_weights: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = n_hidden\n",
    "        self.num_heads = n_heads\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "        self.split_size = self.embed_dim\n",
    "        assert self.head_dim * self.num_heads == self.embed_dim, f\"`embed_dim` must be divisible by num_heads \" \\\n",
    "                                                                 f\"(got `embed_dim`: {self.embed_dim} and \" \\\n",
    "                                                                 f\"`num_heads`: {self.num_heads}).\"\n",
    "\n",
    "        self.scale_attn_weights = scale_attn_weights\n",
    "\n",
    "        self.qkv_attn = Conv1D(3 * self.embed_dim, self.embed_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        heads, index = find_pruneable_heads_and_indices(heads, self.num_heads, self.head_dim, self.pruned_heads)\n",
    "        index_attn = torch.cat([index, index + self.split_size, index + (2 * self.split_size)])\n",
    "\n",
    "        # Prune conv1d layers\n",
    "        self.qkv_attn = prune_conv1d_layer(self.qkv_attn, index_attn, dim=1)\n",
    "\n",
    "        # Update hyper params\n",
    "        self.split_size = (self.split_size // self.num_heads) * (self.num_heads - len(heads))\n",
    "        self.num_heads = self.num_heads - len(heads)\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    def _attn(self, query, key, value, attention_mask=None):\n",
    "        attn_weights = torch.matmul(query, key.transpose(-1, -2))\n",
    "        attn_weights = attn_weights / (float(value.size(-1)) ** 0.5)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask\n",
    "            attn_weights = attn_weights + attention_mask\n",
    "\n",
    "        attn_weights = nn.Softmax(dim=-1)(attn_weights)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        attn_output = torch.matmul(attn_weights, value)\n",
    "\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "    @staticmethod\n",
    "    def _split_heads(tensor, num_heads, attn_head_size):\n",
    "        new_shape = tensor.size()[:-1] + (num_heads, attn_head_size)\n",
    "        tensor = tensor.view(*new_shape)\n",
    "        return tensor.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
    "\n",
    "    @staticmethod\n",
    "    def _merge_heads(tensor, num_heads, attn_head_size):\n",
    "        tensor = tensor.permute(0, 2, 1, 3).contiguous()\n",
    "        new_shape = tensor.size()[:-2] + (num_heads * attn_head_size,)\n",
    "        return tensor.view(new_shape)\n",
    "\n",
    "    def forward(self,\n",
    "                hidden_states,\n",
    "                attention_mask=None,\n",
    "                return_attention_weights=False):\n",
    "\n",
    "        query, key, value = self.qkv_attn(hidden_states).split(self.split_size, dim=2)\n",
    "\n",
    "        # Query is averaged to obtain pooling\n",
    "        query = self._split_heads(query, self.num_heads, self.head_dim).mean(-2, keepdims=True)\n",
    "        key = self._split_heads(key, self.num_heads, self.head_dim)\n",
    "        value = self._split_heads(value, self.num_heads, self.head_dim)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = (1.0 - attention_mask) * -1e+6\n",
    "            attention_mask = attention_mask[:, None, None, :]\n",
    "\n",
    "        attn_output, attn_weights = self._attn(query, key, value, attention_mask)\n",
    "\n",
    "        attn_output = self._merge_heads(attn_output, self.num_heads, self.head_dim)\n",
    "\n",
    "        if not return_attention_weights:\n",
    "            return attn_output  # attention\n",
    "        else:\n",
    "            attn_weights = self._merge_heads(attn_weights, self.num_heads, self.head_dim)\n",
    "            return attn_output, attn_weights\n",
    "\n",
    "\n",
    "# class GPT2Attention(nn.Module):\n",
    "# https://github.com/huggingface/transformers/blob/master/src/transformers/models/gpt2/modeling_gpt2.py\n",
    "\n",
    "\n",
    "class SequenceClassification(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size: int = 512, kernel_size: int = 5):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_size)\n",
    "        self.conv1d = nn.Conv1d(input_size, hidden_size, kernel_size, padding='same')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_head = nn.Linear(hidden_size, output_size)\n",
    "        ##\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.out_norm = nn.LayerNorm(hidden_size)\n",
    "        self.pool = AttentionAvgPooling()\n",
    "        \n",
    "    def forward(self, x, w):\n",
    "        # \n",
    "        x = self.dropout(x)\n",
    "        #\n",
    "        h = self.conv1d(x.transpose(-1, -2)).transpose(-1, -2)  # self.norm(x).transpose(-1, -2)\n",
    "        ##\n",
    "        h = self.norm(h)\n",
    "        # Non-linear activation\n",
    "        h = F.gelu(h)\n",
    "        \n",
    "        # Dropout\n",
    "        h = self.dropout(h)\n",
    "        # Weighted sum\n",
    "        # h = torch.einsum('btd,bt->bd', h, w)\n",
    "        # Apply last linear projection\n",
    "        # h = self.out_head(h)\n",
    "        ##\n",
    "        h = self.pool(h, w)\n",
    "        h = self.out_norm(h)\n",
    "        y = self.out_head(h)\n",
    "\n",
    "        return y\n",
    "\n",
    "'''\n",
    "class SequenceClassification(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size: int = 512, kernel_size: int = 5):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_size)\n",
    "        self.conv1d = nn.Conv1d(input_size, hidden_size, kernel_size, padding='same')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.cls_head = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, w):\n",
    "        # \n",
    "        x = self.dropout(x)\n",
    "        #\n",
    "        h = self.conv1d(self.norm(x).transpose(-1, -2))\n",
    "        # Non-linear activation\n",
    "        h = F.gelu(h)\n",
    "        # Dropout\n",
    "        h = self.dropout(h)\n",
    "        # Weighted sum\n",
    "        h = torch.einsum('btd,bt->bd', h.transpose(-1, -2), w)\n",
    "        # Apply last linear projection\n",
    "        y = self.cls_head(h)\n",
    "\n",
    "        return y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment ['negative' 'positive']\n"
     ]
    }
   ],
   "source": [
    "le = sst['train'].get_label_transformer()\n",
    "for label, le_ in le.items():\n",
    "    print(label, le_.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment tensor([1.1226, 1.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "lw = {label: lw_.to(device) for label, lw_ in sst['train'].get_label_weights().items()}\n",
    "for label, lw_ in lw.items():\n",
    "    print(label, lw_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task = 'sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassification(\n",
       "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (conv1d): Conv1d(300, 512, kernel_size=(5,), stride=(1,), padding=same)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_head): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (out_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (pool): AttentionAvgPooling(\n",
       "    (qkv_attn): Conv1D()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequenceClassification(300, len(le[task].classes_))    \n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 512\n",
    "n_epochs = 64\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr, weight_decay=0.2)\n",
    "# optimizer = torch.optim.RMSprop(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def collate(mini_batch):\n",
    "    # Tokenise sequences \n",
    "    sequences = embeddings_model.tokenise([sample['sequence'] for sample in mini_batch])\n",
    "    # Get the length of the longest sentence\n",
    "    max_sequence_len = max(len(sample) for sample in sequences)\n",
    "    # Create an input tensor with all zero values\n",
    "    input_embeds = np.zeros((len(mini_batch), max_sequence_len, 300))\n",
    "    # Create weights tensor with all zero values\n",
    "    token_weights = np.zeros((len(mini_batch), max_sequence_len))\n",
    "    valid_mask = np.zeros((len(mini_batch), max_sequence_len))\n",
    "    # Create a target output matrix with all -100 (PyTorch ignores this value by default)\n",
    "    output_lbl = np.full((len(mini_batch), 1), -100)\n",
    "    # Fill the tensor and the matrix\n",
    "    for i, sample in enumerate(sequences):\n",
    "        for j, token in enumerate(sample):\n",
    "            # Manage missing tokens in vocabulary\n",
    "            input_embeds[i, j] = embeddings_model[token.lower()]\n",
    "        token_weights[i, :len(sample)] = embeddings_model.sif_embedding_model.word_weights[embeddings_model.encode(sample, backend='numpy')]\n",
    "        valid_mask[i, :len(sample)] = 1.0\n",
    "        output_lbl[i] = le[task].transform([mini_batch[i][task]])[0]\n",
    "    # Convert to PyTorch tensor\n",
    "    input_embeds = torch.tensor(input_embeds, dtype=torch.float, device=device)\n",
    "    token_weights = torch.tensor(token_weights, dtype=torch.float, device=device)\n",
    "    valid_mask = torch.tensor(valid_mask, dtype=torch.float, device=device)\n",
    "    output_lbl = torch.tensor(output_lbl, device=device)\n",
    "\n",
    "    # return input_embeds, token_weights, output_lbl\n",
    "    return input_embeds, valid_mask, output_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_loader = {\n",
    "    split: torch.utils.data.DataLoader(\n",
    "        data, batch_size=batch_size, collate_fn=collate, shuffle=split == 'train'\n",
    "    )\n",
    "    for split, data in sst.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 2/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 3/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 3/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 4/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 4/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 5/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 5/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 6/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 6/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 7/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 7/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 8/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 8/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.59it/s]\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join('../experiments/contextual/', f'{model_id}_{corpus}_{task}_{datetime.now()}.ckpt')\n",
    "\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Accumulator of loss\n",
    "history = []\n",
    "validation_history = []\n",
    "best_validation_loss = torch.tensor(float('inf'), device=device)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, steps_per_epoch=len(data_loader['train']), epochs=n_epochs, anneal_strategy='linear', pct_start=0.05)\n",
    "\n",
    "estop_counter = 0\n",
    "\n",
    "# Iterate over epochs\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Starting epoch {i + 1}/{n_epochs}\")\n",
    "    # Iterate over training batches\n",
    "    for embeds, weights, lbl in tqdm(data_loader['train']):\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        weights = weights.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds, weights)\n",
    "        # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "        logits = logits.reshape(-1, len(le[task].classes_))\n",
    "        # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "        lbl = lbl.reshape(-1)\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(logits, lbl)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # Save loss\n",
    "        history.append(loss)\n",
    "    # Disable gradients\n",
    "    with torch.no_grad():\n",
    "        print(f\"Starting validation epoch {i + 1}/{n_epochs}\")\n",
    "        # Set in evaluation mode\n",
    "        model.eval()\n",
    "        # Init validation loss accumulator\n",
    "        loss = []\n",
    "        # Iterate over validation batches\n",
    "        for embeds, weights, lbl in tqdm(data_loader['validation']):\n",
    "            # Move input and output to target device\n",
    "            embeds = embeds.to(device)\n",
    "            weights = weights.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "            # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "            logits = model(embeds, weights)\n",
    "            # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "            logits = logits.reshape(-1, len(le[task].classes_))\n",
    "            # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "            lbl = lbl.reshape(-1)\n",
    "            # Compute loss\n",
    "            loss.append(F.cross_entropy(logits, lbl))\n",
    "        # Aggregate validation loss\n",
    "        validation_history.append(torch.tensor(loss, device=device).mean())\n",
    "        # Check if validation loss has improved\n",
    "        if validation_history[-1] <= best_validation_loss:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_validation_loss = validation_history[-1]\n",
    "            estop_counter = 0\n",
    "        else:\n",
    "            estop_counter += 1\n",
    "        # Restore training mode\n",
    "        model.train()\n",
    "    if estop_counter >= 5:\n",
    "        break\n",
    "        \n",
    "# Restore best weights\n",
    "if os.path.exists(path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "history = [loss.cpu().item() for loss in history]\n",
    "validation_history = [loss.cpu().item() for loss in validation_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(history)), history, label='Training loss')\n",
    "plt.plot(range(len(data_loader['train']) - 1, len(history), len(data_loader['train'])), validation_history, label='Validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim([0.0, len(history)])\n",
    "plt.ylim([0.0, 4.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassification(\n",
       "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (conv1d): Conv1d(300, 512, kernel_size=(5,), stride=(1,), padding=same)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_head): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (out_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (pool): AttentionAvgPooling(\n",
       "    (qkv_attn): Conv1D()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.45      0.56      1049\n",
      "    positive       0.61      0.84      0.71      1076\n",
      "\n",
      "    accuracy                           0.65      2125\n",
      "   macro avg       0.68      0.65      0.64      2125\n",
      "weighted avg       0.68      0.65      0.64      2125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "split = 'validation'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, weights, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        weights = weights.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds, weights)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)[:, 1]\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.46      0.56       512\n",
      "    positive       0.61      0.82      0.70       532\n",
      "\n",
      "    accuracy                           0.65      1044\n",
      "   macro avg       0.66      0.64      0.63      1044\n",
      "weighted avg       0.66      0.65      0.63      1044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "split = 'test'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, weights, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        weights = weights.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds, weights)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)[:, 1]\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### STS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "corpus = 'STS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sts['train']._data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "embeddings_model.fit_sif_embedding([sample[key] for sample in sts['train'] for key in ['sequence_a', 'sequence_b']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Set\n",
    "\n",
    "class Conv1D(nn.Module):\n",
    "    \"\"\"\n",
    "    1D-convolutional layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2).\n",
    "    Basically works like a linear layer but the weights are transposed.\n",
    "    Args:\n",
    "        nf (:obj:`int`): The number of output features.\n",
    "        nx (:obj:`int`): The number of input features.\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nf, nx):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        w = torch.empty(nx, nf)\n",
    "        nn.init.normal_(w, std=0.02)\n",
    "        self.weight = nn.Parameter(w)\n",
    "        self.bias = nn.Parameter(torch.zeros(nf))\n",
    "\n",
    "    def forward(self, x):\n",
    "        size_out = x.size()[:-1] + (self.nf,)\n",
    "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
    "        x = x.view(*size_out)\n",
    "        return x\n",
    "\n",
    "\n",
    "def find_pruneable_heads_and_indices(heads: List[int],\n",
    "                                     n_heads: int,\n",
    "                                     head_size: int,\n",
    "                                     already_pruned_heads: Set[int]) -> Tuple[Set[int], torch.LongTensor]:\n",
    "    \"\"\"\n",
    "    Finds the heads and their indices taking :obj:`already_pruned_heads` into account.\n",
    "    Args:\n",
    "        heads (:obj:`List[int]`): List of the indices of heads to prune.\n",
    "        n_heads (:obj:`int`): The number of heads in the model.\n",
    "        head_size (:obj:`int`): The size of each head.\n",
    "        already_pruned_heads (:obj:`Set[int]`): A set of already pruned heads.\n",
    "    Returns:\n",
    "        :obj:`Tuple[Set[int], torch.LongTensor]`: A tuple with the remaining heads and their corresponding indices.\n",
    "\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "    mask = torch.ones(n_heads, head_size)\n",
    "    heads = set(heads) - already_pruned_heads  # Convert to set and remove already pruned heads\n",
    "    for head in heads:\n",
    "        # Compute how many pruned heads are before the head and move the index accordingly\n",
    "        head = head - sum(1 if h < head else 0 for h in already_pruned_heads)\n",
    "        mask[head] = 0\n",
    "    mask = mask.view(-1).contiguous().eq(1)\n",
    "    index: torch.LongTensor = torch.arange(len(mask))[mask].long()\n",
    "    return heads, index\n",
    "\n",
    "\n",
    "def prune_conv1d_layer(layer: Conv1D, index: torch.LongTensor, dim: int = 1) -> Conv1D:\n",
    "    \"\"\"\n",
    "    Prune a Conv1D layer to keep only entries in index. A Conv1D work as a Linear layer (see e.g. BERT) but the weights\n",
    "    are transposed.\n",
    "    Used to remove heads.\n",
    "    Args:\n",
    "        layer (:class:`~transformers.modeling_utils.Conv1D`): The layer to prune.\n",
    "        index (:obj:`torch.LongTensor`): The indices to keep in the layer.\n",
    "        dim (:obj:`int`, `optional`, defaults to 1): The dimension on which to keep the indices.\n",
    "    Returns:\n",
    "        :class:`~transformers.modeling_utils.Conv1D`: The pruned layer as a new layer with :obj:`requires_grad=True`.\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "    index = index.to(layer.weight.device)\n",
    "    W = layer.weight.index_select(dim, index).clone().detach()\n",
    "    if dim == 0:\n",
    "        b = layer.bias.clone().detach()\n",
    "    else:\n",
    "        b = layer.bias[index].clone().detach()\n",
    "    new_size = list(layer.weight.size())\n",
    "    new_size[dim] = len(index)\n",
    "    new_layer = Conv1D(new_size[1], new_size[0]).to(layer.weight.device)\n",
    "    new_layer.weight.requires_grad = False\n",
    "    new_layer.weight.copy_(W.contiguous())\n",
    "    new_layer.weight.requires_grad = True\n",
    "    new_layer.bias.requires_grad = False\n",
    "    new_layer.bias.copy_(b.contiguous())\n",
    "    new_layer.bias.requires_grad = True\n",
    "    return new_layer\n",
    "\n",
    "\n",
    "class AttentionAvgPooling(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_hidden: int = 512,\n",
    "                 n_heads: int = 8,\n",
    "                 max_positions: int = 1024,\n",
    "                 p_dropout: float = 0.1,\n",
    "                 scale_attn_weights: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = n_hidden\n",
    "        self.num_heads = n_heads\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "        self.split_size = self.embed_dim\n",
    "        assert self.head_dim * self.num_heads == self.embed_dim, f\"`embed_dim` must be divisible by num_heads \" \\\n",
    "                                                                 f\"(got `embed_dim`: {self.embed_dim} and \" \\\n",
    "                                                                 f\"`num_heads`: {self.num_heads}).\"\n",
    "\n",
    "        self.scale_attn_weights = scale_attn_weights\n",
    "\n",
    "        self.qkv_attn = Conv1D(3 * self.embed_dim, self.embed_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        heads, index = find_pruneable_heads_and_indices(heads, self.num_heads, self.head_dim, self.pruned_heads)\n",
    "        index_attn = torch.cat([index, index + self.split_size, index + (2 * self.split_size)])\n",
    "\n",
    "        # Prune conv1d layers\n",
    "        self.qkv_attn = prune_conv1d_layer(self.qkv_attn, index_attn, dim=1)\n",
    "\n",
    "        # Update hyper params\n",
    "        self.split_size = (self.split_size // self.num_heads) * (self.num_heads - len(heads))\n",
    "        self.num_heads = self.num_heads - len(heads)\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    def _attn(self, query, key, value, attention_mask=None):\n",
    "        attn_weights = torch.matmul(query, key.transpose(-1, -2))\n",
    "        attn_weights = attn_weights / (float(value.size(-1)) ** 0.5)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask\n",
    "            attn_weights = attn_weights + attention_mask\n",
    "\n",
    "        attn_weights = nn.Softmax(dim=-1)(attn_weights)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        attn_output = torch.matmul(attn_weights, value)\n",
    "\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "    @staticmethod\n",
    "    def _split_heads(tensor, num_heads, attn_head_size):\n",
    "        new_shape = tensor.size()[:-1] + (num_heads, attn_head_size)\n",
    "        tensor = tensor.view(*new_shape)\n",
    "        return tensor.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
    "\n",
    "    @staticmethod\n",
    "    def _merge_heads(tensor, num_heads, attn_head_size):\n",
    "        tensor = tensor.permute(0, 2, 1, 3).contiguous()\n",
    "        new_shape = tensor.size()[:-2] + (num_heads * attn_head_size,)\n",
    "        return tensor.view(new_shape)\n",
    "\n",
    "    def forward(self,\n",
    "                hidden_states,\n",
    "                attention_mask=None,\n",
    "                return_attention_weights=False):\n",
    "\n",
    "        query, key, value = self.qkv_attn(hidden_states).split(self.split_size, dim=2)\n",
    "\n",
    "        # Query is averaged to obtain pooling\n",
    "        query = self._split_heads(query, self.num_heads, self.head_dim).mean(-2, keepdims=True)\n",
    "        key = self._split_heads(key, self.num_heads, self.head_dim)\n",
    "        value = self._split_heads(value, self.num_heads, self.head_dim)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = (1.0 - attention_mask) * -1e+6\n",
    "            attention_mask = attention_mask[:, None, None, :]\n",
    "\n",
    "        attn_output, attn_weights = self._attn(query, key, value, attention_mask)\n",
    "\n",
    "        attn_output = self._merge_heads(attn_output, self.num_heads, self.head_dim)\n",
    "\n",
    "        if not return_attention_weights:\n",
    "            return attn_output  # attention\n",
    "        else:\n",
    "            attn_weights = self._merge_heads(attn_weights, self.num_heads, self.head_dim)\n",
    "            return attn_output, attn_weights\n",
    "\n",
    "\n",
    "# class GPT2Attention(nn.Module):\n",
    "# https://github.com/huggingface/transformers/blob/master/src/transformers/models/gpt2/modeling_gpt2.py\n",
    "\n",
    "\n",
    "class SequenceEmbedding(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size: int = 512, kernel_size: int = 5):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_size)\n",
    "        self.conv1d = nn.Conv1d(input_size, hidden_size, kernel_size, padding='same')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_head = nn.Linear(hidden_size, hidden_size)\n",
    "        ##\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.out_norm = nn.LayerNorm(hidden_size)\n",
    "        self.pool = AttentionAvgPooling()\n",
    "        \n",
    "    def forward(self, x, w):\n",
    "        # \n",
    "        x = self.dropout(x)\n",
    "        #\n",
    "        h = self.conv1d(x.transpose(-1, -2)).transpose(-1, -2)  # self.norm(x).transpose(-1, -2)\n",
    "        ##\n",
    "        h = self.norm(h)\n",
    "        # Non-linear activation\n",
    "        h = F.gelu(h)\n",
    "        \n",
    "        # Dropout\n",
    "        h = self.dropout(h)\n",
    "        # Weighted sum\n",
    "        # h = torch.einsum('btd,bt->bd', h, w)\n",
    "        # Apply last linear projection\n",
    "        # h = self.out_head(h)\n",
    "        ##\n",
    "        h = self.pool(h, w)\n",
    "        h = self.out_norm(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mms = sts['train'].get_label_transformer()\n",
    "mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task = 'similarity_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = SequenceEmbedding(300)    \n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 512\n",
    "n_epochs = 64\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr, weight_decay=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def collate(mini_batch):\n",
    "    # Tokenise sequences \n",
    "    sequences_a = embeddings_model.tokenise([sample['sequence_a'] for sample in mini_batch])\n",
    "    sequences_b = embeddings_model.tokenise([sample['sequence_b'] for sample in mini_batch])\n",
    "    # Get the length of the longest sentence\n",
    "    max_sequence_len_a = max(len(sample) for sample in sequences_a)\n",
    "    max_sequence_len_b = max(len(sample) for sample in sequences_b)\n",
    "    # Create an input tensor with all zero values\n",
    "    input_embeds_a = np.zeros((len(mini_batch), max_sequence_len_a, 300))\n",
    "    input_embeds_b = np.zeros((len(mini_batch), max_sequence_len_b, 300))\n",
    "    # Create weights tensor with all zero values\n",
    "    token_weights_a = np.zeros((len(mini_batch), max_sequence_len_a))\n",
    "    valid_mask_a = np.zeros((len(mini_batch), max_sequence_len_a))\n",
    "    token_weights_b = np.zeros((len(mini_batch), max_sequence_len_b))\n",
    "    valid_mask_b = np.zeros((len(mini_batch), max_sequence_len_b))\n",
    "    # Create a target output matrix with all -100 (PyTorch ignores this value by default)\n",
    "    output_score = np.zeros((len(mini_batch), 1))\n",
    "    # Fill the tensor and the matrix\n",
    "    for i, _ in enumerate(mini_batch):\n",
    "        for j, token in enumerate(sequences_a[i]):\n",
    "            # Manage missing tokens in vocabulary\n",
    "            input_embeds_a[i, j] = embeddings_model[token.lower()]\n",
    "        token_weights_a[i, :len(sequences_a[i])] = embeddings_model.sif_embedding_model.word_weights[embeddings_model.encode(sequences_a[i], backend='numpy')]\n",
    "        valid_mask_a[i, :len(sequences_a[i])] = 1.0\n",
    "        for j, token in enumerate(sequences_b[i]):\n",
    "            # Manage missing tokens in vocabulary\n",
    "            input_embeds_b[i, j] = embeddings_model[token.lower()]\n",
    "        token_weights_b[i, :len(sequences_b[i])] = embeddings_model.sif_embedding_model.word_weights[embeddings_model.encode(sequences_b[i], backend='numpy')]\n",
    "        valid_mask_b[i, :len(sequences_b[i])] = 1.0\n",
    "        output_score[i] = mms[task].transform([[mini_batch[i][task]]])[0]\n",
    "    # Convert to PyTorch tensor\n",
    "    input_embeds_a = torch.tensor(input_embeds_a, dtype=torch.float, device=device)\n",
    "    token_weights_a = torch.tensor(token_weights_a, dtype=torch.float, device=device)\n",
    "    valid_mask_a = torch.tensor(valid_mask_a, dtype=torch.float, device=device)\n",
    "    input_embeds_b = torch.tensor(input_embeds_b, dtype=torch.float, device=device)\n",
    "    token_weights_b = torch.tensor(token_weights_b, dtype=torch.float, device=device)\n",
    "    valid_mask_b = torch.tensor(valid_mask_b, dtype=torch.float, device=device)\n",
    "    output_score = torch.tensor(output_score, dtype=torch.float, device=device)\n",
    "\n",
    "    # return input_embeds_a, token_weights_a, input_embeds_b, token_weights_b, output_score\n",
    "    return input_embeds_a, valid_mask_a, input_embeds_b, valid_mask_b, output_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_loader = {\n",
    "    split: torch.utils.data.DataLoader(\n",
    "        data, batch_size=batch_size, collate_fn=collate, shuffle=split == 'train'\n",
    "    )\n",
    "    for split, data in sts.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('../experiments/contextual/', f'{model_id}_{corpus}_{task}_{datetime.now()}.ckpt')\n",
    "\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Accumulator of loss\n",
    "history = []\n",
    "validation_history = []\n",
    "best_validation_loss = torch.tensor(float('inf'), device=device)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, steps_per_epoch=len(data_loader['train']), epochs=n_epochs, anneal_strategy='linear', pct_start=0.05)\n",
    "\n",
    "estop_counter = 0\n",
    "\n",
    "# Iterate over epochs\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Starting epoch {i + 1}/{n_epochs}\")\n",
    "    # Iterate over training batches\n",
    "    for embeds_a, weights_a, embeds_b, weights_b, score in tqdm(data_loader['train']):\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        # Move input and output to target device\n",
    "        embeds_a = embeds_a.to(device)\n",
    "        weights_a = weights_a.to(device)\n",
    "        embeds_b = embeds_b.to(device)\n",
    "        weights_b = weights_b.to(device)\n",
    "        score = score.to(device)\n",
    "        # Compute logits \n",
    "        embeds_a = model(embeds_a, weights_a)\n",
    "        embeds_b = model(embeds_b, weights_b)\n",
    "        logits = torch.sum(embeds_a.squeeze() * embeds_b.squeeze(), dim=1, keepdims=True)\n",
    "        # Compute loss\n",
    "        ## loss = F.binary_cross_entropy_with_logits(logits, score)\n",
    "        loss = F.mse_loss(F.cosine_similarity(embeds_a, embeds_b, dim=-1), score)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # Save loss\n",
    "        history.append(loss.detach())\n",
    "    # Disable gradients\n",
    "    with torch.no_grad():\n",
    "        print(f\"Starting validation epoch {i + 1}/{n_epochs}\")\n",
    "        # Set in evaluation mode\n",
    "        model.eval()\n",
    "        # Init validation loss accumulator\n",
    "        loss = []\n",
    "        # Iterate over validation batches\n",
    "        for embeds_a, weights_a, embeds_b, weights_b, score in tqdm(data_loader['train']):\n",
    "            # Zero your gradients for every batch!\n",
    "            optimizer.zero_grad()\n",
    "            # Move input and output to target device\n",
    "            embeds_a = embeds_a.to(device)\n",
    "            weights_a = weights_a.to(device)\n",
    "            embeds_b = embeds_b.to(device)\n",
    "            weights_b = weights_b.to(device)\n",
    "            score = score.to(device)\n",
    "            # Compute logits \n",
    "            embeds_a = model(embeds_a, weights_a)\n",
    "            embeds_b = model(embeds_b, weights_b)\n",
    "            logits = torch.sum(embeds_a.squeeze() * embeds_b.squeeze(), dim=1, keepdims=True)\n",
    "            # Compute loss\n",
    "            ## loss.append(F.binary_cross_entropy_with_logits(logits, score))\n",
    "            loss.append(F.mse_loss(F.cosine_similarity(embeds_a, embeds_b, dim=-1), score))\n",
    "        # Aggregate validation loss\n",
    "        validation_history.append(torch.tensor(loss, device=device).mean())\n",
    "        # Check if validation loss has improved\n",
    "        if validation_history[-1] <= best_validation_loss:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_validation_loss = validation_history[-1]\n",
    "            estop_counter = 0\n",
    "        else:\n",
    "            estop_counter += 1\n",
    "        # Restore training mode\n",
    "        model.train()\n",
    "    if estop_counter >= 5:\n",
    "        break\n",
    "\n",
    "# Restore best weights\n",
    "if os.path.exists(path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "history = [loss.cpu().item() for loss in history]\n",
    "validation_history = [loss.cpu().item() for loss in validation_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(history)), history, label='Training loss')\n",
    "plt.plot(range(len(data_loader['train']) - 1, len(history), len(data_loader['train'])), validation_history, label='Validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim([0.0, len(history)])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set model in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "split = 'validation'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds_a, weights_a, embeds_b, weights_b, score in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds_a = embeds_a.to(device)\n",
    "        weights_a = weights_a.to(device)\n",
    "        embeds_b = embeds_b.to(device)\n",
    "        weights_b = weights_b.to(device)\n",
    "        score = score.to(device)\n",
    "        # Compute logits \n",
    "        embeds_a = model(embeds_a, weights_a)\n",
    "        embeds_b = model(embeds_b, weights_b)\n",
    "        logits = torch.sum(embeds_a.squeeze() * embeds_b.squeeze(), dim=1, keepdims=True)\n",
    "        # Append predicted labels\n",
    "        ## y_pred.append(F.sigmoid(logits).view(-1).cpu().numpy())\n",
    "        y_pred.append(F.cosine_similarity(embeds_a, embeds_b, dim=-1).view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(score.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "\n",
    "# \n",
    "spearman_corr = spearmanr(y_true, y_pred)\n",
    "pearson_corr = pearsonr(y_true, y_pred)\n",
    "\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        REG_METRICS, [pearson_corr.correlation, pearson_corr.pvalue, spearman_corr.correlation, spearman_corr.pvalue]\n",
    "    )\n",
    "])\n",
    "\n",
    "print(pearson_corr)\n",
    "print(spearman_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "split = 'test'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds_a, weights_a, embeds_b, weights_b, score in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds_a = embeds_a.to(device)\n",
    "        weights_a = weights_a.to(device)\n",
    "        embeds_b = embeds_b.to(device)\n",
    "        weights_b = weights_b.to(device)\n",
    "        score = score.to(device)\n",
    "        # Compute logits \n",
    "        embeds_a = model(embeds_a, weights_a)\n",
    "        embeds_b = model(embeds_b, weights_b)\n",
    "        logits = torch.sum(embeds_a.squeeze() * embeds_b.squeeze(), dim=1, keepdims=True)\n",
    "        # Append predicted labels\n",
    "        ## y_pred.append(F.sigmoid(logits).view(-1).cpu().numpy())\n",
    "        y_pred.append(F.cosine_similarity(embeds_a, embeds_b, dim=-1).view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(score.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "\n",
    "# \n",
    "spearman_corr = spearmanr(y_true, y_pred)\n",
    "pearson_corr = pearsonr(y_true, y_pred)\n",
    "\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        REG_METRICS, [pearson_corr.correlation, pearson_corr.pvalue, spearman_corr.correlation, spearman_corr.pvalue]\n",
    "    )\n",
    "])\n",
    "\n",
    "print(pearson_corr)\n",
    "print(spearman_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20NG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "corpus = '20NG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'From: backon@vms.huji.ac.il\\nSubject: Re: Go Hezbollah!!\\nDistribution: world\\nOrganization: The Hebrew University of Jerusalem\\nLines: 23\\n\\nIn article <1993Apr14.125813.21737@ncsu.edu>, hernlem@chess.ncsu.edu (Brad Hernlem) writes:\\n>\\n> Lebanese resistance forces detonated a bomb under an Israeli occupation\\n> patrol in Lebanese territory two days ago. Three soldiers were killed and\\n> two wounded. In \"retaliation\", Israeli and Israeli-backed forces wounded\\n> 8 civilians by bombarding several Lebanese villages. Ironically, the Israeli\\n> government justifies its occupation in Lebanon by claiming that it is\\n> necessary to prevent such bombardments of Israeli villages!!\\n>\\n> Congratulations to the brave men of the Lebanese resistance! With every\\n> Israeli son that you place in the grave you are underlining the moral\\n> bankruptcy of Israel\\'s occupation and drawing attention to the Israeli\\n> government\\'s policy of reckless disregard for civilian life.\\n>\\n> Brad Hernlem (hernlem@chess.ncsu.EDU)\\n\\n\\nI\\'m sure the Federal Bureau of Investigation (fbi.gov on the Internet) is going\\nto *love* reading your incitement to murder.\\n\\n\\nJosh\\nbackon@VMS.HUJI.AC.IL\\n',\n",
       "  'newsgroup': 'talk.politics.mideast'},\n",
       " {'sequence': \"From: ak296@yfn.ysu.edu (John R. Daker)\\nSubject: Re: Dumbest automotive concepts of all time\\nOrganization: St. Elizabeth Hospital, Youngstown, OH\\nLines: 13\\nReply-To: ak296@yfn.ysu.edu (John R. Daker)\\nNNTP-Posting-Host: yfn.ysu.edu\\n\\n\\nCup holders (driving is an importantant enough undertaking)\\nCellular phones and mobile fax machines (see above)\\nVanity mirrors on the driver's side.\\nAshtrays (smokers seem to think it's just fine to use the road)\\nFake convertible roofs and vinyl roofs.\\nAny gold trim.\\n\\n-- \\nDoD #650<----------------------------------------------------------->DarkMan\\n   The significant problems we face cannot be solved at the same level of\\n      thinking we were at when we created them.   - Albert Einstein\\n         ___________________The Eternal Champion_________________\\n\",\n",
       "  'newsgroup': 'rec.autos'},\n",
       " {'sequence': 'From: claborne@npg-sd.SanDiegoCA.NCR.COM (Chris Claborne)\\nSubject: Anyone use Number 9 GXE video card?\\nSummary: Anyone use Number 9 GXE video card?\\nKeywords: Video adaptor hardware graphics\\nDistribution: world\\nOrganization: NCR Corp., Network Products - San Diego\\nLines: 5\\n\\nHas anyone used the Number Nine (# 9) Video Graphics adaptor with Windows\\nor Windows NT?  What do you think???\\n\\n    2\\n-- C  --\\n',\n",
       "  'newsgroup': 'comp.os.ms-windows.misc'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng['train']._data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# embeddings_model.fit_sif_embedding([sample['sequence'] for sample in ng['train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass SequenceClassification(nn.Module):\\n    def __init__(self, input_size, output_size, hidden_size: int = 512, kernel_size: int = 5):\\n        super().__init__()\\n        self.norm = nn.LayerNorm(input_size)\\n        self.conv1d = nn.Conv1d(input_size, hidden_size, kernel_size, padding='same')\\n        self.dropout = nn.Dropout(0.1)\\n        self.cls_head = nn.Linear(hidden_size, output_size)\\n        \\n    def forward(self, x, w):\\n        # \\n        x = self.dropout(x)\\n        #\\n        h = self.conv1d(self.norm(x).transpose(-1, -2))\\n        # Non-linear activation\\n        h = F.gelu(h)\\n        # Dropout\\n        h = self.dropout(h)\\n        # Weighted sum\\n        h = torch.einsum('btd,bt->bd', h.transpose(-1, -2), w)\\n        # Apply last linear projection\\n        y = self.cls_head(h)\\n\\n        return y\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple, List, Set\n",
    "\n",
    "class Conv1D(nn.Module):\n",
    "    \"\"\"\n",
    "    1D-convolutional layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2).\n",
    "    Basically works like a linear layer but the weights are transposed.\n",
    "    Args:\n",
    "        nf (:obj:`int`): The number of output features.\n",
    "        nx (:obj:`int`): The number of input features.\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nf, nx):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        w = torch.empty(nx, nf)\n",
    "        nn.init.normal_(w, std=0.02)\n",
    "        self.weight = nn.Parameter(w)\n",
    "        self.bias = nn.Parameter(torch.zeros(nf))\n",
    "\n",
    "    def forward(self, x):\n",
    "        size_out = x.size()[:-1] + (self.nf,)\n",
    "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
    "        x = x.view(*size_out)\n",
    "        return x\n",
    "\n",
    "\n",
    "def find_pruneable_heads_and_indices(heads: List[int],\n",
    "                                     n_heads: int,\n",
    "                                     head_size: int,\n",
    "                                     already_pruned_heads: Set[int]) -> Tuple[Set[int], torch.LongTensor]:\n",
    "    \"\"\"\n",
    "    Finds the heads and their indices taking :obj:`already_pruned_heads` into account.\n",
    "    Args:\n",
    "        heads (:obj:`List[int]`): List of the indices of heads to prune.\n",
    "        n_heads (:obj:`int`): The number of heads in the model.\n",
    "        head_size (:obj:`int`): The size of each head.\n",
    "        already_pruned_heads (:obj:`Set[int]`): A set of already pruned heads.\n",
    "    Returns:\n",
    "        :obj:`Tuple[Set[int], torch.LongTensor]`: A tuple with the remaining heads and their corresponding indices.\n",
    "\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "    mask = torch.ones(n_heads, head_size)\n",
    "    heads = set(heads) - already_pruned_heads  # Convert to set and remove already pruned heads\n",
    "    for head in heads:\n",
    "        # Compute how many pruned heads are before the head and move the index accordingly\n",
    "        head = head - sum(1 if h < head else 0 for h in already_pruned_heads)\n",
    "        mask[head] = 0\n",
    "    mask = mask.view(-1).contiguous().eq(1)\n",
    "    index: torch.LongTensor = torch.arange(len(mask))[mask].long()\n",
    "    return heads, index\n",
    "\n",
    "\n",
    "def prune_conv1d_layer(layer: Conv1D, index: torch.LongTensor, dim: int = 1) -> Conv1D:\n",
    "    \"\"\"\n",
    "    Prune a Conv1D layer to keep only entries in index. A Conv1D work as a Linear layer (see e.g. BERT) but the weights\n",
    "    are transposed.\n",
    "    Used to remove heads.\n",
    "    Args:\n",
    "        layer (:class:`~transformers.modeling_utils.Conv1D`): The layer to prune.\n",
    "        index (:obj:`torch.LongTensor`): The indices to keep in the layer.\n",
    "        dim (:obj:`int`, `optional`, defaults to 1): The dimension on which to keep the indices.\n",
    "    Returns:\n",
    "        :class:`~transformers.modeling_utils.Conv1D`: The pruned layer as a new layer with :obj:`requires_grad=True`.\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "    index = index.to(layer.weight.device)\n",
    "    W = layer.weight.index_select(dim, index).clone().detach()\n",
    "    if dim == 0:\n",
    "        b = layer.bias.clone().detach()\n",
    "    else:\n",
    "        b = layer.bias[index].clone().detach()\n",
    "    new_size = list(layer.weight.size())\n",
    "    new_size[dim] = len(index)\n",
    "    new_layer = Conv1D(new_size[1], new_size[0]).to(layer.weight.device)\n",
    "    new_layer.weight.requires_grad = False\n",
    "    new_layer.weight.copy_(W.contiguous())\n",
    "    new_layer.weight.requires_grad = True\n",
    "    new_layer.bias.requires_grad = False\n",
    "    new_layer.bias.copy_(b.contiguous())\n",
    "    new_layer.bias.requires_grad = True\n",
    "    return new_layer\n",
    "\n",
    "\n",
    "class AttentionAvgPooling(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_hidden: int = 512,\n",
    "                 n_heads: int = 8,\n",
    "                 max_positions: int = 1024,\n",
    "                 p_dropout: float = 0.1,\n",
    "                 scale_attn_weights: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = n_hidden\n",
    "        self.num_heads = n_heads\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "        self.split_size = self.embed_dim\n",
    "        assert self.head_dim * self.num_heads == self.embed_dim, f\"`embed_dim` must be divisible by num_heads \" \\\n",
    "                                                                 f\"(got `embed_dim`: {self.embed_dim} and \" \\\n",
    "                                                                 f\"`num_heads`: {self.num_heads}).\"\n",
    "\n",
    "        self.scale_attn_weights = scale_attn_weights\n",
    "\n",
    "        self.qkv_attn = Conv1D(3 * self.embed_dim, self.embed_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        heads, index = find_pruneable_heads_and_indices(heads, self.num_heads, self.head_dim, self.pruned_heads)\n",
    "        index_attn = torch.cat([index, index + self.split_size, index + (2 * self.split_size)])\n",
    "\n",
    "        # Prune conv1d layers\n",
    "        self.qkv_attn = prune_conv1d_layer(self.qkv_attn, index_attn, dim=1)\n",
    "\n",
    "        # Update hyper params\n",
    "        self.split_size = (self.split_size // self.num_heads) * (self.num_heads - len(heads))\n",
    "        self.num_heads = self.num_heads - len(heads)\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    def _attn(self, query, key, value, attention_mask=None):\n",
    "        attn_weights = torch.matmul(query, key.transpose(-1, -2))\n",
    "        attn_weights = attn_weights / (float(value.size(-1)) ** 0.5)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask\n",
    "            attn_weights = attn_weights + attention_mask\n",
    "\n",
    "        attn_weights = nn.Softmax(dim=-1)(attn_weights)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        attn_output = torch.matmul(attn_weights, value)\n",
    "\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "    @staticmethod\n",
    "    def _split_heads(tensor, num_heads, attn_head_size):\n",
    "        new_shape = tensor.size()[:-1] + (num_heads, attn_head_size)\n",
    "        tensor = tensor.view(*new_shape)\n",
    "        return tensor.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
    "\n",
    "    @staticmethod\n",
    "    def _merge_heads(tensor, num_heads, attn_head_size):\n",
    "        tensor = tensor.permute(0, 2, 1, 3).contiguous()\n",
    "        new_shape = tensor.size()[:-2] + (num_heads * attn_head_size,)\n",
    "        return tensor.view(new_shape)\n",
    "\n",
    "    def forward(self,\n",
    "                hidden_states,\n",
    "                attention_mask=None,\n",
    "                return_attention_weights=False):\n",
    "\n",
    "        query, key, value = self.qkv_attn(hidden_states).split(self.split_size, dim=2)\n",
    "\n",
    "        # Query is averaged to obtain pooling\n",
    "        query = self._split_heads(query, self.num_heads, self.head_dim).mean(-2, keepdims=True)\n",
    "        key = self._split_heads(key, self.num_heads, self.head_dim)\n",
    "        value = self._split_heads(value, self.num_heads, self.head_dim)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = (1.0 - attention_mask) * -1e+6\n",
    "            attention_mask = attention_mask[:, None, None, :]\n",
    "\n",
    "        attn_output, attn_weights = self._attn(query, key, value, attention_mask)\n",
    "\n",
    "        attn_output = self._merge_heads(attn_output, self.num_heads, self.head_dim)\n",
    "\n",
    "        if not return_attention_weights:\n",
    "            return attn_output  # attention\n",
    "        else:\n",
    "            attn_weights = self._merge_heads(attn_weights, self.num_heads, self.head_dim)\n",
    "            return attn_output, attn_weights\n",
    "\n",
    "\n",
    "# class GPT2Attention(nn.Module):\n",
    "# https://github.com/huggingface/transformers/blob/master/src/transformers/models/gpt2/modeling_gpt2.py\n",
    "\n",
    "\n",
    "class SequenceClassification(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size: int = 512, kernel_size: int = 5):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_size)\n",
    "        self.conv1d = nn.Conv1d(input_size, hidden_size, kernel_size, padding='same')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_head = nn.Linear(hidden_size, output_size)\n",
    "        ##\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.out_norm = nn.LayerNorm(hidden_size)\n",
    "        self.pool = AttentionAvgPooling()\n",
    "        \n",
    "    def forward(self, x, w):\n",
    "        # \n",
    "        x = self.dropout(x)\n",
    "        #\n",
    "        h = self.conv1d(x.transpose(-1, -2)).transpose(-1, -2)  # self.norm(x).transpose(-1, -2)\n",
    "        ##\n",
    "        h = self.norm(h)\n",
    "        # Non-linear activation\n",
    "        h = F.gelu(h)\n",
    "        \n",
    "        # Dropout\n",
    "        h = self.dropout(h)\n",
    "        # Weighted sum\n",
    "        # h = torch.einsum('btd,bt->bd', h, w)\n",
    "        # Apply last linear projection\n",
    "        # h = self.out_head(h)\n",
    "        ##\n",
    "        h = self.pool(h, w)\n",
    "        h = self.out_norm(h)\n",
    "        y = self.out_head(h)\n",
    "\n",
    "        return y\n",
    "\n",
    "'''\n",
    "class SequenceClassification(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size: int = 512, kernel_size: int = 5):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_size)\n",
    "        self.conv1d = nn.Conv1d(input_size, hidden_size, kernel_size, padding='same')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.cls_head = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, w):\n",
    "        # \n",
    "        x = self.dropout(x)\n",
    "        #\n",
    "        h = self.conv1d(self.norm(x).transpose(-1, -2))\n",
    "        # Non-linear activation\n",
    "        h = F.gelu(h)\n",
    "        # Dropout\n",
    "        h = self.dropout(h)\n",
    "        # Weighted sum\n",
    "        h = torch.einsum('btd,bt->bd', h.transpose(-1, -2), w)\n",
    "        # Apply last linear projection\n",
    "        y = self.cls_head(h)\n",
    "\n",
    "        return y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup ['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\n",
      " 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\n",
      " 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\n",
      " 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\n",
      " 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\n",
      " 'talk.politics.misc' 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "le = ng['train'].get_label_transformer()\n",
    "for label, le_ in le.items():\n",
    "    print(label, le_.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup tensor([1.2582, 1.0595, 1.0266, 1.0475, 1.0793, 1.0668, 1.0198, 1.0619, 1.0619,\n",
      "        1.0312, 1.0289, 1.0523, 1.0428, 1.0000, 1.0547, 1.0428, 1.1517, 1.1024,\n",
      "        1.2969, 1.5966], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "lw = {label: lw_.to(device) for label, lw_ in ng['train'].get_label_weights().items()}\n",
    "for label, lw_ in lw.items():\n",
    "    print(label, lw_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task = 'newsgroup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassification(\n",
       "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (conv1d): Conv1d(300, 512, kernel_size=(5,), stride=(1,), padding=same)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_head): Linear(in_features=512, out_features=20, bias=True)\n",
       "  (out_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (pool): AttentionAvgPooling(\n",
       "    (qkv_attn): Conv1D()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequenceClassification(300, len(le[task].classes_))    \n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 8\n",
    "n_epochs = 64\n",
    "accumulation_steps = 64\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr, weight_decay=0.2)\n",
    "# optimizer = torch.optim.RMSprop(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def collate(mini_batch):\n",
    "    # Tokenise sequences \n",
    "    sequences = embeddings_model.tokenise([sample['sequence'] for sample in mini_batch])\n",
    "    # Get the length of the longest sentence\n",
    "    max_sequence_len = max(len(sample) for sample in sequences)\n",
    "    # Create an input tensor with all zero values\n",
    "    input_embeds = np.zeros((len(mini_batch), max_sequence_len, 300))\n",
    "    # Create weights tensor with all zero values\n",
    "    token_weights = np.zeros((len(mini_batch), max_sequence_len))\n",
    "    valid_mask = np.zeros((len(mini_batch), max_sequence_len))\n",
    "    # Create a target output matrix with all -100 (PyTorch ignores this value by default)\n",
    "    output_lbl = np.full((len(mini_batch), 1), -100)\n",
    "    # Fill the tensor and the matrix\n",
    "    for i, sample in enumerate(sequences):\n",
    "        for j, token in enumerate(sample):\n",
    "            # Manage missing tokens in vocabulary\n",
    "            input_embeds[i, j] = embeddings_model[token.lower()]\n",
    "        token_weights[i, :len(sample)] = embeddings_model.sif_embedding_model.word_weights[embeddings_model.encode(sample, backend='numpy')]\n",
    "        valid_mask[i, :len(sample)] = 1.0\n",
    "        output_lbl[i] = le[task].transform([mini_batch[i][task]])[0]\n",
    "    # Convert to PyTorch tensor\n",
    "    input_embeds = torch.tensor(input_embeds, dtype=torch.float, device=device)\n",
    "    token_weights = torch.tensor(token_weights, dtype=torch.float, device=device)\n",
    "    valid_mask = torch.tensor(valid_mask, dtype=torch.float, device=device)\n",
    "    output_lbl = torch.tensor(output_lbl, device=device)\n",
    "\n",
    "    # return input_embeds, token_weights, output_lbl\n",
    "    return input_embeds, valid_mask, output_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_loader = {\n",
    "    split: torch.utils.data.DataLoader(\n",
    "        data, batch_size=batch_size, collate_fn=collate, shuffle=split == 'train'\n",
    "    )\n",
    "    for split, data in ng.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 26.28it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "8it [00:00, 34.22it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "12it [00:00, 32.74it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "22it [00:00, 41.06it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "27it [00:00, 42.72it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "32it [00:00, 37.83it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "36it [00:00, 37.67it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "41it [00:01, 38.91it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "45it [00:01, 38.53it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "55it [00:01, 40.77it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "60it [00:01, 42.74it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "65it [00:01, 40.81it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "75it [00:01, 37.16it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "80it [00:02, 39.37it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "85it [00:02, 33.14it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "90it [00:02, 36.55it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "95it [00:02, 36.39it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "101it [00:02, 41.02it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "106it [00:02, 41.58it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "111it [00:02, 42.80it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "116it [00:02, 41.41it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "121it [00:03, 42.02it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "126it [00:03, 38.84it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "131it [00:03, 40.91it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "136it [00:03, 30.93it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "140it [00:03, 32.59it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "145it [00:03, 36.55it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "150it [00:03, 36.87it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "156it [00:04, 41.29it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "161it [00:04, 33.96it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "167it [00:04, 36.43it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "171it [00:04, 36.88it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "176it [00:04, 39.37it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "188it [00:04, 46.00it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "193it [00:04, 46.45it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "198it [00:05, 44.35it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "203it [00:05, 31.87it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "210it [00:05, 37.34it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "215it [00:05, 34.74it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "219it [00:05, 32.74it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "224it [00:05, 35.24it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "229it [00:06, 38.44it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "235it [00:06, 28.35it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "239it [00:06, 25.30it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "242it [00:06, 17.94it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "245it [00:07, 19.07it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "250it [00:07, 21.29it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "254it [00:07, 23.48it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "259it [00:07, 27.97it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "264it [00:07, 31.67it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "274it [00:07, 36.96it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "279it [00:07, 35.94it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "285it [00:08, 40.12it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "290it [00:08, 32.14it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "295it [00:08, 35.23it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "300it [00:08, 36.26it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "310it [00:08, 41.12it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "316it [00:08, 44.86it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "321it [00:08, 44.01it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "326it [00:09, 25.09it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "331it [00:09, 28.45it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "337it [00:09, 32.34it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "341it [00:09, 23.66it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "350it [00:10, 25.58it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "355it [00:10, 29.81it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "359it [00:10, 31.25it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "363it [00:10, 31.11it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "368it [00:10, 35.26it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "374it [00:10, 40.84it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "380it [00:10, 45.12it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "390it [00:11, 42.34it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "395it [00:11, 35.88it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "400it [00:11, 37.73it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "404it [00:11, 35.09it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "409it [00:11, 36.64it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "413it [00:11, 37.33it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "418it [00:11, 38.39it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "423it [00:12, 40.34it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "429it [00:12, 43.75it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "434it [00:12, 37.62it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "440it [00:12, 41.24it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "445it [00:12, 37.52it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "450it [00:12, 39.71it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "455it [00:12, 35.41it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "459it [00:13, 35.85it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "464it [00:13, 38.24it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "468it [00:13, 36.59it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "472it [00:13, 19.62it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "475it [00:13, 19.65it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "479it [00:14, 22.93it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "485it [00:14, 29.93it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "489it [00:14, 31.55it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "494it [00:14, 34.81it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "498it [00:14, 19.52it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "508it [00:15, 27.90it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "512it [00:15, 29.19it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "517it [00:15, 33.09it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "523it [00:15, 37.73it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "528it [00:15, 39.90it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "533it [00:15, 41.73it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "538it [00:15, 40.87it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "543it [00:15, 40.59it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "549it [00:15, 45.30it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "554it [00:16, 43.97it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "559it [00:16, 42.82it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "564it [00:16, 44.36it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "574it [00:16, 41.28it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "580it [00:16, 40.12it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "585it [00:16, 38.51it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "590it [00:16, 40.28it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "602it [00:17, 44.44it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "607it [00:17, 25.16it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "611it [00:17, 23.60it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "618it [00:17, 30.29it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "623it [00:18, 33.12it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "628it [00:18, 36.37it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "645it [00:18, 44.41it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "651it [00:18, 45.51it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "656it [00:18, 43.04it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "662it [00:18, 45.35it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "667it [00:19, 41.62it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "673it [00:19, 42.64it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "678it [00:19, 22.77it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "682it [00:19, 24.35it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "686it [00:19, 23.93it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "690it [00:20, 26.67it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "694it [00:20, 28.06it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "705it [00:20, 36.31it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "714it [00:20, 39.47it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "719it [00:20, 41.51it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "724it [00:20, 43.68it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "729it [00:21, 40.04it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "734it [00:21, 40.57it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "739it [00:21, 41.00it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "744it [00:21, 33.74it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "748it [00:21, 28.39it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "752it [00:22, 19.24it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "755it [00:22, 19.23it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "759it [00:22, 22.62it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "768it [00:22, 29.87it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "785it [00:22, 42.17it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "796it [00:23, 44.14it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "801it [00:23, 35.43it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "811it [00:23, 39.98it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "816it [00:23, 35.01it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "826it [00:23, 40.07it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "832it [00:24, 44.17it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "837it [00:24, 45.46it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "847it [00:24, 41.58it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "857it [00:24, 41.05it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "862it [00:24, 41.38it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "880it [00:25, 52.21it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "886it [00:25, 41.13it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "891it [00:25, 22.89it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "902it [00:26, 29.73it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "908it [00:26, 34.87it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "913it [00:26, 26.35it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "918it [00:26, 30.09it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "922it [00:26, 31.27it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "932it [00:26, 35.79it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "936it [00:27, 36.75it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "941it [00:27, 39.15it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "952it [00:27, 33.07it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "957it [00:27, 35.29it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "963it [00:27, 39.31it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "968it [00:27, 41.67it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "973it [00:28, 32.07it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1003it [00:28, 46.83it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1009it [00:28, 48.35it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1019it [00:29, 47.89it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1024it [00:29, 37.22it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1030it [00:29, 42.36it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1035it [00:29, 37.53it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1040it [00:29, 39.70it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1045it [00:29, 40.80it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1051it [00:29, 45.10it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1056it [00:30, 24.95it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:30, 34.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                    | 0/354 [00:00<?, ?it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "  2%|██▉                                                                                                                                                                         | 6/354 [00:00<00:13, 25.28it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "  3%|█████▊                                                                                                                                                                     | 12/354 [00:00<00:08, 38.10it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "  5%|████████▋                                                                                                                                                                  | 18/354 [00:00<00:07, 42.10it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "  8%|██████████████                                                                                                                                                             | 29/354 [00:00<00:07, 46.34it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 10%|████████████████▍                                                                                                                                                          | 34/354 [00:00<00:07, 41.80it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 12%|█████████████████████▎                                                                                                                                                     | 44/354 [00:01<00:07, 42.93it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 14%|███████████████████████▋                                                                                                                                                   | 49/354 [00:01<00:10, 28.01it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 17%|████████████████████████████▉                                                                                                                                              | 60/354 [00:01<00:09, 29.71it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 19%|███████████████████████████████▉                                                                                                                                           | 66/354 [00:01<00:08, 35.46it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 20%|██████████████████████████████████▊                                                                                                                                        | 72/354 [00:01<00:06, 40.62it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 22%|█████████████████████████████████████▏                                                                                                                                     | 77/354 [00:02<00:07, 37.06it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 25%|██████████████████████████████████████████▌                                                                                                                                | 88/354 [00:02<00:06, 38.08it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 27%|█████████████████████████████████████████████▍                                                                                                                             | 94/354 [00:02<00:06, 41.36it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 30%|███████████████████████████████████████████████████▍                                                                                                                      | 107/354 [00:02<00:05, 48.92it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 35%|████████████████████████████████████████████████████████████                                                                                                              | 125/354 [00:03<00:05, 43.10it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 37%|██████████████████████████████████████████████████████████████▍                                                                                                           | 130/354 [00:03<00:06, 32.38it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 38%|█████████████████████████████████████████████████████████████████▎                                                                                                        | 136/354 [00:03<00:06, 36.21it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 40%|████████████████████████████████████████████████████████████████████▏                                                                                                     | 142/354 [00:03<00:05, 40.75it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 42%|███████████████████████████████████████████████████████████████████████                                                                                                   | 148/354 [00:03<00:04, 44.45it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 43%|█████████████████████████████████████████████████████████████████████████▍                                                                                                | 153/354 [00:03<00:04, 42.34it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 45%|███████████████████████████████████████████████████████████████████████████▉                                                                                              | 158/354 [00:04<00:04, 41.22it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 46%|██████████████████████████████████████████████████████████████████████████████▊                                                                                           | 164/354 [00:04<00:04, 45.15it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                        | 169/354 [00:04<00:04, 43.99it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 49%|████████████████████████████████████████████████████████████████████████████████████                                                                                      | 175/354 [00:04<00:03, 47.20it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 51%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                   | 181/354 [00:04<00:03, 48.63it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 186/354 [00:04<00:04, 40.44it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 191/354 [00:04<00:03, 41.55it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 55%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                            | 196/354 [00:04<00:03, 42.16it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 58%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                      | 207/354 [00:05<00:03, 45.53it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                    | 212/354 [00:05<00:03, 43.42it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 236/354 [00:05<00:02, 50.51it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                     | 242/354 [00:05<00:02, 47.18it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                   | 247/354 [00:05<00:02, 45.36it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                | 254/354 [00:06<00:02, 49.92it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 260/354 [00:06<00:01, 49.80it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 278/354 [00:06<00:02, 37.74it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                  | 283/354 [00:06<00:01, 37.27it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 294/354 [00:07<00:01, 42.49it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                          | 299/354 [00:07<00:01, 42.39it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 305/354 [00:07<00:01, 45.30it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 310/354 [00:07<00:00, 45.21it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 316/354 [00:07<00:01, 32.79it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 332/354 [00:08<00:00, 42.85it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 337/354 [00:08<00:00, 41.61it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 343/354 [00:08<00:00, 42.64it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 40.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 44.47it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "10it [00:00, 44.77it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "33it [00:00, 52.86it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "67it [00:01, 35.44it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "95it [00:02, 35.69it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "129it [00:03, 29.40it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "144it [00:04, 30.73it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "149it [00:04, 33.82it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "191it [00:05, 33.73it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "207it [00:05, 34.87it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "217it [00:06, 26.80it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "232it [00:06, 32.40it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "293it [00:08, 41.59it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "355it [00:10, 25.20it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "383it [00:11, 32.13it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "416it [00:11, 46.54it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "422it [00:11, 47.86it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "469it [00:13, 35.73it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "517it [00:14, 42.33it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "555it [00:15, 40.90it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "596it [00:16, 36.93it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "612it [00:16, 45.57it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "617it [00:16, 41.12it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "639it [00:17, 48.39it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "644it [00:17, 47.26it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "649it [00:17, 47.12it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "654it [00:17, 46.08it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "691it [00:18, 48.72it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "702it [00:18, 36.13it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "708it [00:18, 39.30it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "713it [00:18, 41.42it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "718it [00:19, 41.22it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "767it [00:20, 35.93it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "773it [00:20, 38.71it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "876it [00:22, 47.18it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "886it [00:23, 23.20it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "895it [00:23, 27.44it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "977it [00:26, 27.61it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1004it [00:27, 41.05it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1057it [00:28, 41.44it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 2/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 3/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "212it [00:06, 20.40it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "287it [00:08, 40.14it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "324it [00:09, 37.08it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "396it [00:11, 36.72it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "422it [00:11, 45.43it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "466it [00:12, 45.35it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "523it [00:14, 40.02it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "612it [00:16, 47.16it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "624it [00:16, 38.50it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1059it [00:28, 23.23it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:29, 36.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 3/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 4/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:00, 45.05it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "468it [00:13, 34.74it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "830it [00:22, 48.90it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "840it [00:22, 32.33it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1000it [00:26, 36.14it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1060it [00:28, 31.29it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 36.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 4/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 5/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:00, 23.29it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "166it [00:04, 45.26it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1058it [00:28, 52.12it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 5/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 6/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "409it [00:10, 32.85it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1056it [00:28, 40.77it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 6/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 7/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 7/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 8/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "786it [00:21, 34.45it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 8/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 9/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1058it [00:28, 26.06it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 36.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 9/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 10/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 10/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 11/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 11/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 12/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 12/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 13/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 13/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 14/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1060it [00:27, 43.83it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 14/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 15/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 15/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 16/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 16/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 17/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 17/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 18/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1058it [00:28, 46.75it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 18/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 19/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 19/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 20/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 20/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 21/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1059it [00:28, 39.01it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 21/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 22/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 22/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 23/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1059it [00:28, 49.23it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 23/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 24/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1057it [00:28, 42.57it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 36.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 24/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 25/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1057it [00:28, 25.29it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:29, 36.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 25/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 26/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 26/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 27/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1060it [00:28, 46.57it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 27/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 28/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1060it [00:28, 35.96it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 28/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 29/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 29/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 30/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 30/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 31/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1058it [00:28, 38.75it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 36.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 31/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 32/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1057it [00:28, 33.69it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 32/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 33/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 33/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 34/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 34/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 35/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 35/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 43.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 36/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 36/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 37/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 37/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 43.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 38/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1057it [00:27, 40.27it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 38/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 39/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1058it [00:28, 36.25it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 39/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 43.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 40/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:29, 36.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 40/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 41/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 41/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 42/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1059it [00:29, 43.99it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:29, 36.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 42/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 43/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 43/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 44/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:29, 35.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 44/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 40.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 45/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1058it [00:29, 26.52it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:29, 36.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 45/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 40.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 46/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:30, 35.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 46/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 47/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1057it [00:28, 48.30it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 36.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 47/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 48/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1057it [00:29, 44.95it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:29, 36.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 48/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 49/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 49/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 50/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 50/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 51/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1060it [00:28, 45.95it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 51/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 52/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 52/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 53/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1055it [00:29, 32.80it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:29, 35.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 53/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 40.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 54/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 54/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 55/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1056it [00:28, 51.40it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 55/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 43.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 56/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 56/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 57/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1054it [00:28, 39.72it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 36.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 57/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 58/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1057it [00:28, 37.15it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 36.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 58/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 59/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1060it [00:28, 45.91it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 36.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 59/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 60/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 37.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 60/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 43.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 61/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1055it [00:28, 36.33it/s]/home/vincenzo/anaconda3/envs/vstk/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "1061it [00:28, 37.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 61/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 42.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 62/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [00:28, 36.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 62/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:08<00:00, 41.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 63/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:02, 21.46it/s]"
     ]
    }
   ],
   "source": [
    "path = os.path.join('../experiments/contextual/', f'{model_id}_{corpus}_{task}_{datetime.now()}.ckpt')\n",
    "\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Accumulator of loss\n",
    "history = []\n",
    "validation_history = []\n",
    "best_validation_loss = torch.tensor(float('inf'), device=device)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, steps_per_epoch=len(data_loader['train']), epochs=n_epochs, anneal_strategy='linear', pct_start=0.05)\n",
    "\n",
    "estop_counter = 0\n",
    "\n",
    "# Iterate over epochs\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Starting epoch {i + 1}/{n_epochs}\")\n",
    "    # Iterate over training batches\n",
    "    for j, (embeds, weights, lbl) in tqdm(enumerate(data_loader['train'])):\n",
    "        # Zero your gradients for every batch!\n",
    "        if j % accumulation_steps == 0:\n",
    "            optimizer.zero_grad()\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        weights = weights.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds, weights)\n",
    "        # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "        logits = logits.reshape(-1, len(le[task].classes_))\n",
    "        # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "        lbl = lbl.reshape(-1)\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(logits, lbl) / accumulation_steps\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        if j + 1 % accumulation_steps == 0 or j + 1 == len(data_loader['train']):\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # Save loss\n",
    "        history.append(loss)\n",
    "    # Disable gradients\n",
    "    with torch.no_grad():\n",
    "        print(f\"Starting validation epoch {i + 1}/{n_epochs}\")\n",
    "        # Set in evaluation mode\n",
    "        model.eval()\n",
    "        # Init validation loss accumulator\n",
    "        loss = []\n",
    "        # Iterate over validation batches\n",
    "        for embeds, weights, lbl in tqdm(data_loader['validation']):\n",
    "            # Move input and output to target device\n",
    "            embeds = embeds.to(device)\n",
    "            weights = weights.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "            # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "            logits = model(embeds, weights)\n",
    "            # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "            logits = logits.reshape(-1, len(le[task].classes_))\n",
    "            # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "            lbl = lbl.reshape(-1)\n",
    "            # Compute loss\n",
    "            loss.append(F.cross_entropy(logits, lbl))\n",
    "        # Aggregate validation loss\n",
    "        validation_history.append(torch.tensor(loss, device=device).mean())\n",
    "        # Check if validation loss has improved\n",
    "        if validation_history[-1] <= best_validation_loss:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_validation_loss = validation_history[-1]\n",
    "            estop_counter = 0\n",
    "        else:\n",
    "            estop_counter += 1\n",
    "        # Restore training mode\n",
    "        model.train()\n",
    "    if estop_counter >= 5:\n",
    "        break\n",
    "        \n",
    "# Restore best weights\n",
    "if os.path.exists(path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "history = [loss.cpu().item() for loss in history]\n",
    "validation_history = [loss.cpu().item() for loss in validation_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkYAAAG2CAYAAACap0noAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABPtElEQVR4nO3deVxU5f4H8M8ZmBkYYUBRGEDADcUN9wUtl8RIvRZ1K3/mTS2zW2lqlpqV5nILS01NS+tW0kaWllwzN0TRVDQ3DMxwSYUKUFMYdoaZ5/fHHEZGQNGAgZnP+/U6L+Y855lzni8z4aezSkIIASIiIiKCwtYDICIiIqovGIyIiIiIZAxGRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKSMRgRERERyRiMiIiIiGT1JhgtWrQIkiRh2rRpN+23fv16hISEwMXFBZ07d8aWLVvqZoBERERk9+pFMDp8+DA++OADhIaG3rTfgQMHMHr0aEyYMAHHjx9HZGQkIiMjkZKSUkcjJSIiInsm2fohsnl5eejevTvef/99/Oc//0HXrl2xfPnySvuOGjUK+fn52Lx5s6Wtb9++6Nq1K9asWVNHIyYiIiJ75WzrAUyaNAkjRoxAeHg4/vOf/9y0b2JiIqZPn27VFhERgdjY2CrfU1xcjOLiYsu8yWTC1atX4eXlBUmS/tbYiYiIqG4IIZCbmws/Pz8oFLV3wMumwWjdunU4duwYDh8+XK3+mZmZ8PHxsWrz8fFBZmZmle+JiorC/Pnz/9Y4iYiIqH5IT09H8+bNa239NgtG6enpmDp1KuLi4uDi4lJr25k9e7bVXqacnBwEBgbi9OnTaNKkSa1ttz4xGAzYvXs3Bg8eDKVSaevh1BlHrJs1s2Z7xZpZc25uLlq2bAl3d/daHYPNgtHRo0dx6dIldO/e3dJmNBqxd+9erFq1CsXFxXBycrJ6j06nQ1ZWllVbVlYWdDpdldtRq9VQq9UV2ps0aQIvL6+/WUXDYDAYoNFo4OXl5TD/cQGOWTdrZs32ijWz5rL52j4NxmZXpQ0ZMgTJyclISkqyTD179sSYMWOQlJRUIRQBQFhYGOLj463a4uLiEBYWVlfDJiIiIjtmsz1G7u7u6NSpk1Vbo0aN4OXlZWkfO3Ys/P39ERUVBQCYOnUqBg4ciKVLl2LEiBFYt24djhw5gg8//LDOx09ERET2p17cx6gqaWlpyMjIsMz369cPMTEx+PDDD9GlSxds2LABsbGxFQIWERER0Z2w+eX65SUkJNx0HgAeeeQRPPLII3UzICIiuiWj0QiDwVCr2zAYDHB2dkZRURGMRmOtbqu+cMSa68NtdOpVMCIiooZDCIHMzExkZ2fXybZ0Oh3S09PrxT+edcERa5YkqVbvUVQdDEZERHRHykKRt7c3NBpNrf7jbTKZkJeXBzc3N5v/w1lXHK1mk8mEP/74A56enrDlQzkYjIiI6LYZjUZLKKqLW5+YTCaUlJTAxcXFIUIC4Jg1N2vWDDk5OTY9dOgYv2kiIqpRZecUaTQaG4+E7IlSqYQkSQxGRETUMDnKuS9UN8q+T7Y8lMZgRERERCRjMCIiIvqbWrRogeXLl1e7f0JCAiRJqvUr+qKjo+Hp6Vmr27A3DEZEROQwJEm66TRv3rw7Wu/hw4fx9NNPV7t/v379kJGRAQ8PjzvaHtUeXpVGREQOo/zTFL7++mvMnTsXqampljY3NzfLayEEjEYjnJ1v/U9ls2bNbmscKpXqpg9AJ9vhHiMiInIYOp3OMnl4eECSJMv8r7/+Cnd3d2zduhU9evSAWq3Gvn37cO7cOTzwwAPw8fGBm5sbevXqhZ07d1qt98ZDaZIk4aOPPsKDDz4IjUaD4OBgbNq0ybL8xkNpZYe8tm/fjvbt28PNzQ3Dhg1DZmam5T2lpaWYMmUKPD094eXlhVmzZmHcuHGIjIy8rd/B6tWr0bp1a6hUKrRr1w6ff/65ZZkQAvPmzUNgYCDUajX8/PwwZcoUy/L3338fwcHBcHFxgY+PDx5++OHb2nZDwGBEREQ1QgiBgpLSWpsKS4xVLqvJq5hefvllLFq0CKdOnUJoaCjy8vIwfPhwxMfH4/jx47jvvvswcuRIpKWl3XQ98+fPx6OPPoqff/4Zw4cPx5gxY3D16tUq+xcUFGDJkiX4/PPPsXfvXqSnp2POnDmW5W+99Ra+/PJLrF27Fvv374der0dsbOxt1bZx40ZMnToVL774IlJSUvDvf/8bTzzxBHbv3g0A+Pbbb7Fs2TJ88MEHOHPmDGJjY9G5c2cAwJEjRzBlyhQsWLAAqamp2LZtGwYMGHBb228IeCiNiIhqRKHBiA5zt9tk278siIBGVTP/pC1YsABDhw61zDdp0gRdunSxzC9cuBAbN27Epk2bMHny5CrXM378eIwePRoA8Oabb+Ldd9/FTz/9hPvuu6/S/gaDAWvWrEHr1q0BAJMmTcKCBQssy1euXInZs2fjwQcfBACsWrUKW7Zsua3alixZgvHjx+O5554DAEyfPh0HDx7EkiVLMHjwYKSlpUGn0yE8PBxKpRKBgYHo3bs3APOD3Rs1aoR//OMfcHd3R1BQELp163Zb228IuMeIiIionJ49e1rN5+Xl4aWXXkL79u3h6ekJNzc3nDp16pZ7jEJDQy2vGzVqBK1Wi0uXLlXZX6PRWEIRYD7sd/nyZQBATk4OsrKyLCEFAJycnNCjR4/bqu3UqVPo37+/VVv//v1x6tQpAOYHtRcWFqJVq1aYOHEiNm7ciNLSUgDA0KFDERQUhFatWuHxxx/Hl19+iYKCgtvafkPAPUZERFQjXJVO+GVBRK2s22QyIVefC3ete6WPx3BVOtXYtho1amQ1/9JLLyEuLg5LlixBmzZt4OrqiocffhglJSU3XY9SqbSalyQJJpPptvrX9Y0OAwICkJqaip07dyIuLg7PPfccFi9ejD179sDd3R3Hjh1DQkICduzYgblz52LevHk4fPiwXd0SgHuMiIioRkiSBI3KudYmV5VTlctq8w7c+/fvx/jx4/Hggw+ic+fO0Ol0uHDhQq1trzIeHh7w8fHB4cOHLW1GoxHHjh27rfW0b98e+/fvt2rbv38/OnToYJl3dXXFyJEj8e677yIhIQGJiYlITk4GADg7OyM8PBxvv/02fv75Z1y4cAG7du36G5XVP9xjREREdBPBwcH47rvvMHLkSEiShDlz5tx0z09tef755xEVFYU2bdogJCQEK1euxLVr124rFM6YMQOPPvoounXrhvDwcHz//ff47rvvLFfZRUdHw2g0ok+fPtBoNPjiiy/g6uqKoKAgbN68Gb/99hsGDBiAxo0bY8uWLTCZTGjXrl1tlWwTDEZEREQ38c477+DJJ59Ev3790LRpU8yaNQt6vb7OxzFr1ixkZmZi7NixcHJywtNPP42IiAg4OVX/MGJkZCRWrFiBJUuWYOrUqWjZsiXWrl2LQYMGAQA8PT2xaNEiTJ8+HUajEZ07d8b3338PLy8veHp64rvvvsO8efNQVFSE4OBgfPXVV+jYsWMtVWwbkrDlk9psQK/Xw8PDA1euXIGXl5eth1MnDAYDtmzZguHDh1c4hm3PHLFu1sya60pRURHOnz+Pli1bwsXFpda3ZzKZoNfrodVqKz3HyB7dqmaTyYT27dvj0UcfxcKFC20wwppXUFCAU6dOoW3btnB3d7daVvbvd05ODrRaba2NgXuMiIiIGoCLFy9ix44dGDhwIIqLi7Fq1SqcP38ejz32mK2HZlccI3YTERE1cAqFAtHR0ejVqxf69++P5ORk7Ny5E+3bt7f10OwK9xgRERE1AAEBARWuKKOaxz1GRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKSMRgRERHdpkGDBmHatGmW+RYtWmD58uU3fY8kSYiNjf3b266p9dzMvHnz0LVr11rdRn3FYERERA5j5MiRuO+++ypd9uOPP0KSJPz888+3vd7Dhw/j6aef/rvDszJ//nzcfffdFdozMjIwbNiwGt0WXcdgREREDmPChAmIi4vD77//XmHZ2rVr0bNnT4SGht72eps1awaNRlMTQ7wlnU4HtVpdJ9tyRAxGRETkMP7xj3+gWbNmiI6OtmrPy8vD+vXrMWHCBPz1118YPXo0/P39odFo0LlzZ3z11Vc3Xe+Nh9LOnDmDAQMGwMXFBR06dEBcXFyF98yaNQtt27aFRqNBq1atMGfOHBgMBgBAdHQ0FixYgJSUFDg5OUGSJMuYbzyUlpycjHvuuQeurq7w8vLC008/jby8PMvy8ePHIzIyEkuWLIGvry+8vLwwadIky7aqw2QyYcGCBWjevDnUajW6du2Kbdu2WZaXlJRg8uTJ8PX1hYuLC4KCghAVFQUAEEJg3rx5CAwMhFqthp+fH6ZMmVLtbdc1PhKEiIhqhhCAoaB21m0ymddd4gRU8qR5KDWAJN1yNc7Ozhg7diyio6Px6quvQpLfs379ehiNRowePRp5eXno0aMHZs2aBa1Wix9++AGPP/44Wrdujd69e1djqCY89NBD8PHxwaFDh5CTk2N1PlIZd3d3REdHw8/PD8nJyZg4cSLc3d0xc+ZMjBo1CsnJydiyZQvi4+OhUCjg4eFRYR35+fmIiIhAWFgYDh8+jEuXLuGpp57C5MmTrcLf7t274evri927d+Ps2bMYNWoUunbtiokTJ96yHgBYsWIFli5dig8++ADdunXDJ598gvvvvx8nT55EcHAw3n33XWzatAnffPMNAgMDkZ6ejvT0dADAt99+i2XLlmHdunXo2LEjMjMzceLEiWpt1xYYjIiIqGYYCoA3/Wpl1QoAnjfr8MqfgKpRtdb15JNPYvHixdizZw8GDRoEwHwY7Z///Cc8PDzg4eGBl156ydL/+eefx/bt2/HNN99UKxjt3LkTv/76K7Zv3w4/P/Pv480336xwXtBrr71med2iRQu89NJLWLduHWbOnAlXV1e4ubnB2dkZOp0OisrCIICYmBgUFRXhs88+Q6NG5vpXrVqFkSNH4q233oKPjw8AoHHjxli1ahWcnJwQEhKCESNGID4+vtrBaMmSJZg1axb+7//+DwDw1ltvYffu3Vi+fDnee+89pKWlITg4GHfddRckSUJQUJDlvWlpadDpdAgPD4dSqURgYGC1fo+2wkNpRETkUEJCQtCvXz988sknAICzZ8/ixx9/xIQJEwAARqMRCxcuROfOndGkSRO4ublh+/btSEtLq9b6T506hYCAAEsoAoCwsLAK/b7++mv0798fOp0Obm5ueO2116q9jfLb6tKliyUUAUD//v1hMpmQmppqaevYsSOcnJws876+vrh06VK1tqHX6/Hnn3+if//+Vu39+/fHqVOnAJgP1yUlJaFdu3aYMmUKduzYYen3yCOPoLCwEK1atcLEiROxceNGlJaW3laddYl7jIiIqGYoNeY9N7XAZDJBn5sLrbt75XtPlLd34vOECRPw/PPP47333sPatWvRunVrDBw4EACwePFirFixAsuXL0fnzp3RqFEjTJs2DSUlJTVRCgAgMTERY8aMwfz58xEREQEPDw+sW7cOS5curbFtlKdUKq3mJUmCyWSqsfV3794d58+fx9atW7Fz5048+uijCA8Px4YNGxAQEIDU1FTs3LkTcXFxeO655yx77G4cV31g0z1Gq1evRmhoKLRaLbRaLcLCwrB169Yq+0dHR0OSJKvJxcWlDkdMRERVkiTz4azampSaqpdV4/yi8h599FEoFArExMTgs88+w5NPPmk532j//v144IEH8K9//QtdunRBq1atcPr06Wqvu3379khPT0dGRoal7eDBg1Z9Dhw4gKCgILz66qvo2bMngoODcfHiRas+KpUKRqPxlts6ceIE8vPzLW379++HQqFAu3btqj3mm9FqtfDz88P+/fut2vfv348OHTpY9Rs1ahT++9//4uuvv8a3336Lq1evAgBcXV0xcuRIvPvuu0hISEBiYiKSk5NrZHw1zaZ7jJo3b45FixYhODgYQgh8+umneOCBB3D8+HF07Nix0vdotVqr3YPSbf7HQERE5ObmhlGjRmH27NnQ6/UYP368ZVlwcDA2bNiAAwcOoHHjxnjnnXeQlZVlFQJuJjw8HG3btsW4ceOwePFi6PV6vPrqq1Z9goODkZaWhnXr1qFXr1744YcfsHHjRqs+QUFBSEtLQ1JSEgIDA+Hu7l7hMv0xY8bg9ddfx7hx4zBv3jxcvnwZzz//PB5//HHL+UU1YcaMGXj99dfRunVrdO3aFWvXrkVSUhK+/PJLAMA777wDX19fdOvWDQqFAuvXr4dOp4Onpyeio6NhNBrRp08faDQafPHFF3B1dbU6D6k+sekeo5EjR2L48OEIDg5G27Zt8cYbb8DNza1Csi5PkiTodDrLVJMfPBEROY4JEybg2rVriIiIsDof6LXXXkP37t0RERGBQYMGQafTITIystrrVSgU2LhxIwoLC9G7d2889dRTeOONN6z63H///XjhhRcwefJkdO3aFQcOHMCcOXOs+vzzn//EkCFDMGTIEDRr1qzSWwZoNBps374dV69eRa9evfDwww9jyJAhWLVq1e39Mm5hypQpmD59Ol588UV07twZ27Ztw6ZNmxAcHAzAfIXd22+/jZ49e6JXr164cOECtmzZAoVCAU9PT/z3v/9F//79ERoaip07d+L777+Hl5dXjY6xpkhCCGHrQQDmk93Wr1+PcePG4fjx45Um8+joaDz11FPw9/eHyWRC9+7d8eabb1a5dwkAiouLUVxcbJnX6/UICAhARkZGvf1QaprBYEBcXByGDh1aL4/n1hZHrJs1s+a6UlRUhPT0dLRo0aJOTmkQQiA3Nxfu7u4Oc6TAEWsuLCzEr7/+ilatWsHNzc1qmV6vR9OmTZGTkwOtVltrY7B5MEpOTkZYWBiKiorg5uaGmJgYDB8+vNK+iYmJOHPmDEJDQ5GTk4MlS5Zg7969OHnyJJo3b17pe+bNm4f58+dXaI+Jiamzu5QSEdmbssvIAwICoFKpbD0cshMlJSVIT09HZmZmhSvXCgoK8Nhjj9l/MCopKUFaWhpycnKwYcMGfPTRR9izZ0+1juUaDAa0b98eo0ePxsKFCyvtwz1G9eP/Lm3BEetmzay5rnCPUe1zxJrrwx4jm1+ur1Kp0KZNGwBAjx49cPjwYaxYsQIffPDBLd+rVCrRrVs3nD17tso+arW60mfKKJVKh/kjWsYRawYcs27W7BhsWbPRaIQkSVAoFFXefLAmlV1aXrZNR+CINZcFQGdn5wrf7br6rte737TJZLLaw3MzRqMRycnJ8PX1reVRERERkSOw6R6j2bNnY9iwYQgMDERubi5iYmKQkJCA7du3AwDGjh0Lf39/y4PoFixYgL59+6JNmzbIzs7G4sWLcfHiRTz11FO2LIOIyGHVk+t3yE6UfZ9seejQpsHo0qVLGDt2LDIyMuDh4YHQ0FBs374dQ4cOBWB+vkr53YfXrl3DxIkTkZmZicaNG6NHjx44cOBAte8tQURENaPssEZBQQFcXV1tPBqyFwaDAUIIq8eX1DWbBqOPP/74pssTEhKs5pctW4Zly5bV4oiIiKg6nJyc4OnpaXnelkajqdX/yzeZTCgpKUFRUZHDnG/jaDWbTCZcvnwZBQUFjhuMiIio4dLpdABQ7YeR/h1CCBQWFsLV1dVhrtByxJolSUJOTo7jHkojIqKGS5Ik+Pr6wtvbGwaDoVa3ZTAYsHfvXgwYMMBhrj50xJolSbJ67JctMBgREdHf4uTkVOuHPpycnFBaWgoXFxeHCQmOWHNtB+zqsP+DlkRERETVxGBEREREJGMwIiIiIpIxGBERERHJGIyIiIiIZAxGRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKSMRgRERERyRiMiIiIiGQMRkREREQyBiMiIiIiGYMRERERkYzBiIiIiEjGYEREREQkYzAiIiIikjEYEREREckYjIiIiIhkDEZEREREMgYjIiIiIhmDEREREZGMwYiIiIhIxmBEREREJGMwIiIiIpIxGBERERHJGIyIiIiIZAxGRERERDIGIyIiIiIZgxERERGRzKbBaPXq1QgNDYVWq4VWq0VYWBi2bt160/esX78eISEhcHFxQefOnbFly5Y6Gi0RERHZO5sGo+bNm2PRokU4evQojhw5gnvuuQcPPPAATp48WWn/AwcOYPTo0ZgwYQKOHz+OyMhIREZGIiUlpY5HTkRERPbIpsFo5MiRGD58OIKDg9G2bVu88cYbcHNzw8GDByvtv2LFCtx3332YMWMG2rdvj4ULF6J79+5YtWpVHY+ciIiI7FG9OcfIaDRi3bp1yM/PR1hYWKV9EhMTER4ebtUWERGBxMTEuhgiERER2TlnWw8gOTkZYWFhKCoqgpubGzZu3IgOHTpU2jczMxM+Pj5WbT4+PsjMzKxy/cXFxSguLrbM6/V6AIDBYIDBYKiBCuq/sjodpd4yjlg3a3YMrNkxsObKl9U2mwejdu3aISkpCTk5OdiwYQPGjRuHPXv2VBmObldUVBTmz59foX337t3QaDQ1so2GIi4uztZDsAlHrJs1OwbW7BhYs1lBQUGdbNvmwUilUqFNmzYAgB49euDw4cNYsWIFPvjggwp9dTodsrKyrNqysrKg0+mqXP/s2bMxffp0y7xer0dAQAAGDx4MLy+vGqqifjMYDIiLi8PQoUOhVCptPZw644h1s2bWbK9YM2suO+JT22wejG5kMpmsDn2VFxYWhvj4eEybNs3SFhcXV+U5SQCgVquhVqsrtCuVSof5opVxxJoBx6ybNTsG1uwYWPP1trpg02A0e/ZsDBs2DIGBgcjNzUVMTAwSEhKwfft2AMDYsWPh7++PqKgoAMDUqVMxcOBALF26FCNGjMC6detw5MgRfPjhh7Ysg4iIiOyETYPRpUuXMHbsWGRkZMDDwwOhoaHYvn07hg4dCgBIS0uDQnH9wrl+/fohJiYGr732Gl555RUEBwcjNjYWnTp1slUJREREZEdsGow+/vjjmy5PSEio0PbII4/gkUceqaURERERkSOrN/cxIiIiIrI1BiMiIiIiGYMRERERkYzBiIiIiEjGYEREREQkYzAiIiIikjEYEREREckYjIiIiIhkDEZEREREMgYjIiIiIhmDEREREZGMwYiIiIhIxmBEREREJGMwIiIiIpIxGBERERHJGIyIiIiIZAxGRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKSMRgRERERyRiMiIiIiGQMRkREREQyBiMiIiIiGYMRERERkYzBiIiIiEjGYEREREQkYzAiIiIikjEYEREREckYjIiIiIhkDEZEREREMgYjIiIiIhmDEREREZGMwYiIiIhIZtNgFBUVhV69esHd3R3e3t6IjIxEamrqTd8THR0NSZKsJhcXlzoaMREREdkzmwajPXv2YNKkSTh48CDi4uJgMBhw7733Ij8//6bv02q1yMjIsEwXL16soxETERGRPXO25ca3bdtmNR8dHQ1vb28cPXoUAwYMqPJ9kiRBp9PV9vCIiIjIwdg0GN0oJycHANCkSZOb9svLy0NQUBBMJhO6d++ON998Ex07dqy0b3FxMYqLiy3zer0eAGAwGGAwGGpo5PVbWZ2OUm8ZR6ybNTsG1uwYWHPly2qbJIQQdbKlWzCZTLj//vuRnZ2Nffv2VdkvMTERZ86cQWhoKHJycrBkyRLs3bsXJ0+eRPPmzSv0nzdvHubPn1+hPSYmBhqNpkZrICIiotpRUFCAxx57DDk5OdBqtbW2nXoTjJ599lls3boV+/btqzTgVMVgMKB9+/YYPXo0Fi5cWGF5ZXuMAgICkJGRAS8vrxoZe31nMBgQFxeHoUOHQqlU2no4dcYR62bNrNlesWbWrNfr0bRp01oPRvXiUNrkyZOxefNm7N2797ZCEQAolUp069YNZ8+erXS5Wq2GWq2u9H2O8kUr44g1A45ZN2t2DKzZMbDm6211waZXpQkhMHnyZGzcuBG7du1Cy5Ytb3sdRqMRycnJ8PX1rYUREhERkSOx6R6jSZMmISYmBv/73//g7u6OzMxMAICHhwdcXV0BAGPHjoW/vz+ioqIAAAsWLEDfvn3Rpk0bZGdnY/Hixbh48SKeeuopm9VBRERE9sGmwWj16tUAgEGDBlm1r127FuPHjwcApKWlQaG4vmPr2rVrmDhxIjIzM9G4cWP06NEDBw4cQIcOHepq2ERERGSnbBqMqnPed0JCgtX8smXLsGzZsloaERERETkyPiuNiIiISMZgRERERCRjMCIiIiKSMRgRERERyRiMiIiIiGQMRkREREQyBiMiIiIiGYMRERERkYzBiIiIiEjGYEREREQkYzAiIiIikjEYEREREckYjIiIiIhkDEZEREREMgYjIiIiIhmDEREREZGMwYiIiIhIxmBEREREJGMwIiIiIpIxGBERERHJGIyIiIiIZAxGRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKS3VEwSk9Px++//26Z/+mnnzBt2jR8+OGHNTYwIiIiorp2R8Hosccew+7duwEAmZmZGDp0KH766Se8+uqrWLBgQY0OkIiIiKiu3FEwSklJQe/evQEA33zzDTp16oQDBw7gyy+/RHR0dE2Oj4iIiKjO3FEwMhgMUKvVAICdO3fi/vvvBwCEhIQgIyOj5kZHREREVIfuKBh17NgRa9aswY8//oi4uDjcd999AIA///wTXl5eNTpAIiIiorpyR8HorbfewgcffIBBgwZh9OjR6NKlCwBg06ZNlkNsRERERA2N8528adCgQbhy5Qr0ej0aN25saX/66aeh0WhqbHBEREREdemO9hgVFhaiuLjYEoouXryI5cuXIzU1Fd7e3jU6QCIiIqK6ckfB6IEHHsBnn30GAMjOzkafPn2wdOlSREZGYvXq1dVeT1RUFHr16gV3d3d4e3sjMjISqampt3zf+vXrERISAhcXF3Tu3Blbtmy5kzKIiIiIrNxRMDp27BjuvvtuAMCGDRvg4+ODixcv4rPPPsO7775b7fXs2bMHkyZNwsGDBxEXFweDwYB7770X+fn5Vb7nwIEDGD16NCZMmIDjx48jMjISkZGRSElJuZNSiIiIiCzu6ByjgoICuLu7AwB27NiBhx56CAqFAn379sXFixervZ5t27ZZzUdHR8Pb2xtHjx7FgAEDKn3PihUrcN9992HGjBkAgIULFyIuLg6rVq3CmjVr7qQcIiIiIgB3GIzatGmD2NhYPPjgg9i+fTteeOEFAMClS5eg1WrveDA5OTkAgCZNmlTZJzExEdOnT7dqi4iIQGxsbKX9i4uLUVxcbJnX6/UAzPdiMhgMdzzWhqSsTkept4wj1s2aHQNrdgysufJltU0SQojbfdOGDRvw2GOPwWg04p577kFcXBwA8zlDe/fuxdatW297ICaTCffffz+ys7Oxb9++KvupVCp8+umnGD16tKXt/fffx/z585GVlVWh/7x58zB//vwK7TExMbyCjoiIqIEoKCjAY489hpycnL+1E+ZW7miP0cMPP4y77roLGRkZlnsYAcCQIUPw4IMP3tFAJk2ahJSUlJuGojsxe/Zsqz1Mer0eAQEBGDx4sMPcjNJgMCAuLg5Dhw6FUqm09XDqjCPWzZpZs71izay57IhPbbujYAQAOp0OOp0Ov//+OwCgefPmd3xzx8mTJ2Pz5s3Yu3cvmjdvfsvt3rhnKCsrCzqdrtL+arXa8viS8pRKpcN80co4Ys2AY9bNmh0Da3YMrPl6W124o6vSTCYTFixYAA8PDwQFBSEoKAienp5YuHAhTCZTtdcjhMDkyZOxceNG7Nq1Cy1btrzle8LCwhAfH2/VFhcXh7CwsNuug4iIiKi8O9pj9Oqrr+Ljjz/GokWL0L9/fwDAvn37MG/ePBQVFeGNN96o1nomTZqEmJgY/O9//4O7uzsyMzMBAB4eHnB1dQUAjB07Fv7+/oiKigIATJ06FQMHDsTSpUsxYsQIrFu3DkeOHMGHH354J6UQERERWdxRMPr000/x0Ucf4f7777e0hYaGwt/fH88991y1g1HZzSAHDRpk1b527VqMHz8eAJCWlgaF4vqOrX79+iEmJgavvfYaXnnlFQQHByM2NhadOnW6k1KIiIiILO4oGF29ehUhISEV2kNCQnD16tVqr6c6F8QlJCRUaHvkkUfwyCOPVHs7RERERNVxR+cYdenSBatWrarQvmrVKoSGhv7tQRERERHZwh3tMXr77bcxYsQI7Ny503LSc2JiItLT0/ncMiIiImqw7miP0cCBA3H69Gk8+OCDyM7ORnZ2Nh566CGcPHkSn3/+eU2PkYiIiKhO3PF9jPz8/CqcZH3ixAl8/PHHvEKMiIiIGqQ72mNEREREZI8YjIiIiIhkDEZEREREsts6x+ihhx666fLs7Oy/MxYiIiIim7qtYOTh4XHL5WPHjv1bAyIiIiKyldsKRmvXrq2tcRARERHZHM8xIiIiIpIxGBERERHJGIyIiIiIZAxGRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKSMRgRERERyRiMiIiIiGQMRkREREQyBiMiIiIiGYMRERERkYzBiIiIiEjGYEREREQkYzAiIiIikjEYEREREckYjIiIiIhkDEZEREREMgYjIiIiIhmDEREREZGMwYiIiIhIxmBEREREJGMwIiIiIpLZNBjt3bsXI0eOhJ+fHyRJQmxs7E37JyQkQJKkClNmZmbdDJiIiIjsmk2DUX5+Prp06YL33nvvtt6XmpqKjIwMy+Tt7V1LIyQiIiJH4mzLjQ8bNgzDhg277fd5e3vD09Oz5gdEREREDs2mwehOde3aFcXFxejUqRPmzZuH/v37V9m3uLgYxcXFlnm9Xg8AMBgMMBgMtT7W+qCsTkept4wj1s2aHQNrdgysufJltU0SQog62dItSJKEjRs3IjIysso+qampSEhIQM+ePVFcXIyPPvoIn3/+OQ4dOoTu3btX+p558+Zh/vz5FdpjYmKg0WhqavhERERUiwoKCvDYY48hJycHWq221rbToIJRZQYOHIjAwEB8/vnnlS6vbI9RQEAAMjIy4OXl9XeG3GAYDAbExcVh6NChUCqVth5OnXHEulkza7ZXrJk16/V6NG3atNaDUYM8lFZe7969sW/fviqXq9VqqNXqCu1KpdJhvmhlHLFmwDHrZs2OgTU7BtZ8va0uNPj7GCUlJcHX19fWwyAiIiI7YNM9Rnl5eTh79qxl/vz580hKSkKTJk0QGBiI2bNn448//sBnn30GAFi+fDlatmyJjh07oqioCB999BF27dqFHTt22KoEIiIisiM2DUZHjhzB4MGDLfPTp08HAIwbNw7R0dHIyMhAWlqaZXlJSQlefPFF/PHHH9BoNAgNDcXOnTut1kFERER0p2wajAYNGoSbnfsdHR1tNT9z5kzMnDmzlkdFREREjqrBn2NEREREVFMYjIiIiIhkDEZEREREMgYjIiIiIhmDEREREZGMwYiIiIhIxmBEREREJGMwIiIiIpIxGBERERHJGIyIiIiIZAxGRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKSMRgRERERyRiMiIiIiGQMRkREREQyBiMiIiIiGYMRERERkYzBiIiIiEjGYEREREQkYzAiIiIikjEYEREREckYjIiIiIhkDEZEREREMgYjIiIiIhmDEREREZGMwYiIiIhIxmBEREREJGMwIiIiIpIxGBERERHJGIyIiIiIZAxGRERERDKbBqO9e/di5MiR8PPzgyRJiI2NveV7EhIS0L17d6jVarRp0wbR0dG1Pk4iIiJyDDYNRvn5+ejSpQvee++9avU/f/48RowYgcGDByMpKQnTpk3DU089he3bt9fySImIiMgRONty48OGDcOwYcOq3X/NmjVo2bIlli5dCgBo37499u3bh2XLliEiIqK2hklEREQOwqbB6HYlJiYiPDzcqi0iIgLTpk2r8j3FxcUoLi62zOv1egCAwWCAwWColXHWN2V1Okq9ZRyxbtbsGFizY2DNlS+rbQ0qGGVmZsLHx8eqzcfHB3q9HoWFhXB1da3wnqioKMyfP79C++7du6HRaGptrPVRXFycrYdgE45YN2t2DKzZMbBms4KCgjrZdoMKRndi9uzZmD59umVer9cjICAAgwcPhpeXlw1HVncMBgPi4uIwdOhQKJVKWw+nzjhi3ayZNdsr1syay4741LYGFYx0Oh2ysrKs2rKysqDVaivdWwQAarUaarW6QrtSqXSYL1oZR6wZcMy6WbNjYM2OgTVfb6sLDeo+RmFhYYiPj7dqi4uLQ1hYmI1GRERERPbEpsEoLy8PSUlJSEpKAmC+HD8pKQlpaWkAzIfBxo4da+n/zDPP4LfffsPMmTPx66+/4v3338c333yDF154wRbDJyIiIjtj02B05MgRdOvWDd26dQMATJ8+Hd26dcPcuXMBABkZGZaQBAAtW7bEDz/8gLi4OHTp0gVLly7FRx99xEv1iYiIqEbY9ByjQYMGQQhR5fLK7mo9aNAgHD9+vBZHRURERI6qQZ1jRERERFSbGIyIiIiIZAxGRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKSMRgRERERyRiM6lJhNmAy2noUREREVAWbPhLE4Wz8N/BbAuDVBmgaDDRte33yagOoNLYeIRERkUNjMKpL1y4ApUVAVop5upFHoDkwNWtnHZwaNQMkqc6HS0RE5GgYjOrSsweA7IvAlTPAldPA5VT5dSpQeA3ISTNP5+Kt3+fiWW7vUllwagt4BgFO/AiJiIhqCv9VrUsKJ6BJK/PUNsJ6Wf5f5rB0JfV6cLpyGrh2ESjKBn7/yTxZrU8JeLW2PiRXtqdJ7VZnZREREdkLBqP6opEX0CgMCAqzbjcUAn+dk4OSvHfpymngylmgtBC4/Kt5upHW3xKSFI3boGnuVSC/F+DpVzf1EBERNUAMRvWd0hXQdTJP5ZlMgP53+ZDc6XLB6TSQfwnQ/2GefkuAE4D+ALB8ERDYD+j8T6BDJNCoad3XQ0REVI8xGDVUCgXgGWie2oRbLyu4Cvx11nI4znQpFQVpx+FWnAWkHTBPW2YCrQcDnf4JhPwDcNHapg4iIqJ6hMHIHmmaAJreQEBvAIDRYED8li0YfldXKFM3AckbgIwk4OxO8+Q0DWh7L9DpYfO5T0pXmw6fiIjIVhiMHInWD+j3vHn66xyQ8q05JF1JBU59b55UbkDICHNIaj0YcFLaetRERER1hsHIUXm1BgbOBAbMMN9TKXkDkPKd+XYBP39tnlybAB0eADo/bD43ScEbpRMRkX1jMHJ0kgToOpun8HlA+k9Aygbg5EYg/zJwdK15cvcDOj1knvy684aTRERklxiM6DpJAgL7mKeIKODCj+aQ9Mv3QO6fQOIq89Sklfmk7U4PA94hth41ERFRjWEwoso5OZvPMWo9GBjxjvkk7eQNQOpW4OpvwN7F5smnk7wn6Z9A4xa2GasQ5ivxym5RoP8DyPkDTjm/o9/5ZDj/923zc+iUroCqkfmnUlPutfxTpbnhdbmp/LyzmnvMiIjsFIMR3Zqz2nxCdsgIoDgPOL3NHJLO7rz+3Lf4BUDzXua9SB0fBNx9ambbQpgflyKHnevh508g5/frr0uLKrxVAaAZAOTVzFAsJEXlgckqeDUyL3NtbD5M6dfNfNNNBioionqNwYhuj9rNfDJ254fNe2lOfW8+3Hb+R+D3w+Zp+2ygxd3mPu1HmsNBZYQwP+4kx3pPD/R/mm9eqf/TPF9aWL2xaZoCHv6Atjmg9YPRzRdJv11Cl7DBcBalgKEAKMk3303cIP8sKTC3GwqsX1vm5b4lBYDJII/bBJTkmaf82/jdaZqaA5JfN8Cvq/mnuy/DEhFRPcJgRHdO0wToMc485WaaT9hO3gD8cQQ4v8c8bZ5uvgFlq4FAwV/l9vT8aQ5ChoJqbsvLvMfFwxx6oPWX5/3N8+5+gNLF6i0mgwG/Z29BaOshgLIGbjtgNMihqbBcwCqwfn1jwMrNAP48AVz6BSi4ApyNM09lGnlXEpZ0f3+sRER0RxiMqGa464C+z5qnq+eBk98Byd8Cl04Cp7eap6q4NrHa02N+XTbJIeiG0GMTTkrAyQNw8bj99xoKgayTwJ/HgT+TzD8v/2p+fMuZ7eapjLsv4NvVOiy5eddQEUREdDMMRlTzmrQE7n7RPF06Zd6LdOmU+bwjqz09cvBxhDttK12B5j3NU5mSAvP5WeXD0pVU816m3AzrMOnuZ71nybcr4NasjosgIrJ/DEZUu7zbA0Pm2HoU9ZNKY35si/zoFgDmw3KZyTeEpdPm2yWk/gmk/nC9r7b59T1Kfl0B326Ais+8IyL6OxiMiOoTVSMgsK95KlOcWzEs/XVGPkH9d+DXzZauzh4B6CXpoDhwBtB1BJxdzFcVOqmuT85lr9Xy4UGVuY/Cqe7rrYoQgLHEfLVhqfzTMl+urbQYUkkBml89BCnpGiDkE+TdvAE3H/PkrnOMvZJEVCMYjIjqO7U7ENTPPJUp0gOZP8thSQ5MV89BykmHH9KB3YdvfzuSQg5L5cNTZYFKdT1MOSkrBiwnJSA5lQsyxfJUVDHslBYDxnLLLSGouNrDdgbQAwAu3ux3qC0XlHyuv7bM68yvNU14lSCRg2MwImqIXLRAi7vMU5nCbJT+fgypu9ehvUcRFNkXzUHEWGIOHMZKpvKEyXxrhNJCoPq5pG44qa/v/bJMLoCTCiYnFa5k56Kpjz8UKldzHXmXgLwsIDdLrkdvnv46c/PtKJQ37G26MUTJAcrN2zwGIrI7DEZE9sLVE6LF3Tjrk4u2w4dDcatbFAhhvgVB+aBUWiy3FcttBrmtfKCqpM3yPnneZKw0xFiHm2q2OaluuhfHaDAgccsWDK+sZiHMgSjvkvmWEnlZ16fcLCAv8/qywqvme1WV3VPrlr/vxpXveXLXybeQ0JmvMORhPKIGhcGIyFFJkvnwmLPK1iOpPZJkvr2CiwfQNPjmfUtLzLdPqCw05V2ynjcZzHdkL7xmvu3Czbg2NgeksklbyetGzerXOV5EDozBiIgIMAdEj+bm6WbKHlOTl1VJaMowt+n/NL8uLboeoC79UvU6JSfzXqfKQpO77/U9UGotz4EiqmX1Ihi99957WLx4MTIzM9GlSxesXLkSvXv3rrRvdHQ0nnjiCas2tVqNoqKKz8oiIqpxkmQ+SVvTxHw7iqqUPfJGn3H93lS5Gdbz+gzzXiphNN+SIffPm29b2Qhw18HJXYfuegFF/E+AZ3NzaNI0LduweduV/kQ1+tziZ1ltlp8CgHT9UOgtf7oACsXt/c6J6pDNg9HXX3+N6dOnY82aNejTpw+WL1+OiIgIpKamwtu78rv9arVapKamWuYl/h8UEdU3kmQ+jObaGPDpUHU/Y6k5HFUWmsoHqqIc83P7rp6D4uo5BADAwQN1VU3NsjqPrHo/FQoVOvzxBxR7fgbUmuvLlRrAxRNw9bz+07Uxz+2iO2bzYPTOO+9g4sSJlr1Aa9aswQ8//IBPPvkEL7/8cqXvkSQJOh2fJ0VEdsDJWX70jR/gf5N+Jfnmw3S5GSi9lo5fDyegfXMPOJUd0iu8KneU5MNtlf0sv/xWfW/2s+ztchuE9S0YLPebKjcvTNffV3aS/m1c/egEIBgALv1wi55lb1BfD0nlA5NViGpc+Wt7Pu+ObsmmwaikpARHjx7F7NmzLW0KhQLh4eFITEys8n15eXkICgqCyWRC9+7d8eabb6Jjx451MWQiIttQNQK8WgNerSH8DTiXpkG7ocPhVBMPSK5tQgCm0huCU3HF8HSTn8biApw/cwotA/3gZCq5vqykwHzIsjDbfC5XUbY5hBmLr1+BeLuUjSrugbK89rwepFRu5sOgplLzlZgm4w3zpeaxmEqraCubN15/f1lfYYRTqQHdf0+H08bvAAjrPsJoXk/5Q52W13K7MJVbZrJedtvvwfXXkpP5+6h2M99nTSX/tLx2k39qy72+YbmyUb09pGrTYHTlyhUYjUb4+PhYtfv4+ODXXyu/0qNdu3b45JNPEBoaipycHCxZsgT9+vXDyZMn0bx5xZMmi4uLUVx8/X9L9Ho9AMBgMMBgMNRgNfVXWZ2OUm8ZR6ybNTuGBluzwgVQuQCq238Qs8FgwMnCOPgNGQrlzcKgEEBJniUkSWWhqex1UQ5QeA1SUY65rfCaua0o29wGmA9ZGvKrd9uGWqQAzIdMr9l0GLVCQDKHKzk0CTkwSc4adP8rD9iyC0YXrSVMCZUbSg11c+WmJETZWXR1788//4S/vz8OHDiAsLAwS/vMmTOxZ88eHDp06JbrMBgMaN++PUaPHo2FCxdWWD5v3jzMnz+/QntMTAw0Gs3fK4CIiOyHMEFpLIDSmA9VaT6URvOkMhZAWZp3w+sCOJuKIKCAkBQQkpPltancayEpIOB0/fUNy0yQ2yRFlesCFDBV8n5AMu/IkRTyafGSOXDIhzsF5D0yktxebrm5v3m5kMotgyTPo9zr8u8FJCHgbCyEs6kIzsYi+WdhFT/Ny5Xl2su2frv0xQIei3KRk5MDrbb2ngtp0z1GTZs2hZOTE7KyrHd1ZmVlVfscIqVSiW7duuHs2bOVLp89ezamT59umdfr9QgICMDgwYPh5eV154NvQAwGA+Li4jB06C3+T8vOOGLdrJk12yvWbB81lwoBGArMe/VK8oDiPEgluUCxed5UmIMzKcfQNsgPCmMBpOLr/Uw52QB21/oYbRqMVCoVevTogfj4eERGRgIATCYT4uPjMXny5Gqtw2g0Ijk5GcOHD690uVqthlpd8db9SqXSbr5o1eWINQOOWTdrdgys2THYXc0qFdDIs9JFBoMBZy/7ou09Fc+fU+j1wJTbPwx7u2x+Vdr06dMxbtw49OzZE71798by5cuRn59vuUpt7Nix8Pf3R1RUFABgwYIF6Nu3L9q0aYPs7GwsXrwYFy9exFNPPWXLMoiIiMgO2DwYjRo1CpcvX8bcuXORmZmJrl27Ytu2bZYTstPS0qAod+b6tWvXMHHiRGRmZqJx48bo0aMHDhw4gA4dbnKfECIiIqJqsHkwAoDJkydXeegsISHBan7ZsmVYtmxZHYyKiIiIHE39vIkAERERkQ0wGBERERHJGIyIiIiIZAxGRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKSMRgRERERyRiMiIiIiGQMRkREREQyBiMiIiIiGYMRERERkYzBiIiIiEjGYEREREQkYzAiIiIikjEYEREREckYjIiIiIhkDEZEREREMgYjIiIiIhmDEREREZGMwYiIiIhIxmBEREREJGMwIiIiIpIxGBERERHJGIyIiIiIZAxGRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKSMRgRERERyRiMiIiIiGQMRkREREQyZ1sPAADee+89LF68GJmZmejSpQtWrlyJ3r17V9l//fr1mDNnDi5cuIDg4GC89dZbGD58+G1tc9G2VKgbueNagQFhrbzQqlkj5Bcbkfx7Nj7Y+xueGdgaW5IzcOZSHlyUCiwf1Q1qZwW0rkrsSb0EX09X9GnZBFtTMhH3SxZeHdEefp6uOHbxGr479jsOnb+KSYPboLO/BwKbaHDi92woJAnuLs4I9nGHm9oZ3x37Ha2buSFE544SowkqJwWcFBKUzgpIAJwV5vnLecVwd3FGblEpFBKgUTpD6SxBggQAOHc5D1uSM/DvAa0BAAWGUvx+rRAd/bQoNQkoTEaUGAEhhKX+UqMJzk7mXFxkMMJF6QQhBCRJsvQzCcBJIVn6lhpNAMxtkmTetsFogtEk4KJ0sqzLWSFZ9RNCwGAUUDk3/BwuhECpSUDp1PBrISKqLpNJQCH/bbd3kij/r6UNfP311xg7dizWrFmDPn36YPny5Vi/fj1SU1Ph7e1dof+BAwcwYMAAREVF4R//+AdiYmLw1ltv4dixY+jUqdMtt6fX6+Hh4YGAad9AodbURklERERUw0zFBUhf/ihycnKg1WprbTs2D0Z9+vRBr169sGrVKgCAyWRCQEAAnn/+ebz88ssV+o8aNQr5+fnYvHmzpa1v377o2rUr1qxZc8vtMRgRERE1PHUVjGx6KK2kpARHjx7F7NmzLW0KhQLh4eFITEys9D2JiYmYPn26VVtERARiY2Mr7V9cXIzi4mLLfE5ODgDzL5iIiIgahrJ/t2t7f45Ng9GVK1dgNBrh4+Nj1e7j44Nff/210vdkZmZW2j8zM7PS/lFRUZg/f36F9j9Wj7+zQRMREZHN5ObmwsPDo9bWXy9Ovq5Ns2fPttrDlJ2djaCgIKSlpdXqL7Y+0ev1CAgIQHp6eq3ufqxvHLFu1sya7RVrZs1CCOTm5sLPz69Wx2DTYNS0aVM4OTkhKyvLqj0rKws6na7S9+h0utvqr1aroVarK7R7eHg4zBetjFardbiaAcesmzU7BtbsGFjzdXWxQ8Om1xyrVCr06NED8fHxljaTyYT4+HiEhYVV+p6wsDCr/gAQFxdXZX8iIiKi6rL5obTp06dj3Lhx6NmzJ3r37o3ly5cjPz8fTzzxBABg7Nix8Pf3R1RUFABg6tSpGDhwIJYuXYoRI0Zg3bp1OHLkCD788ENblkFERER2wObBaNSoUbh8+TLmzp2LzMxMdO3aFdu2bbOcYJ2WlgaF4vqOrX79+iEmJgavvfYaXnnlFQQHByM2NrZa9zACzIfWXn/99UoPr9krR6wZcMy6WbNjYM2OgTXbhs3vY0RERERUX/C5BkREREQyBiMiIiIiGYMRERERkYzBiIiIiEjmcMHovffeQ4sWLeDi4oI+ffrgp59+svWQKrV3716MHDkSfn5+kCSpwrPghBCYO3cufH194erqivDwcJw5c8aqz9WrVzFmzBhotVp4enpiwoQJyMvLs+rz888/4+6774aLiwsCAgLw9ttvVxjL+vXrERISAhcXF3Tu3Blbtmyp8XoB8+NbevXqBXd3d3h7eyMyMhKpqalWfYqKijBp0iR4eXnBzc0N//znPyvc8DMtLQ0jRoyARqOBt7c3ZsyYgdLSUqs+CQkJ6N69O9RqNdq0aYPo6OgK46mL78rq1asRGhpquZlZWFgYtm7darf1VmbRokWQJAnTpk2ztNlb3fPmzYMkSVZTSEiI3dZb5o8//sC//vUveHl5wdXVFZ07d8aRI0csy+3t71iLFi0qfM6SJGHSpEkA7PNzNhqNmDNnDlq2bAlXV1e0bt0aCxcutHqeWYP7nIUDWbdunVCpVOKTTz4RJ0+eFBMnThSenp4iKyvL1kOrYMuWLeLVV18V3333nQAgNm7caLV80aJFwsPDQ8TGxooTJ06I+++/X7Rs2VIUFhZa+tx3332iS5cu4uDBg+LHH38Ubdq0EaNHj7Ysz8nJET4+PmLMmDEiJSVFfPXVV8LV1VV88MEHlj779+8XTk5O4u233xa//PKLeO2114RSqRTJyck1XnNERIRYu3atSElJEUlJSWL48OEiMDBQ5OXlWfo888wzIiAgQMTHx4sjR46Ivn37in79+lmWl5aWik6dOonw8HBx/PhxsWXLFtG0aVMxe/ZsS5/ffvtNaDQaMX36dPHLL7+IlStXCicnJ7Ft2zZLn7r6rmzatEn88MMP4vTp0yI1NVW88sorQqlUipSUFLus90Y//fSTaNGihQgNDRVTp061tNtb3a+//rro2LGjyMjIsEyXL1+223qFEOLq1asiKChIjB8/Xhw6dEj89ttvYvv27eLs2bOWPvb2d+zSpUtWn3FcXJwAIHbv3i2EsM/P+Y033hBeXl5i8+bN4vz582L9+vXCzc1NrFixwtKnoX3ODhWMevfuLSZNmmSZNxqNws/PT0RFRdlwVLd2YzAymUxCp9OJxYsXW9qys7OFWq0WX331lRBCiF9++UUAEIcPH7b02bp1q5AkSfzxxx9CCCHef/990bhxY1FcXGzpM2vWLNGuXTvL/KOPPipGjBhhNZ4+ffqIf//73zVaY2UuXbokAIg9e/YIIcw1KpVKsX79ekufU6dOCQAiMTFRCGEOlAqFQmRmZlr6rF69Wmi1WkudM2fOFB07drTa1qhRo0RERIRl3pbflcaNG4uPPvrI7uvNzc0VwcHBIi4uTgwcONASjOyx7tdff1106dKl0mX2WK8Q5r8ld911V5XLHeHv2NSpU0Xr1q2FyWSy2895xIgR4sknn7Rqe+ihh8SYMWOEEA3zc3aYQ2klJSU4evQowsPDLW0KhQLh4eFITEy04chu3/nz55GZmWlVi4eHB/r06WOpJTExEZ6enujZs6elT3h4OBQKBQ4dOmTpM2DAAKhUKkufiIgIpKam4tq1a5Y+5bdT1qcufmc5OTkAgCZNmgAAjh49CoPBYDWekJAQBAYGWtXduXNnyw1Cy8ar1+tx8uRJS5+b1WSr74rRaMS6deuQn5+PsLAwu6930qRJGDFiRIWx2WvdZ86cgZ+fH1q1aoUxY8YgLS3NruvdtGkTevbsiUceeQTe3t7o1q0b/vvf/1qW2/vfsZKSEnzxxRd48sknIUmS3X7O/fr1Q3x8PE6fPg0AOHHiBPbt24dhw4YBaJifs8MEoytXrsBoNFp94QDAx8cHmZmZNhrVnSkb781qyczMhLe3t9VyZ2dnNGnSxKpPZesov42q+tT278xkMmHatGno37+/5a7mmZmZUKlU8PT0rHI8f6cmvV6PwsLCOv+uJCcnw83NDWq1Gs888ww2btyIDh062G29ALBu3TocO3bM8qif8uyx7j59+iA6Ohrbtm3D6tWrcf78edx9993Izc21y3oB4LfffsPq1asRHByM7du349lnn8WUKVPw6aefWo3bXv+OxcbGIjs7G+PHj7eMwR4/55dffhn/93//h5CQECiVSnTr1g3Tpk3DmDFjrMbdkD5nmz8ShKgykyZNQkpKCvbt22frodS6du3aISkpCTk5OdiwYQPGjRuHPXv22HpYtSY9PR1Tp05FXFwcXFxcbD2cOlH2f88AEBoaij59+iAoKAjffPMNXF1dbTiy2mMymdCzZ0+8+eabAIBu3bohJSUFa9aswbhx42w8utr38ccfY9iwYfDz87P1UGrVN998gy+//BIxMTHo2LEjkpKSMG3aNPj5+TXYz9lh9hg1bdoUTk5OFa4AyMrKgk6ns9Go7kzZeG9Wi06nw6VLl6yWl5aW4urVq1Z9KltH+W1U1ac2f2eTJ0/G5s2bsXv3bjRv3tzSrtPpUFJSguzs7CrH83dq0mq1cHV1rfPvikqlQps2bdCjRw9ERUWhS5cuWLFihd3We/ToUVy6dAndu3eHs7MznJ2dsWfPHrz77rtwdnaGj4+PXdZdnqenJ9q2bYuzZ8/a7efs6+uLDh06WLW1b9/ecgjRnv+OXbx4ETt37sRTTz1labPXz3nGjBmWvUadO3fG448/jhdeeMGyN7ghfs4OE4xUKhV69OiB+Ph4S5vJZEJ8fDzCwsJsOLLb17JlS+h0Oqta9Ho9Dh06ZKklLCwM2dnZOHr0qKXPrl27YDKZ0KdPH0ufvXv3wmAwWPrExcWhXbt2aNy4saVP+e2U9amN35kQApMnT8bGjRuxa9cutGzZ0mp5jx49oFQqrcaTmpqKtLQ0q7qTk5Ot/iOLi4uDVqu1/JG+VU22/q6YTCYUFxfbbb1DhgxBcnIykpKSLFPPnj0xZswYy2t7rLu8vLw8nDt3Dr6+vnb7Offv37/C7TZOnz6NoKAgAPb7dwwA1q5dC29vb4wYMcLSZq+fc0FBgdWD3gHAyckJJpMJQAP9nG/rVO0Gbt26dUKtVovo6Gjxyy+/iKefflp4enpaXQFQX+Tm5orjx4+L48ePCwDinXfeEcePHxcXL14UQpgvf/T09BT/+9//xM8//yweeOCBSi9/7Natmzh06JDYt2+fCA4Otrr8MTs7W/j4+IjHH39cpKSkiHXr1gmNRlPh8kdnZ2exZMkScerUKfH666/X2uX6zz77rPDw8BAJCQlWl7wWFBRY+jzzzDMiMDBQ7Nq1Sxw5ckSEhYWJsLAwy/Kyy13vvfdekZSUJLZt2yaaNWtW6eWuM2bMEKdOnRLvvfdepZe71sV35eWXXxZ79uwR58+fFz///LN4+eWXhSRJYseOHXZZb1XKX5Vmj3W/+OKLIiEhQZw/f17s379fhIeHi6ZNm4pLly7ZZb1CmG/F4OzsLN544w1x5swZ8eWXXwqNRiO++OILSx97/DtmNBpFYGCgmDVrVoVl9vg5jxs3Tvj7+1su1//uu+9E06ZNxcyZMy19Gtrn7FDBSAghVq5cKQIDA4VKpRK9e/cWBw8etPWQKrV7924BoMI0btw4IYT5Esg5c+YIHx8foVarxZAhQ0RqaqrVOv766y8xevRo4ebmJrRarXjiiSdEbm6uVZ8TJ06Iu+66S6jVauHv7y8WLVpUYSzffPONaNu2rVCpVKJjx47ihx9+qJWaK6sXgFi7dq2lT2FhoXjuuedE48aNhUajEQ8++KDIyMiwWs+FCxfEsGHDhKurq2jatKl48cUXhcFgsOqze/du0bVrV6FSqUSrVq2stlGmLr4rTz75pAgKChIqlUo0a9ZMDBkyxBKK7LHeqtwYjOyt7lGjRglfX1+hUqmEv7+/GDVqlNX9fOyt3jLff/+96NSpk1Cr1SIkJER8+OGHVsvt8e/Y9u3bBYAKdQhhn5+zXq8XU6dOFYGBgcLFxUW0atVKvPrqq1aX1Te0z1kSotztKYmIiIgcmMOcY0RERER0KwxGRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKSMRgRUb0xaNAgTJs2zdbDICIHxmBERNVWVXCJjo6Gp6dnnY8nISEBkiRVeDBnTWNgI3IcDEZEREREMgYjIqpx48ePR2RkJObPn49mzZpBq9XimWeeQUlJiaVPfn4+xo4dCzc3N/j6+mLp0qUV1vP555+jZ8+ecHd3h06nw2OPPWZ58viFCxcwePBgAEDjxo0hSRLGjx8PwPw08aioKLRs2RKurq7o0qULNmzYcNMxv//++wgODoaLiwt8fHzw8MMPW2rZs2cPVqxYAUmSIEkSLly4AABISUnBsGHD4ObmBh8fHzz++OO4cuWKZZ2DBg3C5MmTMXnyZHh4eKBp06aYM2cO+CQmovqLwYiIakV8fDxOnTqFhIQEfPXVV/juu+8wf/58y/IZM2Zgz549+N///ocdO3YgISEBx44ds1qHwWDAwoULceLECcTGxuLChQuW8BMQEIBvv/0WAJCamoqMjAysWLECABAVFYXPPvsMa9aswcmTJ/HCCy/gX//6F/bs2VPpWI8cOYIpU6ZgwYIFSE1NxbZt2zBgwAAAwIoVKxAWFoaJEyciIyMDGRkZCAgIQHZ2Nu655x5069YNR44cwbZt25CVlYVHH33Uat2ffvopnJ2d8dNPP2HFihV455138NFHH9XI75iIasFtP3aWiBzWwIEDxdSpUyu0r127Vnh4eFjmx40bJ5o0aSLy8/MtbatXrxZubm7CaDSK3NxcoVKpxDfffGNZ/tdffwlXV9dK11/m8OHDAoDlqdu7d+8WAMS1a9csfYqKioRGoxEHDhyweu+ECRPE6NGjK13vt99+K7RardDr9dWue+HCheLee++1aktPT7d6svrAgQNF+/bthclksvSZNWuWaN++fZU1EpFtcY8REdWKLl26QKPRWObDwsKQl5eH9PR0nDt3DiUlJejTp49leZMmTdCuXTurdRw9ehQjR45EYGAg3N3dMXDgQABAWlpalds9e/YsCgoKMHToULi5uVmmzz77DOfOnav0PUOHDkVQUBBatWqFxx9/HF9++SUKCgpuWt+JEyewe/duq22EhIQAgNV2+vbtC0mSrH4PZ86cgdFovOn6icg2nG09ACJqOLRaLXJyciq0Z2dnw8PDo0a3lZ+fj4iICERERODLL79Es2bNkJaWhoiICKtzlW6Ul5cHAPjhhx/g7+9vtUytVlf6Hnd3dxw7dgwJCQnYsWMH5s6di3nz5uHw4cNVXm2Xl5eHkSNH4q233qqwzNfXt5pVElF9w2BERNXWrl077Nixo0L7sWPH0LZtW6u2EydOoLCwEK6urgCAgwcPws3NDQEBAfDy8oJSqcShQ4cQGBgIALh27RpOnz5t2Sv066+/4q+//sKiRYsQEBAAwHwuUHkqlQoArPa+dOjQAWq1GmlpaZZ1VYezszPCw8MRHh6O119/HZ6enti1axceeughqFSqCnt4unfvjm+//RYtWrSAs3PVf0oPHTpkNX/w4EEEBwfDycmp2mMjorrDQ2lEVG3PPvssTp8+jSlTpuDnn39Gamoq3nnnHXz11Vd48cUXrfqWlJRgwoQJ+OWXX7Blyxa8/vrrmDx5MhQKBdzc3DBhwgTMmDEDu3btQkpKCsaPHw+F4vqfpMDAQKhUKqxcuRK//fYbNm3ahIULF1ptIygoCJIkYfPmzbh8+TLy8vLg7u6Ol156CS+88AI+/fRTnDt3DseOHcPKlSvx6aefVlrX5s2b8e677yIpKQkXL17EZ599BpPJZDm016JFCxw6dAgXLlzAlStXYDKZMGnSJFy9ehWjR4/G4cOHce7cOWzfvh1PPPGEVYhKS0vD9OnTkZqaiq+++gorV67E1KlTa+ojIaKaZuuTnIioYfnpp5/E0KFDRbNmzYSHh4fo06eP2Lhxo1WfcePGiQceeEDMnTtXeHl5CTc3NzFx4kRRVFRk6ZObmyv+9a9/CY1GI3x8fMTbb79d4STnmJgY0aJFC6FWq0VYWJjYtGmTACCOHz9u6bNgwQKh0+mEJEli3LhxQgghTCaTWL58uWjXrp1QKpWiWbNmIiIiQuzZs6fSmn788UcxcOBA0bhxY+Hq6ipCQ0PF119/bVmempoq+vbtK1xdXQUAcf78eSGEEKdPnxYPPvig8PT0FK6uriIkJERMmzbNcrL1wIEDxXPPPSeeeeYZodVqRePGjcUrr7xidTI2EdUvkhC8oQYR1azx48cjOzsbsbGxth6KTQ0aNAhdu3bF8uXLbT0UIqomHkojIiIikjEYEREREcl4KI2IiIhIxj1GRERERDIGIyIiIiIZgxERERGRjMGIiIiISMZgRERERCRjMCIiIiKSMRgRERERyRiMiIiIiGQMRkRERESy/wcfe1SYwAdKVgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(history)), history, label='Training loss')\n",
    "plt.plot(range(len(data_loader['train']) - 1, len(history), len(data_loader['train'])), validation_history, label='Validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim([0.0, len(history)])\n",
    "plt.ylim([0.0, 4.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set model in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "split = 'validation'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, weights, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        weights = weights.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds, weights)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "split = 'test'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, weights, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        weights = weights.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds, weights)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WELFake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "corpus = 'WELFake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "welfake['train']._data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# embeddings_model.fit_sif_embedding([sample['sequence'] for sample in welfake['train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Set\n",
    "\n",
    "class Conv1D(nn.Module):\n",
    "    \"\"\"\n",
    "    1D-convolutional layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2).\n",
    "    Basically works like a linear layer but the weights are transposed.\n",
    "    Args:\n",
    "        nf (:obj:`int`): The number of output features.\n",
    "        nx (:obj:`int`): The number of input features.\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nf, nx):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        w = torch.empty(nx, nf)\n",
    "        nn.init.normal_(w, std=0.02)\n",
    "        self.weight = nn.Parameter(w)\n",
    "        self.bias = nn.Parameter(torch.zeros(nf))\n",
    "\n",
    "    def forward(self, x):\n",
    "        size_out = x.size()[:-1] + (self.nf,)\n",
    "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
    "        x = x.view(*size_out)\n",
    "        return x\n",
    "\n",
    "\n",
    "def find_pruneable_heads_and_indices(heads: List[int],\n",
    "                                     n_heads: int,\n",
    "                                     head_size: int,\n",
    "                                     already_pruned_heads: Set[int]) -> Tuple[Set[int], torch.LongTensor]:\n",
    "    \"\"\"\n",
    "    Finds the heads and their indices taking :obj:`already_pruned_heads` into account.\n",
    "    Args:\n",
    "        heads (:obj:`List[int]`): List of the indices of heads to prune.\n",
    "        n_heads (:obj:`int`): The number of heads in the model.\n",
    "        head_size (:obj:`int`): The size of each head.\n",
    "        already_pruned_heads (:obj:`Set[int]`): A set of already pruned heads.\n",
    "    Returns:\n",
    "        :obj:`Tuple[Set[int], torch.LongTensor]`: A tuple with the remaining heads and their corresponding indices.\n",
    "\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "    mask = torch.ones(n_heads, head_size)\n",
    "    heads = set(heads) - already_pruned_heads  # Convert to set and remove already pruned heads\n",
    "    for head in heads:\n",
    "        # Compute how many pruned heads are before the head and move the index accordingly\n",
    "        head = head - sum(1 if h < head else 0 for h in already_pruned_heads)\n",
    "        mask[head] = 0\n",
    "    mask = mask.view(-1).contiguous().eq(1)\n",
    "    index: torch.LongTensor = torch.arange(len(mask))[mask].long()\n",
    "    return heads, index\n",
    "\n",
    "\n",
    "def prune_conv1d_layer(layer: Conv1D, index: torch.LongTensor, dim: int = 1) -> Conv1D:\n",
    "    \"\"\"\n",
    "    Prune a Conv1D layer to keep only entries in index. A Conv1D work as a Linear layer (see e.g. BERT) but the weights\n",
    "    are transposed.\n",
    "    Used to remove heads.\n",
    "    Args:\n",
    "        layer (:class:`~transformers.modeling_utils.Conv1D`): The layer to prune.\n",
    "        index (:obj:`torch.LongTensor`): The indices to keep in the layer.\n",
    "        dim (:obj:`int`, `optional`, defaults to 1): The dimension on which to keep the indices.\n",
    "    Returns:\n",
    "        :class:`~transformers.modeling_utils.Conv1D`: The pruned layer as a new layer with :obj:`requires_grad=True`.\n",
    "\n",
    "    Thanks to Hugging Face for the implementation\n",
    "    \"\"\"\n",
    "    index = index.to(layer.weight.device)\n",
    "    W = layer.weight.index_select(dim, index).clone().detach()\n",
    "    if dim == 0:\n",
    "        b = layer.bias.clone().detach()\n",
    "    else:\n",
    "        b = layer.bias[index].clone().detach()\n",
    "    new_size = list(layer.weight.size())\n",
    "    new_size[dim] = len(index)\n",
    "    new_layer = Conv1D(new_size[1], new_size[0]).to(layer.weight.device)\n",
    "    new_layer.weight.requires_grad = False\n",
    "    new_layer.weight.copy_(W.contiguous())\n",
    "    new_layer.weight.requires_grad = True\n",
    "    new_layer.bias.requires_grad = False\n",
    "    new_layer.bias.copy_(b.contiguous())\n",
    "    new_layer.bias.requires_grad = True\n",
    "    return new_layer\n",
    "\n",
    "\n",
    "class AttentionAvgPooling(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_hidden: int = 512,\n",
    "                 n_heads: int = 8,\n",
    "                 max_positions: int = 1024,\n",
    "                 p_dropout: float = 0.1,\n",
    "                 scale_attn_weights: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = n_hidden\n",
    "        self.num_heads = n_heads\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "        self.split_size = self.embed_dim\n",
    "        assert self.head_dim * self.num_heads == self.embed_dim, f\"`embed_dim` must be divisible by num_heads \" \\\n",
    "                                                                 f\"(got `embed_dim`: {self.embed_dim} and \" \\\n",
    "                                                                 f\"`num_heads`: {self.num_heads}).\"\n",
    "\n",
    "        self.scale_attn_weights = scale_attn_weights\n",
    "\n",
    "        self.qkv_attn = Conv1D(3 * self.embed_dim, self.embed_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        heads, index = find_pruneable_heads_and_indices(heads, self.num_heads, self.head_dim, self.pruned_heads)\n",
    "        index_attn = torch.cat([index, index + self.split_size, index + (2 * self.split_size)])\n",
    "\n",
    "        # Prune conv1d layers\n",
    "        self.qkv_attn = prune_conv1d_layer(self.qkv_attn, index_attn, dim=1)\n",
    "\n",
    "        # Update hyper params\n",
    "        self.split_size = (self.split_size // self.num_heads) * (self.num_heads - len(heads))\n",
    "        self.num_heads = self.num_heads - len(heads)\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    def _attn(self, query, key, value, attention_mask=None):\n",
    "        attn_weights = torch.matmul(query, key.transpose(-1, -2))\n",
    "        attn_weights = attn_weights / (float(value.size(-1)) ** 0.5)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask\n",
    "            attn_weights = attn_weights + attention_mask\n",
    "\n",
    "        attn_weights = nn.Softmax(dim=-1)(attn_weights)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        attn_output = torch.matmul(attn_weights, value)\n",
    "\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "    @staticmethod\n",
    "    def _split_heads(tensor, num_heads, attn_head_size):\n",
    "        new_shape = tensor.size()[:-1] + (num_heads, attn_head_size)\n",
    "        tensor = tensor.view(*new_shape)\n",
    "        return tensor.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
    "\n",
    "    @staticmethod\n",
    "    def _merge_heads(tensor, num_heads, attn_head_size):\n",
    "        tensor = tensor.permute(0, 2, 1, 3).contiguous()\n",
    "        new_shape = tensor.size()[:-2] + (num_heads * attn_head_size,)\n",
    "        return tensor.view(new_shape)\n",
    "\n",
    "    def forward(self,\n",
    "                hidden_states,\n",
    "                attention_mask=None,\n",
    "                return_attention_weights=False):\n",
    "\n",
    "        query, key, value = self.qkv_attn(hidden_states).split(self.split_size, dim=2)\n",
    "\n",
    "        # Query is averaged to obtain pooling\n",
    "        query = self._split_heads(query, self.num_heads, self.head_dim).mean(-2, keepdims=True)\n",
    "        key = self._split_heads(key, self.num_heads, self.head_dim)\n",
    "        value = self._split_heads(value, self.num_heads, self.head_dim)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = (1.0 - attention_mask) * -1e+6\n",
    "            attention_mask = attention_mask[:, None, None, :]\n",
    "\n",
    "        attn_output, attn_weights = self._attn(query, key, value, attention_mask)\n",
    "\n",
    "        attn_output = self._merge_heads(attn_output, self.num_heads, self.head_dim)\n",
    "\n",
    "        if not return_attention_weights:\n",
    "            return attn_output  # attention\n",
    "        else:\n",
    "            attn_weights = self._merge_heads(attn_weights, self.num_heads, self.head_dim)\n",
    "            return attn_output, attn_weights\n",
    "\n",
    "\n",
    "# class GPT2Attention(nn.Module):\n",
    "# https://github.com/huggingface/transformers/blob/master/src/transformers/models/gpt2/modeling_gpt2.py\n",
    "\n",
    "\n",
    "class SequenceClassification(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size: int = 512, kernel_size: int = 5):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_size)\n",
    "        self.conv1d = nn.Conv1d(input_size, hidden_size, kernel_size, padding='same')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_head = nn.Linear(hidden_size, output_size)\n",
    "        ##\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.out_norm = nn.LayerNorm(hidden_size)\n",
    "        self.pool = AttentionAvgPooling()\n",
    "        \n",
    "    def forward(self, x, w):\n",
    "        # \n",
    "        x = self.dropout(x)\n",
    "        #\n",
    "        h = self.conv1d(x.transpose(-1, -2)).transpose(-1, -2)  # self.norm(x).transpose(-1, -2)\n",
    "        ##\n",
    "        h = self.norm(h)\n",
    "        # Non-linear activation\n",
    "        h = F.gelu(h)\n",
    "        \n",
    "        # Dropout\n",
    "        h = self.dropout(h)\n",
    "        # Weighted sum\n",
    "        # h = torch.einsum('btd,bt->bd', h, w)\n",
    "        # Apply last linear projection\n",
    "        # h = self.out_head(h)\n",
    "        ##\n",
    "        h = self.pool(h, w)\n",
    "        h = self.out_norm(h)\n",
    "        y = self.out_head(h)\n",
    "\n",
    "        return y\n",
    "\n",
    "'''\n",
    "class SequenceClassification(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size: int = 512, kernel_size: int = 5):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_size)\n",
    "        self.conv1d = nn.Conv1d(input_size, hidden_size, kernel_size, padding='same')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.cls_head = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, w):\n",
    "        # \n",
    "        x = self.dropout(x)\n",
    "        #\n",
    "        h = self.conv1d(self.norm(x).transpose(-1, -2))\n",
    "        # Non-linear activation\n",
    "        h = F.gelu(h)\n",
    "        # Dropout\n",
    "        h = self.dropout(h)\n",
    "        # Weighted sum\n",
    "        h = torch.einsum('btd,bt->bd', h.transpose(-1, -2), w)\n",
    "        # Apply last linear projection\n",
    "        y = self.cls_head(h)\n",
    "\n",
    "        return y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "le = welfake['train'].get_label_transformer()\n",
    "for label, le_ in le.items():\n",
    "    print(label, le_.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = {label: lw_.to(device) for label, lw_ in welfake['train'].get_label_weights().items()}\n",
    "for label, lw_ in lw.items():\n",
    "    print(label, lw_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task = 'fakenews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = SequenceClassification(300, len(le[task].classes_))    \n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "batch_size = 8\n",
    "n_epochs = 16\n",
    "accumulation_steps = 64\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr, weight_decay=0.2)\n",
    "# optimizer = torch.optim.RMSprop(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def collate(mini_batch):\n",
    "    # Tokenise sequences \n",
    "    sequences = embeddings_model.tokenise([sample['sequence'] for sample in mini_batch])\n",
    "    # Get the length of the longest sentence\n",
    "    max_sequence_len = max(len(sample) for sample in sequences)\n",
    "    # Create an input tensor with all zero values\n",
    "    input_embeds = np.zeros((len(mini_batch), max_sequence_len, 300))\n",
    "    # Create weights tensor with all zero values\n",
    "    token_weights = np.zeros((len(mini_batch), max_sequence_len))\n",
    "    valid_mask = np.zeros((len(mini_batch), max_sequence_len))\n",
    "    # Create a target output matrix with all -100 (PyTorch ignores this value by default)\n",
    "    output_lbl = np.full((len(mini_batch), 1), -100)\n",
    "    # Fill the tensor and the matrix\n",
    "    for i, sample in enumerate(sequences):\n",
    "        for j, token in enumerate(sample):\n",
    "            # Manage missing tokens in vocabulary\n",
    "            input_embeds[i, j] = embeddings_model[token.lower()]\n",
    "        token_weights[i, :len(sample)] = embeddings_model.sif_embedding_model.word_weights[embeddings_model.encode(sample, backend='numpy')]\n",
    "        valid_mask[i, :len(sample)] = 1.0\n",
    "        output_lbl[i] = le[task].transform([mini_batch[i][task]])[0]\n",
    "    # Convert to PyTorch tensor\n",
    "    input_embeds = torch.tensor(input_embeds, dtype=torch.float, device=device)\n",
    "    token_weights = torch.tensor(token_weights, dtype=torch.float, device=device)\n",
    "    valid_mask = torch.tensor(valid_mask, dtype=torch.float, device=device)\n",
    "    output_lbl = torch.tensor(output_lbl, device=device)\n",
    "\n",
    "    # return input_embeds, token_weights, output_lbl\n",
    "    return input_embeds, valid_mask, output_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_loader = {\n",
    "    split: torch.utils.data.DataLoader(\n",
    "        data, batch_size=batch_size, collate_fn=collate, shuffle=split == 'train'\n",
    "    )\n",
    "    for split, data in welfake.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join('../experiments/contextual/', f'{model_id}_{corpus}_{task}_{datetime.now()}.ckpt')\n",
    "\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Accumulator of loss\n",
    "history = []\n",
    "validation_history = []\n",
    "best_validation_loss = torch.tensor(float('inf'), device=device)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, steps_per_epoch=len(data_loader['train']), epochs=n_epochs, anneal_strategy='linear', pct_start=0.05)\n",
    "\n",
    "estop_counter = 0\n",
    "\n",
    "# Iterate over epochs\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Starting epoch {i + 1}/{n_epochs}\")\n",
    "    # Iterate over training batches\n",
    "    for j, (embeds, weights, lbl) in tqdm(enumerate(data_loader['train'])):\n",
    "        # Zero your gradients for every batch!\n",
    "        if j % accumulation_steps == 0:\n",
    "            optimizer.zero_grad()\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        weights = weights.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds, weights)\n",
    "        # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "        logits = logits.reshape(-1, len(le[task].classes_))\n",
    "        # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "        lbl = lbl.reshape(-1)\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(logits, lbl) / accumulation_steps\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        if j + 1 % accumulation_steps == 0 or j + 1 == len(data_loader['train']):\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # Save loss\n",
    "        history.append(loss)\n",
    "    # Disable gradients\n",
    "    with torch.no_grad():\n",
    "        print(f\"Starting validation epoch {i + 1}/{n_epochs}\")\n",
    "        # Set in evaluation mode\n",
    "        model.eval()\n",
    "        # Init validation loss accumulator\n",
    "        loss = []\n",
    "        # Iterate over validation batches\n",
    "        for embeds, weights, lbl in tqdm(data_loader['validation']):\n",
    "            # Move input and output to target device\n",
    "            embeds = embeds.to(device)\n",
    "            weights = weights.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "            # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "            logits = model(embeds, weights)\n",
    "            # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "            logits = logits.reshape(-1, len(le[task].classes_))\n",
    "            # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "            lbl = lbl.reshape(-1)\n",
    "            # Compute loss\n",
    "            loss.append(F.cross_entropy(logits, lbl))\n",
    "        # Aggregate validation loss\n",
    "        validation_history.append(torch.tensor(loss, device=device).mean())\n",
    "        # Check if validation loss has improved\n",
    "        if validation_history[-1] <= best_validation_loss:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_validation_loss = validation_history[-1]\n",
    "            estop_counter = 0\n",
    "        else:\n",
    "            estop_counter += 1\n",
    "        # Restore training mode\n",
    "        model.train()\n",
    "    if estop_counter >= 5:\n",
    "        break\n",
    "        \n",
    "# Restore best weights\n",
    "if os.path.exists(path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "history = [loss.cpu().item() for loss in history]\n",
    "validation_history = [loss.cpu().item() for loss in validation_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(history)), history, label='Training loss')\n",
    "plt.plot(range(len(data_loader['train']) - 1, len(history), len(data_loader['train'])), validation_history, label='Validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim([0.0, len(history)])\n",
    "plt.ylim([0.0, 4.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set model in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "split = 'validation'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, weights, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        weights = weights.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds, weights)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)[:, 1]\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "split = 'test'\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, weights, lbl in tqdm(data_loader[split]):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        weights = weights.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = model(embeds, weights)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted proba\n",
    "        y_proba.append(logits.view(-1, len(le[task].classes_)).cpu().numpy())\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.view(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.view(-1).cpu().numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_proba = np.concatenate(y_proba, axis=0)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "y_proba = y_proba[~mask]\n",
    "\n",
    "labels = np.unique(y_true)\n",
    "mapping = np.zeros(len(le[task].classes_), dtype=int)\n",
    "mapping[labels] = np.arange(len(labels))\n",
    "\n",
    "y_true = mapping[y_true]\n",
    "y_pred = mapping[y_pred]\n",
    "y_proba = softmax(y_proba[:, labels], axis=1)[:, 1]\n",
    "\n",
    "ids, counts = np.unique(y_true, return_counts=True)\n",
    "weights = counts / np.sum(counts)\n",
    "\n",
    "# \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_m, recall_m, fscore_m, support_m = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "auc_m = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "precision_w, recall_w, fscore_w, support_w = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "auc_w = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "accuracy_sw = accuracy_score(y_true, y_pred, sample_weight=weights[y_true])\n",
    "precision_sw, recall_sw, fscore_sw, support_sw = precision_recall_fscore_support(y_true, y_pred, average='weighted', sample_weight=weights[y_true])\n",
    "auc_sw = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted', sample_weight=weights[y_true])\n",
    "results.extend([\n",
    "    {\n",
    "        'corpus': corpus,\n",
    "        'task': task,\n",
    "        'embeddings': model_id,\n",
    "        'split': split,\n",
    "        'timestamp': timestamp,\n",
    "        'metric': metric,\n",
    "        'value': value\n",
    "    }\n",
    "    for metric, value in zip(\n",
    "        CLS_METRICS, [\n",
    "            accuracy, precision_m, recall_m, fscore_m, auc_m, \n",
    "            precision_w, recall_w, fscore_w, auc_w,\n",
    "            accuracy_sw, precision_sw, recall_sw, fscore_sw, auc_sw\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=le[task].classes_[labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(RESULTS_FILE_PATH):\n",
    "    results_df.to_csv(RESULTS_FILE_PATH, mode='a', index=False, header=False)\n",
    "else:\n",
    "    results_df.to_csv(RESULTS_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results_df[results_df['metric'].apply(lambda x: '(sample weight)' in x or 'corr.' in x)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['task', 'metric', 'split']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
