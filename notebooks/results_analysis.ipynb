{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03724928-317b-406a-ad62-1b3647b25513",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cbe829-3ab5-4154-a1ba-893df281ec88",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Environment preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ea481-4edf-44d3-8e19-47aa45d97742",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3774e0-19b4-4805-8880-5787038176db",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450aef53-d9a7-4d10-8d1a-2cd361096505",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa8fda0-9fc6-4879-ba70-1135eb343144",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7754e639-ea00-48b9-a634-92f8df76ac75",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd4d5ff-1faa-400c-b0ad-279edf869e47",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "RESULTS_FILE_PATH = f'../experiments/contextual/results.csv'  # 'results_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39524c37-21cc-4ab7-a009-53c9c5d2bf92",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9077e0-af3b-4e16-9db3-7c80894934e7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>task</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>split</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.819458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>precision (macro)</td>\n",
       "      <td>0.740064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>recall (macro)</td>\n",
       "      <td>0.688794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>fscore (macro)</td>\n",
       "      <td>0.708233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>auc (macro)</td>\n",
       "      <td>0.980106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>accuracy (sample weight)</td>\n",
       "      <td>0.799859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>precision (sample weight)</td>\n",
       "      <td>0.801995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>recall (sample weight)</td>\n",
       "      <td>0.799859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>fscore (sample weight)</td>\n",
       "      <td>0.798575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>auc (sample weight)</td>\n",
       "      <td>0.880254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus      task  embeddings       split            timestamp  \\\n",
       "0    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "1    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "2    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "3    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "4    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "..          ...       ...         ...         ...                  ...   \n",
       "423     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "424     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "425     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "426     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "427     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "\n",
       "                        metric     value  \n",
       "0                     accuracy  0.819458  \n",
       "1            precision (macro)  0.740064  \n",
       "2               recall (macro)  0.688794  \n",
       "3               fscore (macro)  0.708233  \n",
       "4                  auc (macro)  0.980106  \n",
       "..                         ...       ...  \n",
       "423   accuracy (sample weight)  0.799859  \n",
       "424  precision (sample weight)  0.801995  \n",
       "425     recall (sample weight)  0.799859  \n",
       "426     fscore (sample weight)  0.798575  \n",
       "427        auc (sample weight)  0.880254  \n",
       "\n",
       "[428 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv(RESULTS_FILE_PATH)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1221b5-3314-4ea7-9c30-5bc1db9b61aa",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fcdaa7f-95d8-447b-8953-471aac260b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines_df = results_df[results_df['embeddings'].isin(['word_2_vec', 'glove', 'fast_text', 'def_2_vec_legacy'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe2f0d3-65dc-4cc5-b46f-e9bb6db5eac9",
   "metadata": {},
   "source": [
    "### Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43476faa-1258-473e-b910-cbd12d7ddc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>task</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>split</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.819458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>precision (macro)</td>\n",
       "      <td>0.740064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>recall (macro)</td>\n",
       "      <td>0.688794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>fscore (macro)</td>\n",
       "      <td>0.708233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>auc (macro)</td>\n",
       "      <td>0.980106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.797715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>precision (macro)</td>\n",
       "      <td>0.802301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>recall (macro)</td>\n",
       "      <td>0.795567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>fscore (macro)</td>\n",
       "      <td>0.795974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>auc (macro)</td>\n",
       "      <td>0.880254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus      task  embeddings       split            timestamp  \\\n",
       "0    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "1    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "2    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "3    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "4    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "..          ...       ...         ...         ...                  ...   \n",
       "414     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "415     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "416     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "417     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "418     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "\n",
       "                metric     value  \n",
       "0             accuracy  0.819458  \n",
       "1    precision (macro)  0.740064  \n",
       "2       recall (macro)  0.688794  \n",
       "3       fscore (macro)  0.708233  \n",
       "4          auc (macro)  0.980106  \n",
       "..                 ...       ...  \n",
       "414           accuracy  0.797715  \n",
       "415  precision (macro)  0.802301  \n",
       "416     recall (macro)  0.795567  \n",
       "417     fscore (macro)  0.795974  \n",
       "418        auc (macro)  0.880254  \n",
       "\n",
       "[158 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = baselines_df[baselines_df['metric'].apply(lambda x: x == 'accuracy' or '(macro)' in x or 'corr.' in x) ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af671b53-ce61-4f47-94a4-db82c3b10d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('chunk',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 83.19 & 62.93 & 49.56 & 53.70 & 95.91 \\\\\n",
      "('validation',) -- 85.18 & 67.08 & 52.10 & 56.11 & 95.91 \\\\\n",
      "\n",
      "('fakenews',)\n",
      "\n",
      "\n",
      "('def_2_vec_legacy',)\n",
      "\n",
      "('test',) -- 77.90 & 80.87 & 77.39 & 77.12 & 90.53 \\\\\n",
      "('validation',) -- 77.72 & 80.97 & 77.24 & 76.90 & 90.63 \\\\\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 79.77 & 80.23 & 79.56 & 79.60 & 88.03 \\\\\n",
      "('validation',) -- 79.77 & 80.27 & 79.58 & 79.60 & 87.84 \\\\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 77.17 & 78.59 & 77.51 & 77.01 & 87.78 \\\\\n",
      "('validation',) -- 77.15 & 78.64 & 77.47 & 76.98 & 87.68 \\\\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 78.34 & 78.36 & 78.26 & 78.28 & 86.11 \\\\\n",
      "('validation',) -- 78.40 & 78.41 & 78.35 & 78.37 & 86.08 \\\\\n",
      "\n",
      "('ner',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 92.03 & 76.39 & 65.55 & 70.36 & 96.51 \\\\\n",
      "('validation',) -- 93.58 & 84.01 & 69.36 & 75.73 & 97.30 \\\\\n",
      "\n",
      "('newsgroup',)\n",
      "\n",
      "\n",
      "('def_2_vec_legacy',)\n",
      "\n",
      "('test',) -- 56.20 & 59.58 & 55.97 & 55.59 & 94.33 \\\\\n",
      "('validation',) -- 64.97 & 67.47 & 65.11 & 64.61 & 96.20 \\\\\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 66.37 & 66.53 & 65.03 & 64.39 & 96.53 \\\\\n",
      "('validation',) -- 71.76 & 71.96 & 70.33 & 69.77 & 97.27 \\\\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 75.52 & 75.84 & 74.16 & 73.86 & 97.89 \\\\\n",
      "('validation',) -- 81.55 & 81.40 & 80.39 & 80.25 & 98.67 \\\\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 72.58 & 72.28 & 71.24 & 71.16 & 97.47 \\\\\n",
      "('validation',) -- 80.06 & 80.29 & 79.06 & 79.16 & 98.42 \\\\\n",
      "\n",
      "('pos',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 80.45 & 77.93 & 69.37 & 71.74 & 97.82 \\\\\n",
      "('validation',) -- 81.95 & 74.01 & 68.88 & 70.82 & 98.01 \\\\\n",
      "\n",
      "('sentiment',)\n",
      "\n",
      "\n",
      "('def_2_vec_legacy',)\n",
      "\n",
      "('test',) -- 59.87 & 59.92 & 59.91 & 59.86 & 62.77 \\\\\n",
      "('validation',) -- 58.64 & 58.63 & 58.63 & 58.63 & 61.21 \\\\\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 66.38 & 66.42 & 66.30 & 66.29 & 71.15 \\\\\n",
      "('validation',) -- 63.72 & 63.73 & 63.68 & 63.67 & 69.46 \\\\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 64.56 & 66.43 & 64.21 & 63.18 & 73.85 \\\\\n",
      "('validation',) -- 65.18 & 67.65 & 64.93 & 63.68 & 73.40 \\\\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 69.25 & 69.27 & 69.20 & 69.20 & 74.62 \\\\\n",
      "('validation',) -- 69.93 & 69.94 & 69.90 & 69.91 & 74.31 \\\\\n",
      "\n",
      "('similarity_score',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 70.95 & 0.00 & 69.52 & 0.00 \\\\\n",
      "('validation',) -- 75.95 & 0.00 & 76.79 & 0.00 \\\\\n"
     ]
    }
   ],
   "source": [
    "for task, task_groups in df.groupby(['task']):\n",
    "    print()\n",
    "    print(task)\n",
    "    print()\n",
    "    for embedding, embeddings_groups in task_groups.groupby(['embeddings']):\n",
    "        print()\n",
    "        print(embedding)\n",
    "        print()\n",
    "        for split, split_groups in embeddings_groups.groupby(['split']):\n",
    "            # print(split, ' '.join(f'{row['metric']}: {row['value'] * 100:.2f}' for _, row in split_groups.iterrows()))\n",
    "            print(split, '--', ' & '.join(f'{row['value'] * 100:.2f}' for _, row in split_groups.iterrows()), '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf889bc6-7349-48d4-87ff-20e956d95840",
   "metadata": {},
   "source": [
    "### Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73827ddc-852f-426b-8f72-5472f3304dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>task</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>split</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.819458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>precision (weighted)</td>\n",
       "      <td>0.821385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>recall (weighted)</td>\n",
       "      <td>0.819458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>fscore (weighted)</td>\n",
       "      <td>0.817505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>auc (weighted)</td>\n",
       "      <td>0.982731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.797715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>precision (weighted)</td>\n",
       "      <td>0.801335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>recall (weighted)</td>\n",
       "      <td>0.797715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>fscore (weighted)</td>\n",
       "      <td>0.796580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>auc (weighted)</td>\n",
       "      <td>0.880254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus      task  embeddings       split            timestamp  \\\n",
       "0    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "5    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "6    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "7    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "8    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "..          ...       ...         ...         ...                  ...   \n",
       "414     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "419     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "420     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "421     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "422     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "\n",
       "                   metric     value  \n",
       "0                accuracy  0.819458  \n",
       "5    precision (weighted)  0.821385  \n",
       "6       recall (weighted)  0.819458  \n",
       "7       fscore (weighted)  0.817505  \n",
       "8          auc (weighted)  0.982731  \n",
       "..                    ...       ...  \n",
       "414              accuracy  0.797715  \n",
       "419  precision (weighted)  0.801335  \n",
       "420     recall (weighted)  0.797715  \n",
       "421     fscore (weighted)  0.796580  \n",
       "422        auc (weighted)  0.880254  \n",
       "\n",
       "[158 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = baselines_df[baselines_df['metric'].apply(lambda x: x == 'accuracy' or '(weighted)' in x or 'corr.' in x)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d13d484-d95b-49b9-ac48-28e6c8a4fdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('chunk',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 83.19 & 83.08 & 83.19 & 83.07 & 96.49 \\\\\n",
      "('validation',) -- 85.18 & 85.10 & 85.18 & 85.07 & 97.59 \\\\\n",
      "\n",
      "('fakenews',)\n",
      "\n",
      "\n",
      "('def_2_vec_legacy',)\n",
      "\n",
      "('test',) -- 77.90 & 80.58 & 77.90 & 77.26 & 90.53 \\\\\n",
      "('validation',) -- 77.72 & 80.70 & 77.72 & 77.02 & 90.63 \\\\\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 79.77 & 80.13 & 79.77 & 79.66 & 88.03 \\\\\n",
      "('validation',) -- 79.77 & 80.17 & 79.77 & 79.65 & 87.84 \\\\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 77.17 & 78.82 & 77.17 & 76.95 & 87.78 \\\\\n",
      "('validation',) -- 77.15 & 78.85 & 77.15 & 76.92 & 87.68 \\\\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 78.34 & 78.35 & 78.34 & 78.32 & 86.11 \\\\\n",
      "('validation',) -- 78.40 & 78.41 & 78.40 & 78.39 & 86.08 \\\\\n",
      "\n",
      "('ner',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 92.03 & 91.42 & 92.03 & 91.57 & 96.55 \\\\\n",
      "('validation',) -- 93.58 & 93.18 & 93.58 & 93.22 & 97.44 \\\\\n",
      "\n",
      "('newsgroup',)\n",
      "\n",
      "\n",
      "('def_2_vec_legacy',)\n",
      "\n",
      "('test',) -- 56.20 & 60.60 & 56.20 & 56.24 & 94.44 \\\\\n",
      "('validation',) -- 64.97 & 68.56 & 64.97 & 65.11 & 96.20 \\\\\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 66.37 & 67.45 & 66.37 & 65.77 & 96.69 \\\\\n",
      "('validation',) -- 71.76 & 72.81 & 71.76 & 71.19 & 97.39 \\\\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 75.52 & 76.55 & 75.52 & 75.06 & 98.04 \\\\\n",
      "('validation',) -- 81.55 & 82.06 & 81.55 & 81.27 & 98.75 \\\\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 72.58 & 72.99 & 72.58 & 72.25 & 97.57 \\\\\n",
      "('validation',) -- 80.06 & 80.55 & 80.06 & 79.88 & 98.44 \\\\\n",
      "\n",
      "('pos',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 80.45 & 80.34 & 80.45 & 80.18 & 97.66 \\\\\n",
      "('validation',) -- 81.95 & 82.14 & 81.95 & 81.75 & 98.27 \\\\\n",
      "\n",
      "('sentiment',)\n",
      "\n",
      "\n",
      "('def_2_vec_legacy',)\n",
      "\n",
      "('test',) -- 59.87 & 59.95 & 59.87 & 59.85 & 62.77 \\\\\n",
      "('validation',) -- 58.64 & 58.64 & 58.64 & 58.64 & 61.21 \\\\\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 66.38 & 66.41 & 66.38 & 66.32 & 71.15 \\\\\n",
      "('validation',) -- 63.72 & 63.72 & 63.72 & 63.69 & 69.46 \\\\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 64.56 & 66.33 & 64.56 & 63.32 & 73.85 \\\\\n",
      "('validation',) -- 65.18 & 67.57 & 65.18 & 63.78 & 73.40 \\\\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 69.25 & 69.26 & 69.25 & 69.22 & 74.62 \\\\\n",
      "('validation',) -- 69.93 & 69.94 & 69.93 & 69.92 & 74.31 \\\\\n",
      "\n",
      "('similarity_score',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 70.95 & 0.00 & 69.52 & 0.00 \\\\\n",
      "('validation',) -- 75.95 & 0.00 & 76.79 & 0.00 \\\\\n"
     ]
    }
   ],
   "source": [
    "for task, task_groups in df.groupby(['task']):\n",
    "    print()\n",
    "    print(task)\n",
    "    print()\n",
    "    for embedding, embeddings_groups in task_groups.groupby(['embeddings']):\n",
    "        print()\n",
    "        print(embedding)\n",
    "        print()\n",
    "        for split, split_groups in embeddings_groups.groupby(['split']):\n",
    "            # print(split, ' '.join(f'{row['metric']}: {row['value'] * 100:.2f}' for _, row in split_groups.iterrows()))\n",
    "            print(split, '--', ' & '.join(f'{row['value'] * 100:.2f}' for _, row in split_groups.iterrows()), '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865bc74a-f83f-4c83-9bf4-284ee1510fb0",
   "metadata": {},
   "source": [
    "### Sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0db1017-cd12-4ed2-aea1-4077399da00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>task</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>split</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>accuracy (sample weight)</td>\n",
       "      <td>0.837892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>precision (sample weight)</td>\n",
       "      <td>0.858589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>recall (sample weight)</td>\n",
       "      <td>0.837892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>fscore (sample weight)</td>\n",
       "      <td>0.844059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_19_13_32_45</td>\n",
       "      <td>auc (sample weight)</td>\n",
       "      <td>0.977138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>accuracy (sample weight)</td>\n",
       "      <td>0.799859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>precision (sample weight)</td>\n",
       "      <td>0.801995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>recall (sample weight)</td>\n",
       "      <td>0.799859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>fscore (sample weight)</td>\n",
       "      <td>0.798575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>WELFake</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_19_21_41_32</td>\n",
       "      <td>auc (sample weight)</td>\n",
       "      <td>0.880254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus      task  embeddings       split            timestamp  \\\n",
       "9    CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "10   CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "11   CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "12   CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "13   CoNLL-2003       pos  word_2_vec  validation  2024_05_19_13_32_45   \n",
       "..          ...       ...         ...         ...                  ...   \n",
       "423     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "424     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "425     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "426     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "427     WELFake  fakenews   fast_text        test  2024_05_19_21_41_32   \n",
       "\n",
       "                        metric     value  \n",
       "9     accuracy (sample weight)  0.837892  \n",
       "10   precision (sample weight)  0.858589  \n",
       "11      recall (sample weight)  0.837892  \n",
       "12      fscore (sample weight)  0.844059  \n",
       "13         auc (sample weight)  0.977138  \n",
       "..                         ...       ...  \n",
       "423   accuracy (sample weight)  0.799859  \n",
       "424  precision (sample weight)  0.801995  \n",
       "425     recall (sample weight)  0.799859  \n",
       "426     fscore (sample weight)  0.798575  \n",
       "427        auc (sample weight)  0.880254  \n",
       "\n",
       "[158 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = baselines_df[baselines_df['metric'].apply(lambda x: '(sample weight)' in x or 'corr.' in x)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b78c616-8d0c-4317-9344-116748869667",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('chunk',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 84.38 & 85.14 & 84.38 & 84.65 & 95.30 \\\\\n",
      "('validation',) -- 86.35 & 86.89 & 86.35 & 86.54 & 96.92 \\\\\n",
      "\n",
      "('fakenews',)\n",
      "\n",
      "\n",
      "('def_2_vec_legacy',)\n",
      "\n",
      "('test',) -- 78.42 & 80.69 & 78.42 & 77.73 & 90.53 \\\\\n",
      "('validation',) -- 78.19 & 80.80 & 78.19 & 77.45 & 90.63 \\\\\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 79.99 & 80.20 & 79.99 & 79.86 & 88.03 \\\\\n",
      "('validation',) -- 79.97 & 80.23 & 79.97 & 79.84 & 87.84 \\\\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 76.82 & 78.83 & 76.82 & 76.66 & 87.78 \\\\\n",
      "('validation',) -- 76.84 & 78.86 & 76.84 & 76.65 & 87.68 \\\\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 78.41 & 78.40 & 78.41 & 78.40 & 86.11 \\\\\n",
      "('validation',) -- 78.46 & 78.45 & 78.46 & 78.45 & 86.08 \\\\\n",
      "\n",
      "('ner',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 98.00 & 99.27 & 98.00 & 98.57 & 96.77 \\\\\n",
      "('validation',) -- 98.62 & 99.40 & 98.62 & 98.96 & 97.73 \\\\\n",
      "\n",
      "('newsgroup',)\n",
      "\n",
      "\n",
      "('def_2_vec_legacy',)\n",
      "\n",
      "('test',) -- 56.40 & 61.69 & 56.40 & 56.68 & 94.53 \\\\\n",
      "('validation',) -- 64.86 & 69.34 & 64.86 & 65.27 & 96.19 \\\\\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 67.35 & 68.55 & 67.35 & 67.08 & 96.83 \\\\\n",
      "('validation',) -- 72.73 & 73.90 & 72.73 & 72.50 & 97.50 \\\\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 76.52 & 77.50 & 76.52 & 76.26 & 98.19 \\\\\n",
      "('validation',) -- 82.35 & 82.94 & 82.35 & 82.21 & 98.83 \\\\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 73.60 & 74.01 & 73.60 & 73.43 & 97.68 \\\\\n",
      "('validation',) -- 80.76 & 81.15 & 80.76 & 80.67 & 98.47 \\\\\n",
      "\n",
      "('pos',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 82.23 & 84.66 & 82.23 & 82.99 & 96.70 \\\\\n",
      "('validation',) -- 83.79 & 85.86 & 83.79 & 84.41 & 97.71 \\\\\n",
      "\n",
      "('sentiment',)\n",
      "\n",
      "\n",
      "('def_2_vec_legacy',)\n",
      "\n",
      "('test',) -- 59.82 & 59.99 & 59.82 & 59.83 & 62.77 \\\\\n",
      "('validation',) -- 58.64 & 58.66 & 58.64 & 58.64 & 61.21 \\\\\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 66.46 & 66.43 & 66.46 & 66.40 & 71.15 \\\\\n",
      "('validation',) -- 63.75 & 63.74 & 63.75 & 63.72 & 69.46 \\\\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 64.91 & 66.33 & 64.91 & 63.64 & 73.85 \\\\\n",
      "('validation',) -- 65.42 & 67.56 & 65.42 & 64.01 & 73.40 \\\\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 69.31 & 69.29 & 69.31 & 69.28 & 74.62 \\\\\n",
      "('validation',) -- 69.95 & 69.95 & 69.95 & 69.94 & 74.31 \\\\\n",
      "\n",
      "('similarity_score',)\n",
      "\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 70.95 & 0.00 & 69.52 & 0.00 \\\\\n",
      "('validation',) -- 75.95 & 0.00 & 76.79 & 0.00 \\\\\n"
     ]
    }
   ],
   "source": [
    "for task, task_groups in df.groupby(['task']):\n",
    "    print()\n",
    "    print(task)\n",
    "    print()\n",
    "    for embedding, embeddings_groups in task_groups.groupby(['embeddings']):\n",
    "        print()\n",
    "        print(embedding)\n",
    "        print()\n",
    "        for split, split_groups in embeddings_groups.groupby(['split']):\n",
    "            # print(split, ' '.join(f'{row['metric']}: {row['value'] * 100:.2f}' for _, row in split_groups.iterrows()))\n",
    "            print(split, '--', ' & '.join(f'{row['value'] * 100:.2f}' for _, row in split_groups.iterrows()), '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac2145-42f2-4a98-ab3e-4dcd8f1dc210",
   "metadata": {},
   "source": [
    "## Def2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e464e6-2829-4023-a56f-ab4a6b47a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_2_vec_df = results_df[results_df['embeddings'].apply(lambda x: x == 'def_2_vec' and not (x.endswith('') or x.endswith('')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec0c35-d791-45a7-ac1d-8626ae398d35",
   "metadata": {},
   "source": [
    "### Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bd1e8b1-3593-4d99-a6f2-4f5928438da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>task</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>split</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>8.124684e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>precision (macro)</td>\n",
       "      <td>7.445450e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>recall (macro)</td>\n",
       "      <td>6.819199e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>fscore (macro)</td>\n",
       "      <td>7.053761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>auc (macro)</td>\n",
       "      <td>9.752486e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>spearman corr. p</td>\n",
       "      <td>4.293119e-222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>pearson corr.</td>\n",
       "      <td>6.336248e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>pearson corr. p</td>\n",
       "      <td>1.118321e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>spearman corr.</td>\n",
       "      <td>6.190004e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>spearman corr. p</td>\n",
       "      <td>1.183670e-146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus              task  embeddings       split  \\\n",
       "0    CoNLL-2003               pos  word_2_vec  validation   \n",
       "1    CoNLL-2003               pos  word_2_vec  validation   \n",
       "2    CoNLL-2003               pos  word_2_vec  validation   \n",
       "3    CoNLL-2003               pos  word_2_vec  validation   \n",
       "4    CoNLL-2003               pos  word_2_vec  validation   \n",
       "..          ...               ...         ...         ...   \n",
       "355         STS  similarity_score   fast_text  validation   \n",
       "356         STS  similarity_score   fast_text        test   \n",
       "357         STS  similarity_score   fast_text        test   \n",
       "358         STS  similarity_score   fast_text        test   \n",
       "359         STS  similarity_score   fast_text        test   \n",
       "\n",
       "               timestamp             metric          value  \n",
       "0    2024_05_18_10_27_34           accuracy   8.124684e-01  \n",
       "1    2024_05_18_10_27_34  precision (macro)   7.445450e-01  \n",
       "2    2024_05_18_10_27_34     recall (macro)   6.819199e-01  \n",
       "3    2024_05_18_10_27_34     fscore (macro)   7.053761e-01  \n",
       "4    2024_05_18_10_27_34        auc (macro)   9.752486e-01  \n",
       "..                   ...                ...            ...  \n",
       "355  2024_05_18_11_37_25   spearman corr. p  4.293119e-222  \n",
       "356  2024_05_18_11_37_25      pearson corr.   6.336248e-01  \n",
       "357  2024_05_18_11_37_25    pearson corr. p  1.118321e-155  \n",
       "358  2024_05_18_11_37_25     spearman corr.   6.190004e-01  \n",
       "359  2024_05_18_11_37_25   spearman corr. p  1.183670e-146  \n",
       "\n",
       "[144 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = def_2_vec_df[def_2_vec_df['metric'].apply(lambda x: x == 'accuracy' or '(macro)' in x or 'corr.' in x) ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "423c4050-4142-411d-905d-c8d61662c035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('chunk',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 92.95 & 76.60 & 50.02 & 54.92 & 97.08 \\\n",
      "('validation',) -- 93.37 & 63.00 & 51.31 & 54.59 & 97.53 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 92.97 & 65.97 & 51.29 & 54.68 & 98.13 \\\n",
      "('validation',) -- 93.64 & 70.49 & 56.17 & 60.31 & 98.45 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 81.78 & 60.88 & 48.39 & 52.22 & 95.56 \\\n",
      "('validation',) -- 84.57 & 66.64 & 50.21 & 53.80 & 95.55 \\\n",
      "\n",
      "('ner',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 95.50 & 80.91 & 74.64 & 77.44 & 98.90 \\\n",
      "('validation',) -- 96.47 & 87.86 & 77.57 & 81.83 & 98.84 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 95.98 & 81.90 & 79.93 & 80.84 & 99.09 \\\n",
      "('validation',) -- 97.01 & 88.82 & 82.49 & 85.41 & 99.23 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 91.74 & 75.74 & 64.20 & 69.25 & 96.41 \\\n",
      "('validation',) -- 93.31 & 83.87 & 67.32 & 74.30 & 97.12 \\\n",
      "\n",
      "('pos',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 91.20 & 89.57 & 81.84 & 84.10 & 99.25 \\\n",
      "('validation',) -- 91.98 & 83.96 & 78.96 & 80.79 & 99.18 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 91.84 & 89.35 & 84.18 & 85.80 & 99.40 \\\n",
      "('validation',) -- 92.90 & 85.48 & 80.86 & 82.62 & 99.58 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 80.02 & 75.45 & 68.40 & 70.68 & 97.48 \\\n",
      "('validation',) -- 81.25 & 74.45 & 68.19 & 70.54 & 97.52 \\\n",
      "\n",
      "('sentiment',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 68.39 & 68.38 & 68.37 & 68.37 & 72.53 \\\n",
      "('validation',) -- 66.87 & 66.86 & 66.86 & 66.86 & 71.92 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 66.95 & 67.06 & 66.85 & 66.81 & 74.45 \\\n",
      "('validation',) -- 67.95 & 68.07 & 67.89 & 67.85 & 73.93 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 68.68 & 69.05 & 68.53 & 68.41 & 75.04 \\\n",
      "('validation',) -- 68.75 & 69.15 & 68.65 & 68.51 & 73.97 \\\n",
      "\n",
      "('similarity_score',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 63.36 & 0.00 & 61.90 & 0.00 \\\n",
      "('validation',) -- 69.30 & 0.00 & 70.09 & 0.00 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 69.76 & 0.00 & 68.94 & 0.00 \\\n",
      "('validation',) -- 78.09 & 0.00 & 78.94 & 0.00 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 71.37 & 0.00 & 70.59 & 0.00 \\\n",
      "('validation',) -- 76.35 & 0.00 & 77.09 & 0.00 \\\n"
     ]
    }
   ],
   "source": [
    "for task, task_groups in df.groupby(['task']):\n",
    "    print()\n",
    "    print(task)\n",
    "    print()\n",
    "    for embedding, embeddings_groups in task_groups.groupby(['embeddings']):\n",
    "        print()\n",
    "        print(embedding)\n",
    "        print()\n",
    "        for split, split_groups in embeddings_groups.groupby(['split']):\n",
    "            # print(split, ' '.join(f'{row['metric']}: {row['value'] * 100:.2f}' for _, row in split_groups.iterrows()))\n",
    "            print(split, '--', ' & '.join(f'{row['value'] * 100:.2f}' for _, row in split_groups.iterrows()), '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff84663-abfa-4a72-8eb2-5c0adab36ef4",
   "metadata": {},
   "source": [
    "### Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bd6fa46-e45f-4460-9460-1f34a2a01a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>task</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>split</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>8.124684e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>precision (weighted)</td>\n",
       "      <td>8.134053e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>recall (weighted)</td>\n",
       "      <td>8.124684e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>fscore (weighted)</td>\n",
       "      <td>8.096775e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>auc (weighted)</td>\n",
       "      <td>9.811476e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>spearman corr. p</td>\n",
       "      <td>4.293119e-222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>pearson corr.</td>\n",
       "      <td>6.336248e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>pearson corr. p</td>\n",
       "      <td>1.118321e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>spearman corr.</td>\n",
       "      <td>6.190004e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>spearman corr. p</td>\n",
       "      <td>1.183670e-146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus              task  embeddings       split  \\\n",
       "0    CoNLL-2003               pos  word_2_vec  validation   \n",
       "5    CoNLL-2003               pos  word_2_vec  validation   \n",
       "6    CoNLL-2003               pos  word_2_vec  validation   \n",
       "7    CoNLL-2003               pos  word_2_vec  validation   \n",
       "8    CoNLL-2003               pos  word_2_vec  validation   \n",
       "..          ...               ...         ...         ...   \n",
       "355         STS  similarity_score   fast_text  validation   \n",
       "356         STS  similarity_score   fast_text        test   \n",
       "357         STS  similarity_score   fast_text        test   \n",
       "358         STS  similarity_score   fast_text        test   \n",
       "359         STS  similarity_score   fast_text        test   \n",
       "\n",
       "               timestamp                metric          value  \n",
       "0    2024_05_18_10_27_34              accuracy   8.124684e-01  \n",
       "5    2024_05_18_10_27_34  precision (weighted)   8.134053e-01  \n",
       "6    2024_05_18_10_27_34     recall (weighted)   8.124684e-01  \n",
       "7    2024_05_18_10_27_34     fscore (weighted)   8.096775e-01  \n",
       "8    2024_05_18_10_27_34        auc (weighted)   9.811476e-01  \n",
       "..                   ...                   ...            ...  \n",
       "355  2024_05_18_11_37_25      spearman corr. p  4.293119e-222  \n",
       "356  2024_05_18_11_37_25         pearson corr.   6.336248e-01  \n",
       "357  2024_05_18_11_37_25       pearson corr. p  1.118321e-155  \n",
       "358  2024_05_18_11_37_25        spearman corr.   6.190004e-01  \n",
       "359  2024_05_18_11_37_25      spearman corr. p  1.183670e-146  \n",
       "\n",
       "[144 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = def_2_vec_df[def_2_vec_df['metric'].apply(lambda x: x == 'accuracy' or '(weighted)' in x or 'corr.' in x)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48f03192-972a-4a60-8940-1254f2225c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('chunk',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 92.95 & 92.76 & 92.95 & 92.75 & 99.07 \\\n",
      "('validation',) -- 93.37 & 93.16 & 93.37 & 93.20 & 99.27 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 92.97 & 92.80 & 92.97 & 92.82 & 99.09 \\\n",
      "('validation',) -- 93.64 & 93.49 & 93.64 & 93.53 & 99.33 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 81.78 & 82.59 & 81.78 & 81.94 & 96.35 \\\n",
      "('validation',) -- 84.57 & 84.90 & 84.57 & 84.60 & 97.43 \\\n",
      "\n",
      "('ner',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 95.50 & 95.23 & 95.50 & 95.30 & 99.27 \\\n",
      "('validation',) -- 96.47 & 96.26 & 96.47 & 96.27 & 99.16 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 95.98 & 95.90 & 95.98 & 95.93 & 99.43 \\\n",
      "('validation',) -- 97.01 & 96.89 & 97.01 & 96.93 & 99.48 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 91.74 & 91.09 & 91.74 & 91.25 & 96.33 \\\n",
      "('validation',) -- 93.31 & 92.87 & 93.31 & 92.87 & 97.20 \\\n",
      "\n",
      "('pos',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 91.20 & 91.17 & 91.20 & 91.10 & 99.23 \\\n",
      "('validation',) -- 91.98 & 91.92 & 91.98 & 91.88 & 99.36 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 91.84 & 91.78 & 91.84 & 91.77 & 99.35 \\\n",
      "('validation',) -- 92.90 & 92.83 & 92.90 & 92.83 & 99.52 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 80.02 & 79.80 & 80.02 & 79.70 & 97.52 \\\n",
      "('validation',) -- 81.25 & 81.34 & 81.25 & 80.97 & 98.11 \\\n",
      "\n",
      "('sentiment',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 68.39 & 68.39 & 68.39 & 68.39 & 72.53 \\\n",
      "('validation',) -- 66.87 & 66.87 & 66.87 & 66.87 & 71.92 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 66.95 & 67.05 & 66.95 & 66.85 & 74.45 \\\n",
      "('validation',) -- 67.95 & 68.06 & 67.95 & 67.87 & 73.93 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 68.68 & 69.01 & 68.68 & 68.46 & 75.04 \\\n",
      "('validation',) -- 68.75 & 69.12 & 68.75 & 68.55 & 73.97 \\\n",
      "\n",
      "('similarity_score',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 63.36 & 0.00 & 61.90 & 0.00 \\\n",
      "('validation',) -- 69.30 & 0.00 & 70.09 & 0.00 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 69.76 & 0.00 & 68.94 & 0.00 \\\n",
      "('validation',) -- 78.09 & 0.00 & 78.94 & 0.00 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 71.37 & 0.00 & 70.59 & 0.00 \\\n",
      "('validation',) -- 76.35 & 0.00 & 77.09 & 0.00 \\\n"
     ]
    }
   ],
   "source": [
    "for task, task_groups in df.groupby(['task']):\n",
    "    print()\n",
    "    print(task)\n",
    "    print()\n",
    "    for embedding, embeddings_groups in task_groups.groupby(['embeddings']):\n",
    "        print()\n",
    "        print(embedding)\n",
    "        print()\n",
    "        for split, split_groups in embeddings_groups.groupby(['split']):\n",
    "            # print(split, ' '.join(f'{row['metric']}: {row['value'] * 100:.2f}' for _, row in split_groups.iterrows()))\n",
    "            print(split, '--', ' & '.join(f'{row['value'] * 100:.2f}' for _, row in split_groups.iterrows()), '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7843e-29f6-4de9-a2ac-ac1489628850",
   "metadata": {},
   "source": [
    "### Sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54db9b66-fa2e-4fa0-bfe9-fc57ddf24329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>task</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>split</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>accuracy (sample weight)</td>\n",
       "      <td>8.314087e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>precision (sample weight)</td>\n",
       "      <td>8.513314e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>recall (sample weight)</td>\n",
       "      <td>8.314087e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>fscore (sample weight)</td>\n",
       "      <td>8.371360e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CoNLL-2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>word_2_vec</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_10_27_34</td>\n",
       "      <td>auc (sample weight)</td>\n",
       "      <td>9.744865e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>validation</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>spearman corr. p</td>\n",
       "      <td>4.293119e-222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>pearson corr.</td>\n",
       "      <td>6.336248e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>pearson corr. p</td>\n",
       "      <td>1.118321e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>spearman corr.</td>\n",
       "      <td>6.190004e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>STS</td>\n",
       "      <td>similarity_score</td>\n",
       "      <td>fast_text</td>\n",
       "      <td>test</td>\n",
       "      <td>2024_05_18_11_37_25</td>\n",
       "      <td>spearman corr. p</td>\n",
       "      <td>1.183670e-146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus              task  embeddings       split  \\\n",
       "9    CoNLL-2003               pos  word_2_vec  validation   \n",
       "10   CoNLL-2003               pos  word_2_vec  validation   \n",
       "11   CoNLL-2003               pos  word_2_vec  validation   \n",
       "12   CoNLL-2003               pos  word_2_vec  validation   \n",
       "13   CoNLL-2003               pos  word_2_vec  validation   \n",
       "..          ...               ...         ...         ...   \n",
       "355         STS  similarity_score   fast_text  validation   \n",
       "356         STS  similarity_score   fast_text        test   \n",
       "357         STS  similarity_score   fast_text        test   \n",
       "358         STS  similarity_score   fast_text        test   \n",
       "359         STS  similarity_score   fast_text        test   \n",
       "\n",
       "               timestamp                     metric          value  \n",
       "9    2024_05_18_10_27_34   accuracy (sample weight)   8.314087e-01  \n",
       "10   2024_05_18_10_27_34  precision (sample weight)   8.513314e-01  \n",
       "11   2024_05_18_10_27_34     recall (sample weight)   8.314087e-01  \n",
       "12   2024_05_18_10_27_34     fscore (sample weight)   8.371360e-01  \n",
       "13   2024_05_18_10_27_34        auc (sample weight)   9.744865e-01  \n",
       "..                   ...                        ...            ...  \n",
       "355  2024_05_18_11_37_25           spearman corr. p  4.293119e-222  \n",
       "356  2024_05_18_11_37_25              pearson corr.   6.336248e-01  \n",
       "357  2024_05_18_11_37_25            pearson corr. p  1.118321e-155  \n",
       "358  2024_05_18_11_37_25             spearman corr.   6.190004e-01  \n",
       "359  2024_05_18_11_37_25           spearman corr. p  1.183670e-146  \n",
       "\n",
       "[144 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = def_2_vec_df[def_2_vec_df['metric'].apply(lambda x: '(sample weight)' in x or 'corr.' in x)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b30eec3-bd5a-4e57-b0a1-4f69d9322566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('chunk',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 94.54 & 94.83 & 94.54 & 94.66 & 98.88 \\\n",
      "('validation',) -- 94.70 & 95.01 & 94.70 & 94.82 & 99.12 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 94.23 & 94.59 & 94.23 & 94.38 & 98.86 \\\n",
      "('validation',) -- 94.85 & 95.24 & 94.85 & 95.01 & 99.20 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 81.74 & 85.21 & 81.74 & 82.79 & 95.13 \\\n",
      "('validation',) -- 84.94 & 86.90 & 84.94 & 85.55 & 96.69 \\\n",
      "\n",
      "('ner',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 99.05 & 99.59 & 99.05 & 99.29 & 99.42 \\\n",
      "('validation',) -- 99.45 & 99.70 & 99.45 & 99.56 & 99.40 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 98.78 & 99.59 & 98.78 & 99.14 & 99.56 \\\n",
      "('validation',) -- 99.32 & 99.70 & 99.32 & 99.48 & 99.65 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 97.87 & 99.26 & 97.87 & 98.49 & 96.52 \\\n",
      "('validation',) -- 98.67 & 99.39 & 98.67 & 98.98 & 97.53 \\\n",
      "\n",
      "('pos',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 90.68 & 91.69 & 90.68 & 91.01 & 98.72 \\\n",
      "('validation',) -- 91.18 & 91.80 & 91.18 & 91.38 & 98.77 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 91.47 & 92.32 & 91.47 & 91.77 & 98.94 \\\n",
      "('validation',) -- 92.39 & 92.91 & 92.39 & 92.57 & 99.13 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 82.06 & 84.22 & 82.06 & 82.76 & 96.48 \\\n",
      "('validation',) -- 83.14 & 85.13 & 83.14 & 83.71 & 97.45 \\\n",
      "\n",
      "('sentiment',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 68.41 & 68.41 & 68.41 & 68.41 & 72.53 \\\n",
      "('validation',) -- 66.88 & 66.88 & 66.88 & 66.88 & 71.92 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 67.06 & 67.07 & 67.06 & 66.95 & 74.45 \\\n",
      "('validation',) -- 68.01 & 68.06 & 68.01 & 67.93 & 73.93 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 68.83 & 69.02 & 68.83 & 68.60 & 75.04 \\\n",
      "('validation',) -- 68.85 & 69.12 & 68.85 & 68.64 & 73.97 \\\n",
      "\n",
      "('similarity_score',)\n",
      "\n",
      "\n",
      "('fast_text',)\n",
      "\n",
      "('test',) -- 63.36 & 0.00 & 61.90 & 0.00 \\\n",
      "('validation',) -- 69.30 & 0.00 & 70.09 & 0.00 \\\n",
      "\n",
      "('glove',)\n",
      "\n",
      "('test',) -- 69.76 & 0.00 & 68.94 & 0.00 \\\n",
      "('validation',) -- 78.09 & 0.00 & 78.94 & 0.00 \\\n",
      "\n",
      "('word_2_vec',)\n",
      "\n",
      "('test',) -- 71.37 & 0.00 & 70.59 & 0.00 \\\n",
      "('validation',) -- 76.35 & 0.00 & 77.09 & 0.00 \\\n"
     ]
    }
   ],
   "source": [
    "for task, task_groups in df.groupby(['task']):\n",
    "    print()\n",
    "    print(task)\n",
    "    print()\n",
    "    for embedding, embeddings_groups in task_groups.groupby(['embeddings']):\n",
    "        print()\n",
    "        print(embedding)\n",
    "        print()\n",
    "        for split, split_groups in embeddings_groups.groupby(['split']):\n",
    "            # print(split, ' '.join(f'{row['metric']}: {row['value'] * 100:.2f}' for _, row in split_groups.iterrows()))\n",
    "            print(split, '--', ' & '.join(f'{row['value'] * 100:.2f}' for _, row in split_groups.iterrows()), '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea1d8d-c80a-4f7d-99b6-7bb863157d53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
